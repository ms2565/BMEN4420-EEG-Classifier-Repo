{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY3z4fGrPY0j",
        "outputId": "57de119e-a5bb-492a-b235-40b6c2d8001e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'/content/drive/MyDrive/Columbia Spring 2023/Signal Modeling/Project-EEG-Classifier/BMEN4420-EEG-Classifier-Repo'"
      ],
      "metadata": {
        "id": "wFSwK5USdu7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yhOLV8UPTrKb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import scipy.io as scio\n",
        "\n",
        "#from Models.Transformer import TransformerModel\n",
        "#from Models.PositionalEncoding import LearnedPositionalEncoding\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub01 = scio.loadmat('/content/drive/MyDrive/Columbia Spring 2023/Signal Modeling/Project-EEG-Classifier/Signal_Processing_FC/Signal_Processing_FC/Subject_1.mat')\n",
        "sub02 = scio.loadmat('/content/drive/MyDrive/Columbia Spring 2023/Signal Modeling/Project-EEG-Classifier/Signal_Processing_FC/Signal_Processing_FC/Subject_2.mat')\n",
        "sub03 = scio.loadmat('/content/drive/MyDrive/Columbia Spring 2023/Signal Modeling/Project-EEG-Classifier/Signal_Processing_FC/Signal_Processing_FC/Subject_3.mat')\n",
        "sub04 = scio.loadmat('/content/drive/MyDrive/Columbia Spring 2023/Signal Modeling/Project-EEG-Classifier/Signal_Processing_FC/Signal_Processing_FC/Subject_4.mat')\n",
        "sub05 = scio.loadmat('/content/drive/MyDrive/Columbia Spring 2023/Signal Modeling/Project-EEG-Classifier/Signal_Processing_FC/Signal_Processing_FC/Subject_5.mat')\n",
        "sub06 = scio.loadmat('/content/drive/MyDrive/Columbia Spring 2023/Signal Modeling/Project-EEG-Classifier/Signal_Processing_FC/Signal_Processing_FC/Subject_6.mat')\n",
        "sub07 = scio.loadmat('/content/drive/MyDrive/Columbia Spring 2023/Signal Modeling/Project-EEG-Classifier/Signal_Processing_FC/Signal_Processing_FC/Subject_7.mat')\n",
        "sub08 = scio.loadmat('/content/drive/MyDrive/Columbia Spring 2023/Signal Modeling/Project-EEG-Classifier/Signal_Processing_FC/Signal_Processing_FC/Subject_8.mat')\n"
      ],
      "metadata": {
        "id": "lUT0FtKqgNPP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyBt_PCHgzGZ",
        "outputId": "2a4256dd-63fe-4d79-9db8-9d33e044f67d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'__header__': b'MATLAB 5.0 MAT-file, Platform: MACI64, Created on: Thu Apr 16 01:12:29 2015', '__version__': '1.0', '__globals__': [], 'nTrial': array([[92]], dtype=uint8), 'n_TRAIN': array([[74]], dtype=uint8), 'n_TRAIN_FACE': array([[37]], dtype=uint8), 'n_TRAIN_CAR': array([[37]], dtype=uint8), 'n_TEST': array([[18]], dtype=uint8), 'X_EEG_TRAIN': array([[[   6.97003996,    5.22083678,  -17.1914582 , ...,\n",
            "          -25.80293596,   33.32916215,  -18.34567292],\n",
            "        [   8.2158817 ,    8.26788388,  -11.66153858, ...,\n",
            "          -25.74980671,   35.29228467,  -18.86517921],\n",
            "        [   9.39967036,   11.23717244,   -6.46615225, ...,\n",
            "          -25.68606431,   37.26682919,  -19.3574931 ],\n",
            "        ...,\n",
            "        [   8.79849284,   17.21847384,    4.43483363, ...,\n",
            "           18.67956349,   25.65289945,  -11.04960909],\n",
            "        [   7.7938694 ,   15.27662661,    3.52229213, ...,\n",
            "           16.41005534,   22.45073499,   -9.49163462],\n",
            "        [   6.61649453,   13.37265368,    2.68595743, ...,\n",
            "           14.10814017,   19.24564671,   -7.86932289]],\n",
            "\n",
            "       [[   6.91413808,   17.13276758,   35.15370052, ...,\n",
            "           -7.87408071,  -13.93776875,   24.09352304],\n",
            "        [   6.73833924,   18.31935172,   34.64878254, ...,\n",
            "           -8.99999685,   -7.69235069,   31.04197796],\n",
            "        [   6.54979125,   19.33429283,   34.36053019, ...,\n",
            "          -10.31080849,   -1.79582868,   38.04875697],\n",
            "        ...,\n",
            "        [  -4.91547211,   10.33850121,    3.35180801, ...,\n",
            "         -133.61608604,   20.75511816,   59.41833415],\n",
            "        [  -4.36426827,    8.85641822,    3.36872411, ...,\n",
            "         -116.76679212,   17.61497118,   52.56322136],\n",
            "        [  -3.81088391,    7.45014587,    3.25473242, ...,\n",
            "          -99.89161215,   14.23583776,   45.53445606]],\n",
            "\n",
            "       [[   1.65167492,   -1.98098649,  -12.49624388, ...,\n",
            "            5.25967956,   -4.43130773,  -11.80027543],\n",
            "        [   2.76146109,   -1.18658489,  -13.58722475, ...,\n",
            "            6.42249158,   -4.56941331,  -13.2175283 ],\n",
            "        [   3.86438248,   -0.40228854,  -14.64336742, ...,\n",
            "            7.58142516,   -4.70727352,  -14.64697274],\n",
            "        ...,\n",
            "        [   1.10648373,   -3.30571402,  -15.34711331, ...,\n",
            "            1.52016041,   10.81010688,   -1.89582531],\n",
            "        [   0.93949749,   -2.88936224,  -13.51375534, ...,\n",
            "            1.31908691,    9.49680541,   -1.58863179],\n",
            "        [   0.77919624,   -2.39624284,  -11.68237099, ...,\n",
            "            1.07820257,    8.18117697,   -1.32914093]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[  -7.66430925,    7.44806952,    3.21588944, ...,\n",
            "          -12.47883705,   26.09354006,    8.18283928],\n",
            "        [  -7.73232581,    7.27127635,    3.1943552 , ...,\n",
            "          -11.48215348,   27.5640216 ,   11.50471959],\n",
            "        [  -7.74142252,    7.12858546,    3.13607879, ...,\n",
            "          -10.4550318 ,   29.01425994,   14.80885488],\n",
            "        ...,\n",
            "        [   2.11648153,    4.75239639,   17.90025414, ...,\n",
            "           -2.8907065 ,    3.12125919,   -3.04975854],\n",
            "        [   1.9000686 ,    4.21580194,   15.72443003, ...,\n",
            "           -2.53993794,    2.72944611,   -2.72322395],\n",
            "        [   1.66725756,    3.6545068 ,   13.52108474, ...,\n",
            "           -2.14388155,    2.34377782,   -2.36291572]],\n",
            "\n",
            "       [[  -6.93265555,    7.23345433,    2.54840869, ...,\n",
            "          -12.72232224,   26.20596111,    8.37180088],\n",
            "        [  -6.9284759 ,    6.88678927,    2.4714831 , ...,\n",
            "          -11.52508763,   27.6216858 ,   11.77792948],\n",
            "        [  -6.86915707,    6.58193963,    2.3569207 , ...,\n",
            "          -10.2986953 ,   29.01951409,   15.16314624],\n",
            "        ...,\n",
            "        [   2.39315949,    4.90632353,   18.95068691, ...,\n",
            "           -2.63587378,    3.21491618,   -2.9968696 ],\n",
            "        [   2.14603425,    4.34383353,   16.64035541, ...,\n",
            "           -2.33412937,    2.81276068,   -2.67589066],\n",
            "        [   1.87918778,    3.75585501,   14.29840295, ...,\n",
            "           -1.99391743,    2.42212726,   -2.31833273]],\n",
            "\n",
            "       [[  -6.9187249 ,    7.42563217,    2.63572902, ...,\n",
            "          -13.10483993,   26.58085989,    7.83413356],\n",
            "        [  -6.99294516,    7.24108863,    2.51471302, ...,\n",
            "          -12.06009759,   28.09020874,   11.16452605],\n",
            "        [  -7.00683669,    7.09687449,    2.35682427, ...,\n",
            "          -10.98019808,   29.58074814,   14.47650264],\n",
            "        ...,\n",
            "        [   2.41771618,    4.60638483,   18.26894801, ...,\n",
            "           -2.60322456,    4.29283084,   -2.85240605],\n",
            "        [   2.16949378,    4.08297098,   16.04481857, ...,\n",
            "           -2.30601732,    3.74455891,   -2.54736654],\n",
            "        [   1.89956693,    3.5362827 ,   13.79252026, ...,\n",
            "           -1.96522324,    3.19586859,   -2.20591823]]]), 'X_EEG_TEST': array([[[ 1.38073370e+00, -1.15499484e+01,  1.91565954e+01, ...,\n",
            "          1.29955096e+01, -1.20628854e+00,  3.10986874e+00],\n",
            "        [-5.63401536e-01, -1.48336217e+01,  2.02018641e+01, ...,\n",
            "          1.28783432e+01, -3.44887934e-02,  1.22445099e-01],\n",
            "        [-2.51430074e+00, -1.80970862e+01,  2.12326797e+01, ...,\n",
            "          1.27804801e+01,  1.16278024e+00, -2.84252824e+00],\n",
            "        ...,\n",
            "        [ 3.14560241e+01,  6.91310344e+00, -1.70550347e+01, ...,\n",
            "          2.12843626e-01,  4.87621483e+00,  2.81163473e+01],\n",
            "        [ 2.75492115e+01,  6.05786365e+00, -1.51329578e+01, ...,\n",
            "          1.24927356e-01,  4.36750979e+00,  2.46333523e+01],\n",
            "        [ 2.35818663e+01,  5.20888844e+00, -1.31536966e+01, ...,\n",
            "         -4.79923182e-02,  3.90958562e+00,  2.11075720e+01]],\n",
            "\n",
            "       [[-6.14601537e+00, -1.41951014e+01, -7.30279268e+01, ...,\n",
            "         -3.47523751e+00, -4.68389403e+01,  2.65845621e+00],\n",
            "        [ 2.03605665e+00, -8.13259632e+00, -8.04326642e+01, ...,\n",
            "          1.33455964e-02, -5.22008428e+01,  1.77342258e+00],\n",
            "        [ 9.96497208e+00, -1.93552116e+00, -8.80330959e+01, ...,\n",
            "          3.47989251e+00, -5.75935678e+01,  1.05652678e+00],\n",
            "        ...,\n",
            "        [-4.67897805e+01,  7.83080030e+01,  3.10611424e+01, ...,\n",
            "          2.59768116e+01,  3.88831445e+01, -7.30291914e+01],\n",
            "        [-4.12185255e+01,  6.86067274e+01,  2.75381848e+01, ...,\n",
            "          2.29169008e+01,  3.32888305e+01, -6.40606143e+01],\n",
            "        [-3.55000574e+01,  5.89368521e+01,  2.34653377e+01, ...,\n",
            "          2.03288917e+01,  2.81197023e+01, -5.50534854e+01]],\n",
            "\n",
            "       [[-8.34319703e+00, -1.57249639e+01,  6.79253297e+00, ...,\n",
            "          3.32036412e+00, -8.66520668e+00,  4.83826061e-02],\n",
            "        [-7.06763727e+00, -1.58640837e+01,  8.15253435e+00, ...,\n",
            "          3.52036211e+00, -7.91021102e+00,  1.61056052e-02],\n",
            "        [-5.84834509e+00, -1.59729187e+01,  9.51894697e+00, ...,\n",
            "          3.74593185e+00, -7.13461292e+00, -7.15478726e-03],\n",
            "        ...,\n",
            "        [ 7.84874224e+00,  3.62555589e+00, -1.20314505e+01, ...,\n",
            "          2.41245526e+00, -2.07276595e+00, -7.33579994e+00],\n",
            "        [ 6.78720173e+00,  3.18317302e+00, -1.05636275e+01, ...,\n",
            "          2.22112885e+00, -1.71898006e+00, -6.41597040e+00],\n",
            "        [ 5.74070984e+00,  2.78315089e+00, -9.10480522e+00, ...,\n",
            "          2.04109728e+00, -1.33959949e+00, -5.52208380e+00]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 2.72545772e+01,  1.38300001e+01, -4.28447856e+00, ...,\n",
            "         -1.22786318e+00, -5.69431314e+00, -1.74434031e+01],\n",
            "        [ 2.51552904e+01,  1.46973854e+01, -4.64813332e+00, ...,\n",
            "          5.85531057e-01, -6.65802089e+00, -1.56557034e+01],\n",
            "        [ 2.30885665e+01,  1.55017985e+01, -5.02374615e+00, ...,\n",
            "          2.41204644e+00, -7.67560097e+00, -1.38784937e+01],\n",
            "        ...,\n",
            "        [-2.87597339e+01,  3.68512221e+00,  1.78717461e+00, ...,\n",
            "         -1.19505876e+00,  1.45733231e+01,  1.59851418e+01],\n",
            "        [-2.51391572e+01,  3.19270918e+00,  1.62799366e+00, ...,\n",
            "         -1.04107018e+00,  1.26811928e+01,  1.39837607e+01],\n",
            "        [-2.15343786e+01,  2.68356035e+00,  1.47630330e+00, ...,\n",
            "         -8.93048648e-01,  1.07947854e+01,  1.20755406e+01]],\n",
            "\n",
            "       [[ 2.74031259e+01,  1.40792844e+01, -3.58441864e+00, ...,\n",
            "         -8.91797904e-01, -5.53999973e+00, -1.77485325e+01],\n",
            "        [ 2.52155589e+01,  1.49043654e+01, -3.87990663e+00, ...,\n",
            "          1.03312983e+00, -6.50533562e+00, -1.58841610e+01],\n",
            "        [ 2.30621534e+01,  1.56679382e+01, -4.18889157e+00, ...,\n",
            "          2.96682993e+00, -7.52873308e+00, -1.40362594e+01],\n",
            "        ...,\n",
            "        [-3.00995231e+01,  4.96640656e+00,  1.25602851e+00, ...,\n",
            "         -4.18819156e-01,  1.44394804e+01,  1.71463602e+01],\n",
            "        [-2.63230044e+01,  4.31169152e+00,  1.18478048e+00, ...,\n",
            "         -3.65804274e-01,  1.25627763e+01,  1.50016514e+01],\n",
            "        [-2.25601856e+01,  3.63831511e+00,  1.12401745e+00, ...,\n",
            "         -3.22533915e-01,  1.06889234e+01,  1.29492978e+01]],\n",
            "\n",
            "       [[ 2.73201771e+01,  1.38105162e+01, -3.14137569e+00, ...,\n",
            "         -6.66120848e-01, -5.36424754e+00, -1.76997360e+01],\n",
            "        [ 2.52419586e+01,  1.47400712e+01, -3.40235058e+00, ...,\n",
            "          1.18186961e+00, -6.26933074e+00, -1.59540515e+01],\n",
            "        [ 2.31870226e+01,  1.56029060e+01, -3.67597331e+00, ...,\n",
            "          3.04047173e+00, -7.23541412e+00, -1.42166223e+01],\n",
            "        ...,\n",
            "        [-2.98677745e+01,  4.59853989e+00,  1.63988197e+00, ...,\n",
            "         -1.70513119e+00,  1.42369882e+01,  1.61153834e+01],\n",
            "        [-2.61160599e+01,  3.99200858e+00,  1.51069613e+00, ...,\n",
            "         -1.50272436e+00,  1.23785371e+01,  1.40950260e+01],\n",
            "        [-2.23790839e+01,  3.36138879e+00,  1.38617603e+00, ...,\n",
            "         -1.30127357e+00,  1.05246648e+01,  1.21704324e+01]]]), 'Y_EEG_TRAIN': array([[1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0]], dtype=uint8)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EEGData():\n",
        "  def __init__(self, data):\n",
        "    self.data = data\n",
        "  def __getitem__(self, index):\n",
        "    return self.data[index]\n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ],
      "metadata": {
        "id": "CvUVk_oEw4CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EEGPT(nn.Module):\n",
        "  def __init__(\n",
        "      self,\n",
        "      in_dim = 0\n",
        "               ):\n",
        "    super(EEGPT,self).__init__()\n",
        "    # BUILD SPATIAL PATH\n",
        "    ## CNN MODULE\n",
        "    self.Conv1_s = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=17, stride=1, padding=\"same\")\n",
        "    self.AvgPool1_s = nn.AvgPool1d(kernel_size=32,stride=32)\n",
        "    self.Conv2_s = nn.Conv1d(in_channels=64,out_channels=64,kernel_size=15,stride=1,padding=\"valid\") # output should be \n",
        "    ## TRANSFORMER MODULE\n",
        "    self.PosEnc1_s = PositionalEncoder(embedding_dim=64,max_length=1000)\n",
        "    self.Transf1_s = EncoderTransformer(inSize=64,outSize=4,numLayers=3,hiddenSize=1,numHeads=8,dropout=0.01)\n",
        "\n",
        "    # BUILD TEMPORAL PATH\n",
        "    # CNN MODULE\n",
        "    self.dwconv1_t = nn.Conv1d(in_channels=64,out_channels=64, kernel_size=64, stride=1, groups = 64, bias=False, padding=\"same\")\n",
        "    self.AvgPool1_t = nn.AvgPool2d(kernel_size=8)    \n",
        "    # TRANSFORMER MODULE\n",
        "    self.PosEnc1_t = PositionalEncoder(embedding_dim=64,max_length=1000)\n",
        "    self.Transf1_t = EncoderTransformer(inSize=1200,outSize=4,numLayers=3,hiddenSize=1,numHeads=8,dropout=0.01)\n",
        "    # Build Fully Connected Path\n",
        "    self.fc1 = nn.Linear(8,2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Spatial Pass\n",
        "    x_s = self.Conv1_s(x_s)\n",
        "    x_s = self.AvgPool1_s(x_s)\n",
        "    x_s = self.Conv2_s(x_s)\n",
        "    x_s = self.PosEnc1_s(x_s)\n",
        "    x_s = self.Transf1_s(x_s)\n",
        "    # Temporal Pass\n",
        "    x_t = self.dwconv1_t(x)\n",
        "    x_t = self.AvgPool1_t(x_t)\n",
        "    x_t = x_t.permute(0,2,1) # transpose to present time wise vectors to transformer encoder    \n",
        "    x_t = self.PosEnc1_t(x_t)\n",
        "    x_t = self.Transf1_t(x_t)\n",
        "    # Concatenation\n",
        "    x_cat = torch.cat(x_s, x_t)\n",
        "    # Output Pass: Fully Connected into Softmax\n",
        "    x = self.fc1(x_cat)\n",
        "    x = F.log_softmax(x)\n",
        "    return x\n",
        "\n",
        "class EncoderTransformer():\n",
        "  def __init__(self, inSize, outSize, numLayers=3, hiddenSize=1, numHeads=8, dropout=0.01):\n",
        "    self.encoderLayer = nn.TransformerEncoderLayer(d_model=inSize, nhead=numHeads, dim_feedforward=hiddenSize, dropout=dropout)\n",
        "    self.encoder = nn.TransformerEncoder(self.encoderLayer,num_layers=numLayers)\n",
        "    self.fc1 = nn.Linear(outSize, outSize)\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)\n",
        "    x = self.fc1(x)\n",
        "    return x\n",
        "\n",
        "class PositionalEncoder(nn.Module):\n",
        "  def __init__(self, embedding_dim, max_length=1000):\n",
        "    super(PositionalEncoder,self).__init__()\n",
        "    pe = torch.zeros(max_length, embedding_dim)\n",
        "    position = torch.arange(0, max_length,dtype=float).unsqueeze(1)\n",
        "    div_term = torch.exp(\n",
        "        torch.arange(0, embedding_dim, 2).float()\n",
        "        * (-torch.log(torch.tensor(10000.0))/embedding_dim)\n",
        "    )\n",
        "    pe[:,0::2] = torch.sin(position * div_term)\n",
        "    pe[:,1::2] = torch.cos(position, div_term)\n",
        "    pe.unsqueeze(0).transpose(0,1)\n",
        "    self.register_buffer('pe',pe)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x + self.pe[:x.size(0),:]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "IjLUvymIhn45",
        "outputId": "72379fbf-2586-4a10-81ca-74479c9daa8f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-57d03a4d32ba>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    self.Conv1_s =\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class up_conv_3D(nn.Module):\n",
        "    def __init__(self, ch_in, ch_out):\n",
        "        super(up_conv_3D, self).__init__()\n",
        "        self.up = nn.Sequential(\n",
        "            nn.Upsample(scale_factor = 2),\n",
        "            nn.Conv3d(ch_in, ch_out, kernel_size = 3, stride = 1, padding = 1, bias = True),\n",
        "            nn.GroupNorm(8, ch_out),\n",
        "            # nn.BatchNorm3d(ch_out),\n",
        "            nn.ReLU(inplace = True)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.up(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class conv_block_3D(nn.Module):\n",
        "    def __init__(self, ch_in, ch_out):\n",
        "        super(conv_block_3D, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv3d(ch_in, ch_out, kernel_size = 3, stride = 1, padding = 1, bias = True),\n",
        "            nn.GroupNorm(8, ch_out),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.Conv3d(ch_out, ch_out, kernel_size = 3, stride = 1, padding = 1, bias = True),\n",
        "            nn.GroupNorm(8, ch_out),\n",
        "            nn.ReLU(inplace = True)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class resconv_block_3D(nn.Module):\n",
        "    def __init__(self, ch_in, ch_out):\n",
        "        super(resconv_block_3D, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv3d(ch_in, ch_out, kernel_size = 3, stride = 1, padding = 1, bias = True),\n",
        "            nn.GroupNorm(8, ch_out),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.Conv3d(ch_out, ch_out, kernel_size = 3, stride = 1, padding = 1, bias = True),\n",
        "            nn.GroupNorm(8, ch_out),\n",
        "            nn.ReLU(inplace = True)\n",
        "        )\n",
        "        self.Conv_1x1 = nn.Conv3d(ch_in, ch_out, kernel_size = 1, stride = 1, padding = 0)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        residual = self.Conv_1x1(x)\n",
        "        x = self.conv(x)\n",
        "        return residual + x\n",
        "\n",
        "# Can add squeeze excitation layers if you want to try that as well.\n",
        "class ChannelSELayer3D(nn.Module):\n",
        "    \"\"\"\n",
        "    3D extension of Squeeze-and-Excitation (SE) block described in:\n",
        "        *Hu et al., Squeeze-and-Excitation Networks, arXiv:1709.01507*\n",
        "        *Zhu et al., AnatomyNet, arXiv:arXiv:1808.05238*\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_channels, reduction_ratio=8):\n",
        "        \"\"\"\n",
        "        :param num_channels: No of input channels\n",
        "        :param reduction_ratio: By how much should the num_channels should be reduced\n",
        "        \"\"\"\n",
        "        super(ChannelSELayer3D, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
        "        num_channels_reduced = num_channels // reduction_ratio\n",
        "        self.reduction_ratio = reduction_ratio\n",
        "        self.fc1 = nn.Linear(num_channels, num_channels_reduced, bias=True)\n",
        "        self.fc2 = nn.Linear(num_channels_reduced, num_channels, bias=True)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        \"\"\"\n",
        "        :param input_tensor: X, shape = (batch_size, num_channels, D, H, W)\n",
        "        :return: output tensor\n",
        "        \"\"\"\n",
        "        batch_size, num_channels, D, H, W = input_tensor.size()\n",
        "        # Average along each channel\n",
        "        squeeze_tensor = self.avg_pool(input_tensor)\n",
        "\n",
        "        # channel excitation\n",
        "        fc_out_1 = self.relu(self.fc1(squeeze_tensor.view(batch_size, num_channels)))\n",
        "        fc_out_2 = self.sigmoid(self.fc2(fc_out_1))\n",
        "\n",
        "        output_tensor = torch.mul(input_tensor, fc_out_2.view(batch_size, num_channels, 1, 1, 1))\n",
        "\n",
        "        return output_tensor\n",
        "\n",
        "class TABS(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        img_dim = 192,\n",
        "        patch_dim = 8,\n",
        "        img_ch = 1,\n",
        "        output_ch = 3,\n",
        "        embedding_dim = 512,\n",
        "        num_heads = 8,\n",
        "        num_layers = 4,\n",
        "        hidden_dim = 1728,\n",
        "        dropout_rate = 0.1,\n",
        "        attn_dropout_rate = 0.1,\n",
        "        ):\n",
        "        super(TABS,self).__init__()\n",
        "\n",
        "        self.Maxpool = nn.MaxPool3d(kernel_size=2,stride=2)\n",
        "\n",
        "        self.Conv1 = resconv_block_3D(ch_in=img_ch,ch_out=8)\n",
        "\n",
        "        self.Conv2 = resconv_block_3D(ch_in=8,ch_out=16)\n",
        "\n",
        "        self.Conv3 = resconv_block_3D(ch_in=16,ch_out=32)\n",
        "\n",
        "        self.Conv4 = resconv_block_3D(ch_in=32,ch_out=64)\n",
        "\n",
        "        self.Conv5 = resconv_block_3D(ch_in=64,ch_out=128)\n",
        "\n",
        "        self.Up5 = up_conv_3D(ch_in=128,ch_out=64)\n",
        "        self.Up_conv5 = resconv_block_3D(ch_in=128, ch_out=64)\n",
        "\n",
        "        self.Up4 = up_conv_3D(ch_in=64,ch_out=32)\n",
        "        self.Up_conv4 = resconv_block_3D(ch_in=64, ch_out=32)\n",
        "\n",
        "        self.Up3 = up_conv_3D(ch_in=32,ch_out=16)\n",
        "        self.Up_conv3 = resconv_block_3D(ch_in=32, ch_out=16)\n",
        "\n",
        "        self.Up2 = up_conv_3D(ch_in=16,ch_out=8)\n",
        "        self.Up_conv2 = resconv_block_3D(ch_in=16, ch_out=8)\n",
        "\n",
        "        self.Conv_1x1 = nn.Conv3d(8,output_ch,kernel_size=1,stride=1,padding=0)\n",
        "        self.gn = nn.GroupNorm(8, 128)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.num_patches = int((img_dim // patch_dim) ** 3)\n",
        "        self.seq_length = self.num_patches\n",
        "        self.flatten_dim = 128 * img_ch\n",
        "\n",
        "        self.position_encoding = LearnedPositionalEncoding(\n",
        "            self.seq_length, embedding_dim, self.seq_length\n",
        "        )\n",
        "\n",
        "        self.act = nn.Softmax(dim=1)\n",
        "\n",
        "        self.reshaped_conv = conv_block_3D(512, 128)\n",
        "\n",
        "        self.transformer = TransformerModel(\n",
        "            embedding_dim,\n",
        "            num_layers,\n",
        "            num_heads,\n",
        "            hidden_dim,\n",
        "\n",
        "            dropout_rate,\n",
        "            attn_dropout_rate,\n",
        "        )\n",
        "\n",
        "        self.conv_x = nn.Conv3d(\n",
        "            128,\n",
        "            embedding_dim,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1\n",
        "            )\n",
        "\n",
        "        self.pre_head_ln = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "        self.img_dim = 192\n",
        "        self.patch_dim = 8\n",
        "        self.img_ch = 1\n",
        "        self.output_ch = 3\n",
        "        self.embedding_dim = 512\n",
        "\n",
        "    def forward(self,x):\n",
        "        # encoding path\n",
        "        x1 = self.Conv1(x)\n",
        "\n",
        "        x2 = self.Maxpool(x1)\n",
        "        x2 = self.Conv2(x2)\n",
        "\n",
        "        x3 = self.Maxpool(x2)\n",
        "        x3 = self.Conv3(x3)\n",
        "\n",
        "        x4 = self.Maxpool(x3)\n",
        "        x4 = self.Conv4(x4)\n",
        "\n",
        "        x5 = self.Maxpool(x4)\n",
        "        x = self.Conv5(x5)\n",
        "\n",
        "        x = self.gn(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv_x(x)\n",
        "\n",
        "        x = x.permute(0, 2, 3, 4, 1).contiguous()\n",
        "        x = x.view(x.size(0), -1, self.embedding_dim)\n",
        "\n",
        "        x = self.position_encoding(x)\n",
        "\n",
        "        x, intmd_x = self.transformer(x)\n",
        "        x = self.pre_head_ln(x)\n",
        "\n",
        "        encoder_outputs = {}\n",
        "        all_keys = []\n",
        "        for i in [1, 2, 3, 4]:\n",
        "            val = str(2 * i - 1)\n",
        "            _key = 'Z' + str(i)\n",
        "            all_keys.append(_key)\n",
        "            encoder_outputs[_key] = intmd_x[val]\n",
        "        all_keys.reverse()\n",
        "\n",
        "        x = encoder_outputs[all_keys[0]]\n",
        "        x = self._reshape_output(x)\n",
        "        x = self.reshaped_conv(x)\n",
        "\n",
        "        d5 = self.Up5(x)\n",
        "        d5 = torch.cat((x4,d5),dim=1)\n",
        "        d5 = self.Up_conv5(d5)\n",
        "\n",
        "        d4 = self.Up4(d5)\n",
        "        d4 = torch.cat((x3,d4),dim=1)\n",
        "        d4 = self.Up_conv4(d4)\n",
        "\n",
        "        d3 = self.Up3(d4)\n",
        "        d3 = torch.cat((x2,d3),dim=1)\n",
        "        d3 = self.Up_conv3(d3)\n",
        "\n",
        "        d2 = self.Up2(d3)\n",
        "        d2 = torch.cat((x1,d2),dim=1)\n",
        "        d2 = self.Up_conv2(d2)\n",
        "\n",
        "        d1 = self.Conv_1x1(d2)\n",
        "\n",
        "        d1 = self.act(d1)\n",
        "\n",
        "        return d1\n",
        "\n",
        "    def _reshape_output(self, x):\n",
        "        x = x.view(\n",
        "            x.size(0),\n",
        "            int(self.img_dim//2 / self.patch_dim),\n",
        "            int(self.img_dim//2 / self.patch_dim),\n",
        "            int(self.img_dim//2 / self.patch_dim),\n",
        "            self.embedding_dim,\n",
        "        )\n",
        "        x = x.permute(0, 4, 1, 2, 3).contiguous()\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "MLfq9obROrbO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}