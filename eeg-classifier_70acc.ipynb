{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"gpuClass":"standard"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount(\"/content/drive\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zY3z4fGrPY0j","outputId":"b4b1b71e-3e35-462b-c095-f81f786878b1","execution":{"iopub.status.busy":"2023-04-20T02:16:15.508249Z","iopub.execute_input":"2023-04-20T02:16:15.508808Z","iopub.status.idle":"2023-04-20T02:16:15.514573Z","shell.execute_reply.started":"2023-04-20T02:16:15.508763Z","shell.execute_reply":"2023-04-20T02:16:15.513043Z"},"trusted":true},"execution_count":282,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport random\nimport scipy\nimport scipy.io as scio\nfrom scipy.signal import butter, sosfilt\nfrom scipy.stats import bernoulli\nfrom torch.utils.data import ConcatDataset, Dataset, DataLoader, random_split, RandomSampler\nimport numpy as np\n#from torchmetrics.classification import ConfusionMatrix\nfrom sklearn.metrics import confusion_matrix, accuracy_score \nfrom sklearn.preprocessing import normalize\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#from Models.Transformer import TransformerModel\n#from Models.PositionalEncoding import LearnedPositionalEncoding\n","metadata":{"id":"yhOLV8UPTrKb","execution":{"iopub.status.busy":"2023-04-20T02:16:15.528932Z","iopub.execute_input":"2023-04-20T02:16:15.529388Z","iopub.status.idle":"2023-04-20T02:16:15.538885Z","shell.execute_reply.started":"2023-04-20T02:16:15.529343Z","shell.execute_reply":"2023-04-20T02:16:15.537574Z"},"trusted":true},"execution_count":283,"outputs":[]},{"cell_type":"code","source":"# pip install oct2py\n#!apt-get install octave -y","metadata":{"execution":{"iopub.status.busy":"2023-04-20T02:16:15.547166Z","iopub.execute_input":"2023-04-20T02:16:15.548018Z","iopub.status.idle":"2023-04-20T02:16:15.553103Z","shell.execute_reply.started":"2023-04-20T02:16:15.547978Z","shell.execute_reply":"2023-04-20T02:16:15.551790Z"},"trusted":true},"execution_count":284,"outputs":[]},{"cell_type":"code","source":"if (not(os.path.isdir('./EEGPT_Models'))):\n    os.makedirs('./EEGPT_Models')","metadata":{"execution":{"iopub.status.busy":"2023-04-20T02:16:15.565747Z","iopub.execute_input":"2023-04-20T02:16:15.566124Z","iopub.status.idle":"2023-04-20T02:16:15.572181Z","shell.execute_reply.started":"2023-04-20T02:16:15.566086Z","shell.execute_reply":"2023-04-20T02:16:15.570780Z"},"trusted":true},"execution_count":285,"outputs":[]},{"cell_type":"code","source":"# CHECK GPU RESOURCES\ncuda = torch.cuda.is_available()\nprint(\"GPU available:\", cuda)\n\ntorch.manual_seed(4460)# you don't have to set random seed beyond this block\nnp.random.seed(4460)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ue7yaBP0kCW-","outputId":"81ec6b0e-0bfd-4e96-d60c-a3475b504e12","execution":{"iopub.status.busy":"2023-04-20T02:16:15.582402Z","iopub.execute_input":"2023-04-20T02:16:15.583041Z","iopub.status.idle":"2023-04-20T02:16:15.590552Z","shell.execute_reply.started":"2023-04-20T02:16:15.583003Z","shell.execute_reply":"2023-04-20T02:16:15.589268Z"},"trusted":true},"execution_count":286,"outputs":[{"name":"stdout","text":"GPU available: True\n","output_type":"stream"}]},{"cell_type":"code","source":"os.listdir()","metadata":{"execution":{"iopub.status.busy":"2023-04-20T02:16:15.598952Z","iopub.execute_input":"2023-04-20T02:16:15.599324Z","iopub.status.idle":"2023-04-20T02:16:15.608017Z","shell.execute_reply.started":"2023-04-20T02:16:15.599263Z","shell.execute_reply":"2023-04-20T02:16:15.606688Z"},"trusted":true},"execution_count":287,"outputs":[{"execution_count":287,"output_type":"execute_result","data":{"text/plain":"['EEGPT_Models', '.virtual_documents', '__notebook_source__.ipynb']"},"metadata":{}}]},{"cell_type":"code","source":"datatype = 'eeg'","metadata":{"execution":{"iopub.status.busy":"2023-04-20T02:16:15.617922Z","iopub.execute_input":"2023-04-20T02:16:15.618374Z","iopub.status.idle":"2023-04-20T02:16:15.623607Z","shell.execute_reply.started":"2023-04-20T02:16:15.618335Z","shell.execute_reply":"2023-04-20T02:16:15.622336Z"},"trusted":true},"execution_count":288,"outputs":[]},{"cell_type":"code","source":"if datatype == 'eeg':\n    sub01 = scio.loadmat('/kaggle/input/eeg-tensors/Signal_Processing_FC/Subject_1.mat')\n    sub02 = scio.loadmat('/kaggle/input/eeg-tensors/Signal_Processing_FC/Subject_2.mat')\n    sub03 = scio.loadmat('/kaggle/input/eeg-tensors/Signal_Processing_FC/Subject_3.mat')\n    sub04 = scio.loadmat('/kaggle/input/eeg-tensors/Signal_Processing_FC/Subject_4.mat')\n    sub05 = scio.loadmat('/kaggle/input/eeg-tensors/Signal_Processing_FC/Subject_5.mat')\n    # sub06 = scio.loadmat('/content/drive/MyDrive/Columbia Spring 2023/Signal Modeling/Project-EEG-Classifier/Signal_Processing_FC/Signal_Processing_FC/Subject_6.mat')\n    sub07 = scio.loadmat('/kaggle/input/eeg-tensors/Signal_Processing_FC/Subject_7.mat')\n    sub08 = scio.loadmat('/kaggle/input/eeg-tensors/Signal_Processing_FC/Subject_8.mat')\n    # data = {'sub01':sub01,'sub02':sub02,'sub03':sub03,'sub04':sub04,'sub05':sub05,'sub06':sub06,'sub07':sub07,'sub08':sub08}\n    data = {'sub01':sub01,'sub02':sub02,'sub03':sub03,'sub04':sub04,'sub05':sub05,'sub07':sub07,'sub08':sub08}\nelif datatype == 'ica':\n    sub01 = scio.loadmat('/kaggle/input/eeg-ica-data-ii/ICA_EEG_Data/sub01.mat')\n    sub02 = scio.loadmat('/kaggle/input/eeg-ica-data-ii/ICA_EEG_Data/sub02.mat')\n    sub03 = scio.loadmat('/kaggle/input/eeg-ica-data-ii/ICA_EEG_Data/sub03.mat')\n    sub04 = scio.loadmat('/kaggle/input/eeg-ica-data-ii/ICA_EEG_Data/sub04.mat')\n    sub05 = scio.loadmat('/kaggle/input/eeg-ica-data-ii/ICA_EEG_Data/sub05.mat')\n    sub06 = scio.loadmat('/kaggle/input/eeg-ica-data-ii/ICA_EEG_Data/sub06.mat')\n    sub07 = scio.loadmat('/kaggle/input/eeg-ica-data-ii/ICA_EEG_Data/sub07.mat')\n    sub08 = scio.loadmat('/kaggle/input/eeg-ica-data-ii/ICA_EEG_Data/sub08.mat')\n    data = {'sub01':sub01,'sub02':sub02,'sub03':sub03,'sub04':sub04,'sub05':sub05,'sub06':sub06,'sub07':sub07,'sub08':sub08}","metadata":{"id":"lUT0FtKqgNPP","execution":{"iopub.status.busy":"2023-04-20T02:16:15.630524Z","iopub.execute_input":"2023-04-20T02:16:15.630895Z","iopub.status.idle":"2023-04-20T02:16:18.112679Z","shell.execute_reply.started":"2023-04-20T02:16:15.630860Z","shell.execute_reply":"2023-04-20T02:16:18.111351Z"},"trusted":true},"execution_count":289,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EEGData():\n  def __init__(self, samples, labels):\n    self.X = samples\n    self.Y = labels\n    self.indices = list(range(np.size(self.Y,0)))\n  def __getitem__(self, index):\n    eegTensor = X[index]\n    label = Y[index]    \n    sample = {'eeg' : eegTensor,\n              'label' : label}\n    return sample\n    #return self.x[self.indices[index]], self.y[self.indices[index]]\n  def shuffle(self):\n    random.shuffle(self.indices)\n  def __len__(self):\n    return (np.size(self.Y,0))","metadata":{"id":"CvUVk_oEw4CR","execution":{"iopub.status.busy":"2023-04-20T02:16:18.115161Z","iopub.execute_input":"2023-04-20T02:16:18.115695Z","iopub.status.idle":"2023-04-20T02:16:18.124120Z","shell.execute_reply.started":"2023-04-20T02:16:18.115648Z","shell.execute_reply":"2023-04-20T02:16:18.122971Z"},"trusted":true},"execution_count":290,"outputs":[]},{"cell_type":"code","source":"class EEGPT(nn.Module):\n  def __init__(\n      self,\n      eeg_channels = 60,\n      time_len = 1200\n               ):\n    super(EEGPT,self).__init__()\n    # BUILD SPATIAL PATH\n    ## CNN MODULE\n    self.Conv1_s = nn.Conv1d(in_channels=eeg_channels, out_channels=eeg_channels, kernel_size=16, stride=1, padding=\"same\")\n    self.AvgPool1_s = nn.AvgPool1d(kernel_size=4,stride=4)\n    self.Conv2_s = nn.Conv1d(in_channels=eeg_channels,out_channels=eeg_channels,kernel_size=10,stride=1,padding=\"same\")\n    self.AvgPool2_s = nn.AvgPool1d(kernel_size=4,stride=4)\n    self.Conv3_s = nn.Conv1d(in_channels=eeg_channels,out_channels=eeg_channels,kernel_size=9,stride=1,padding=\"same\")\n    self.AvgPool3_s = nn.AvgPool1d(kernel_size=4,stride=4)\n    self.Conv4_s = nn.Conv1d(in_channels=eeg_channels,out_channels=eeg_channels,kernel_size=9,stride=1,padding=\"valid\")\n    ## TRANSFORMER MODULE\n    self.PosEnc1_s = PositionalEncoder(embedding_dim=10,max_length=1000)\n    self.Transf1_s = EncoderTransformer(inSize=10,outSize=5,numLayers=10,hiddenSize=10,numHeads=10,dropout=0.001)\n\n    # BUILD TEMPORAL PATH\n    # CNN MODULE\n    self.dwconv1_t = nn.Conv1d(in_channels=eeg_channels,out_channels=eeg_channels, kernel_size=eeg_channels, stride=1, groups = eeg_channels, bias=True, padding=\"same\")\n    self.AvgPool1_t = nn.AvgPool2d(kernel_size=(2,1)) \n    self.conv2_t = nn.Conv1d(in_channels=eeg_channels//2,out_channels=eeg_channels//2, kernel_size=3, stride=1, bias = False, padding='same')\n    self.AvgPool2_t = nn.AvgPool2d(kernel_size=(2,1)) \n    # TRANSFORMER MODULE\n    self.PosEnc1_t = PositionalEncoder(embedding_dim=30,max_length=1500)\n    self.Transf1_t = EncoderTransformer(inSize=30,outSize=5,numLayers=5,hiddenSize=5,numHeads=5,dropout=0.001)\n    # Build Fully Connected Path\n    if datatype == 'eeg':\n        self.fc1 = nn.Linear(1260,1)\n    elif datatype == 'ica':\n        self.fc1 = nn.Linear(1220,1)\n        \n\n  def forward(self, x):\n    # Spatial Pass\n    \n    x = x.to(torch.float32)\n    #print('x: ',x.shape)\n    x_s = self.Conv1_s(x)\n    #print('x conv1: ',x_s.shape)\n    x_s = self.AvgPool1_s(x_s)\n    #print('x avg1: ',x_s.shape)\n    x_s = self.Conv2_s(x_s)\n    #print('x conv2: ',x_s.shape)\n    x_s = self.AvgPool2_s(x_s)\n    #print('x avg2: ',x_s.shape)\n    x_s = self.Conv3_s(x_s)\n    #print('x conv3: ',x_s.shape)\n    x_s = self.AvgPool3_s(x_s)\n    x_s = self.Conv4_s(x_s)\n    x_s = self.PosEnc1_s(x_s)\n    x_s = self.Transf1_s(x_s)\n    #print('x_s_transf: ', x_s.shape)\n    \n    # Temporal Pass\n    x_t = self.dwconv1_t(x)\n    #print('x_t conv1: ',x_t.shape)\n    x_t = self.AvgPool1_t(x_t)\n    #print('x_t avg1: ',x_t.shape)\n    #x_t = self.conv2_t(x_t)\n    #print('x_t conv2: ',x_t.shape)\n    #x_t = self.AvgPool2_t(x_t)\n    #print('x_t avg2: ',x_t.shape)\n    x_t = x_t.permute(0,2,1) # transpose to present time wise vectors to transformer encoder\n    #print('x_t avg1_permute: ',x_t.shape)    \n    x_t = self.PosEnc1_t(x_t)\n    x_t = self.Transf1_t(x_t)\n    #print('x_t_transf: ', x_t.shape)\n    \n    # Concatenation\n    x_s = x_s.permute(0,2,1)\n    x_t = x_t.permute(0,2,1)\n    #print('x_t transf1_perm: ',x_t.shape)\n    #print('x_s transf1_perm: ',x_s.shape)\n    x_cat = torch.cat((x_s, x_t),dim=2)\n    # Output Pass: Fully Connected into Softmax\n    #print('x cat: ',x_cat.shape)\n    x = self.fc1(x_cat)\n    #print('x fc1: ',x.shape)\n    x = torch.log_softmax(x,dim=1)\n    #print('x softmax: ',x.shape)\n    return x\n\nclass EncoderTransformer(nn.Module):\n  def __init__(self, inSize, outSize, numLayers=3, hiddenSize=1, numHeads=8, dropout=0.01):\n    super(EncoderTransformer,self).__init__()\n    self.encoderLayer = nn.TransformerEncoderLayer(d_model=inSize, nhead=numHeads, dim_feedforward=hiddenSize, dropout=dropout)\n    self.encoder = nn.TransformerEncoder(self.encoderLayer,num_layers=numLayers)\n    self.fc1 = nn.Linear(inSize, outSize)\n  def forward(self, x):\n    x = self.encoder(x)\n    x = self.fc1(x)\n    return x\n\n## CHECK HERE !\nclass PositionalEncoder(nn.Module):\n  def __init__(self, embedding_dim, max_length=1000):\n    super(PositionalEncoder,self).__init__()\n    pe = torch.zeros(max_length, embedding_dim)\n    position = torch.arange(0, max_length,dtype=float).unsqueeze(1)\n    div_term = torch.exp(\n        torch.arange(0, embedding_dim, 2).float()\n        * (-torch.log(torch.tensor(10000.0))/embedding_dim)\n    )\n    pe[:,0::2] = torch.sin(position * div_term)\n    pe[:,1::2] = torch.cos(position * div_term)\n    pe.unsqueeze(0).transpose(0,1)\n    self.register_buffer('pe',pe)\n\n  def forward(self, x):\n    #print(self.pe[:x.size(1)].shape)\n    return x + self.pe[:x.size(1),:]\n\n","metadata":{"id":"IjLUvymIhn45","execution":{"iopub.status.busy":"2023-04-20T02:16:18.126059Z","iopub.execute_input":"2023-04-20T02:16:18.126745Z","iopub.status.idle":"2023-04-20T02:16:18.153259Z","shell.execute_reply.started":"2023-04-20T02:16:18.126704Z","shell.execute_reply":"2023-04-20T02:16:18.152049Z"},"trusted":true},"execution_count":291,"outputs":[]},{"cell_type":"code","source":"# PREPROCESSING FUNCTIONS\n#tensor = subx\n#print(np.shape(subx))\nclass AddGaussNoise(object):\n    def __init__(self, std, mean, p):\n        self.std = std\n        self.mean = mean\n        self.prob = p # tune probability controlling fraction of dataset this augmentation will be applied to\n    def __call__(self, tensor):\n        #return img + torch.randn_like(img)*std + mean\n        bern_rv = bernoulli.rvs(self.prob)\n        if bern_rv == 1:\n            ret_tensor = tensor + np.random.randn(np.shape(tensor)[0],np.shape(tensor)[1])*self.std + self.mean\n        else:\n            ret_tensor = tensor                \n        return ret_tensor \n\ndef mas2565_normalize(tensor):\n    # normalizes a 60 x 1200 tensor, time wise\n    normal_tensor = normalize(tensor,axis=1,norm='l2')\n    return normal_tensor\ndef mas2565_filter(tensor):\n    Fs = 1000\n    lowcut = 0.5\n    highcut = 40\n    order = 4\n    nyq = 0.5*Fs\n    low = lowcut/nyq\n    high = highcut/nyq\n    sos = butter(order, [low, high], btype='band',output='sos')\n    filtered_tensor = sosfilt(sos, tensor, axis=1)\n    return filtered_tensor\n#print(np.shape(mas2565_normalize(tensor)))\n\ndef mas2565_ICA(tensor):\n    pass\n    #return ICA_tensor","metadata":{"execution":{"iopub.status.busy":"2023-04-20T02:16:18.158593Z","iopub.execute_input":"2023-04-20T02:16:18.159139Z","iopub.status.idle":"2023-04-20T02:16:18.171091Z","shell.execute_reply.started":"2023-04-20T02:16:18.159087Z","shell.execute_reply":"2023-04-20T02:16:18.169963Z"},"trusted":true},"execution_count":292,"outputs":[]},{"cell_type":"code","source":"#print(data['sub01']['X_EEG_TRAIN'])","metadata":{"execution":{"iopub.status.busy":"2023-04-20T02:16:18.172437Z","iopub.execute_input":"2023-04-20T02:16:18.172915Z","iopub.status.idle":"2023-04-20T02:16:18.184750Z","shell.execute_reply.started":"2023-04-20T02:16:18.172878Z","shell.execute_reply":"2023-04-20T02:16:18.183666Z"},"trusted":true},"execution_count":293,"outputs":[]},{"cell_type":"code","source":"# COMPOSE MEGA DATASET FROM ALL SUBJECT TENSORS\nnumSets = 8\nX = []\nY = []\nID = []\nfor i in range(numSets):\n    if i != 5:\n        subSetX = data[('sub0'+str(i+1))]['X_EEG_TRAIN']\n        subSetY = data[('sub0'+str(i+1))]['Y_EEG_TRAIN']\n  #print(np.size(subSetY,0))\n    for j in range(np.size(subSetY,0)):   \n        #print(np.shape(subSetX)[])\n        subx = subSetX[:,:,j]\n\n        #subx = mas2565_ICA(subx)\n        subx = mas2565_normalize(subx)\n        subx = mas2565_filter(subx)\n\n        #noise = AddGaussNoise(50,0,0.7) # noise augmentation\n        #subx = noise(subx)\n        subx = torch.Tensor(subx)\n        #subx = mas2565_filter(subx)\n        #print(np.shape(subx))\n        suby = subSetY[j,:]\n        # miniSet = EEGData(subx,suby)\n        # print(np.shape(miniSet.y))\n        X.append(subx)\n        Y.append(suby)\n\n\n        # DEBUGGING PRINTS\n        #print(np.size(subSetY,0))\n        #print(np.shape(subSetX))\n        #print(np.shape(subSetY))\n        #print(miniSet.__len__())\n\n#MegaSet = ConcatDataset(megaSet)\n#print(np.shape((MegaSet).x))\n#MegaSet = RandomSampler(MegaSet)\n#print(np.shape(X))\n#print(np.shape(Y[1]))\n\nmyEEG = EEGData(X,Y)\n\n# Load Dataset using EEGData and Dataloader\ntrainset, validset, testset = random_split(myEEG,[0.5, 0.25, 0.25])\ntrainloader = DataLoader(trainset,batch_size=3,shuffle=True)\nvalidloader = DataLoader(validset,batch_size=3,shuffle=True)\ntestloader = DataLoader(testset, batch_size =1, shuffle=True)","metadata":{"id":"2tat7z1h7fPw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"48b710ee-f7b9-417c-b27a-0eb1a60b8946","execution":{"iopub.status.busy":"2023-04-20T02:16:18.186217Z","iopub.execute_input":"2023-04-20T02:16:18.187314Z","iopub.status.idle":"2023-04-20T02:16:19.695431Z","shell.execute_reply.started":"2023-04-20T02:16:18.187255Z","shell.execute_reply":"2023-04-20T02:16:19.694337Z"},"trusted":true},"execution_count":294,"outputs":[]},{"cell_type":"code","source":"# Build/Instantiate Model\neegpt = EEGPT(eeg_channels=60, time_len=1200)\nif cuda:\n  eegpt.cuda()\n\n# Call Optimizer\nadam = Adam(eegpt.parameters(),lr=0.00005)","metadata":{"id":"u8WNB1li-GX0","execution":{"iopub.status.busy":"2023-04-20T02:16:19.697271Z","iopub.execute_input":"2023-04-20T02:16:19.698176Z","iopub.status.idle":"2023-04-20T02:16:19.734894Z","shell.execute_reply.started":"2023-04-20T02:16:19.698129Z","shell.execute_reply":"2023-04-20T02:16:19.733883Z"},"trusted":true},"execution_count":295,"outputs":[]},{"cell_type":"code","source":"# COUNT MODEL PARAMETERS\nparam_count = 0;\nfor param in eegpt.parameters():\n    param_count += param.numel()\n\nprint('number of model params: ', param_count)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V_dPdRf_hV-m","outputId":"0c4744ed-0b2f-41d4-d3b0-6a09563a2318","execution":{"iopub.status.busy":"2023-04-20T02:16:19.737095Z","iopub.execute_input":"2023-04-20T02:16:19.737503Z","iopub.status.idle":"2023-04-20T02:16:19.745743Z","shell.execute_reply.started":"2023-04-20T02:16:19.737464Z","shell.execute_reply":"2023-04-20T02:16:19.744658Z"},"trusted":true},"execution_count":296,"outputs":[{"name":"stdout","text":"number of model params:  199221\n","output_type":"stream"}]},{"cell_type":"code","source":"# MODEL TRAINING\nEPOCHS = 50\ntrain_epoch_loss = list()\nvalidation_epoch_loss = list()\nfor epoch in range(EPOCHS):\n  train_loss = list()\n  valid_loss = list()\n  eegpt.train() # put model in train mode\n  for i, sample in enumerate(trainloader):\n    eegTensor = sample['eeg']\n    #print(np.shape(eegTensor))\n    label = sample['label']\n    #print('label shape: ',np.shape(label))\n    #print('sample: ', sample)\n    if cuda:\n      train_pred = eegpt(eegTensor.cuda())\n      # print('pred shape: ', train_pred.shape)\n      # calculate loss\n      loss_fun = nn.CrossEntropyLoss()\n      loss = loss_fun(train_pred, label.cuda().long())\n      train_loss.append(loss.cpu().data.item())\n      # reset gradient\n      adam.zero_grad()\n      # back propagation\n      loss.backward()\n      # Update parameters\n      adam.step()\n      #print('epoch: ', epoch, ' loss: ', loss.item())\n      \n      #print(f'EPOCH {epoch + 1}/{EPOCHS} - Training Batch {i+1}/{len(trainloader)} - Loss: {loss.item()}', end='\\r')\n  eegpt.eval()\n  for i, samples in enumerate(validloader):\n    eegTensor = sample['eeg']\n    #print(np.shape(eegTensor))\n    label = sample['label']\n    #print(np.shape(label))\n    #print('sample: ', sample)\n    if cuda:\n      valid_pred = eegpt(eegTensor.cuda())\n      # calculate loss\n      loss_fun = nn.CrossEntropyLoss()\n      loss = loss_fun(train_pred, label.cuda().long())\n      valid_loss.append(loss.cpu().data.item())\n      \n  train_epoch_loss.append(np.mean(train_loss))\n  validation_epoch_loss.append(np.mean(valid_loss))\n  print(\"Epoch: {} | train_loss: {} | validation_loss: {}\".format(epoch, train_epoch_loss[-1], validation_epoch_loss[-1]))\n  # print(\"Epoch: {} | train_loss: {}\".format(epoch, train_epoch_loss[-1]))\n  torch.save(eegpt.state_dict(), '/kaggle/working/EEGPT_Models/checkpoint_epoch_%s.pth' % (epoch))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":305},"id":"79_uGinHjAXm","outputId":"631006fb-42d7-4895-b1f7-350db5497e1a","execution":{"iopub.status.busy":"2023-04-20T02:16:19.747372Z","iopub.execute_input":"2023-04-20T02:16:19.748052Z","iopub.status.idle":"2023-04-20T02:20:30.675223Z","shell.execute_reply.started":"2023-04-20T02:16:19.748011Z","shell.execute_reply":"2023-04-20T02:20:30.673973Z"},"trusted":true},"execution_count":297,"outputs":[{"name":"stdout","text":"Epoch: 0 | train_loss: 1.242924101029833 | validation_loss: 1.0655012130737305\nEpoch: 1 | train_loss: 0.7520555822799603 | validation_loss: 0.7064177989959717\nEpoch: 2 | train_loss: 0.7094460055232048 | validation_loss: 0.6435794830322266\nEpoch: 3 | train_loss: 0.708942661061883 | validation_loss: 0.9160548448562622\nEpoch: 4 | train_loss: 0.6844685400525728 | validation_loss: 0.5409901142120361\nEpoch: 5 | train_loss: 0.652517102037867 | validation_loss: 0.6113303303718567\nEpoch: 6 | train_loss: 0.6546363836775223 | validation_loss: 0.6247109174728394\nEpoch: 7 | train_loss: 0.6424981883416573 | validation_loss: 0.3523094654083252\nEpoch: 8 | train_loss: 0.6229286889235178 | validation_loss: 0.3047337532043457\nEpoch: 9 | train_loss: 0.6270574832645556 | validation_loss: 0.6568162441253662\nEpoch: 10 | train_loss: 0.622372696797053 | validation_loss: 0.23361462354660034\nEpoch: 11 | train_loss: 0.5892345396180948 | validation_loss: 1.336463451385498\nEpoch: 12 | train_loss: 0.5706042600795627 | validation_loss: 0.20102038979530334\nEpoch: 13 | train_loss: 0.5667909174226224 | validation_loss: 1.322447419166565\nEpoch: 14 | train_loss: 0.5379097807841996 | validation_loss: 0.3253859281539917\nEpoch: 15 | train_loss: 0.5386498323641717 | validation_loss: 0.23966144025325775\nEpoch: 16 | train_loss: 0.528404085819299 | validation_loss: 0.1491570621728897\nEpoch: 17 | train_loss: 0.5182399122665325 | validation_loss: 0.3862427771091461\nEpoch: 18 | train_loss: 0.503632050473243 | validation_loss: 0.5509366989135742\nEpoch: 19 | train_loss: 0.4919925034822275 | validation_loss: 0.34104305505752563\nEpoch: 20 | train_loss: 0.48251303456102806 | validation_loss: 0.1669415682554245\nEpoch: 21 | train_loss: 0.452392430898423 | validation_loss: 0.16536001861095428\nEpoch: 22 | train_loss: 0.45993016225596267 | validation_loss: 0.5844729542732239\nEpoch: 23 | train_loss: 0.45092845110533136 | validation_loss: 0.141989067196846\nEpoch: 24 | train_loss: 0.4477660667616874 | validation_loss: 0.11886804550886154\nEpoch: 25 | train_loss: 0.445084932881097 | validation_loss: 0.5951851606369019\nEpoch: 26 | train_loss: 0.4403245407932748 | validation_loss: 0.6527309417724609\nEpoch: 27 | train_loss: 0.4209150987832497 | validation_loss: 0.16107146441936493\nEpoch: 28 | train_loss: 0.4269613219657913 | validation_loss: 0.1657809615135193\nEpoch: 29 | train_loss: 0.40867921997172135 | validation_loss: 0.16109420359134674\nEpoch: 30 | train_loss: 0.4159622020088136 | validation_loss: 0.7568787336349487\nEpoch: 31 | train_loss: 0.40102023965058226 | validation_loss: 0.09867566078901291\nEpoch: 32 | train_loss: 0.39957061188761145 | validation_loss: 0.25057581067085266\nEpoch: 33 | train_loss: 0.38832198417124647 | validation_loss: 0.3402767777442932\nEpoch: 34 | train_loss: 0.3782378851125638 | validation_loss: 0.5206825137138367\nEpoch: 35 | train_loss: 0.3691558700520545 | validation_loss: 0.08379781991243362\nEpoch: 36 | train_loss: 0.376655353892905 | validation_loss: 1.895809292793274\nEpoch: 37 | train_loss: 0.3516068145399913 | validation_loss: 0.23411430418491364\nEpoch: 38 | train_loss: 0.3540664045140147 | validation_loss: 0.21087318658828735\nEpoch: 39 | train_loss: 0.3296117106607805 | validation_loss: 0.10366912931203842\nEpoch: 40 | train_loss: 0.3321807984029874 | validation_loss: 0.07207272201776505\nEpoch: 41 | train_loss: 0.32025847540353425 | validation_loss: 0.1805008053779602\nEpoch: 42 | train_loss: 0.31693833201037097 | validation_loss: 0.06312348693609238\nEpoch: 43 | train_loss: 0.3138077645562589 | validation_loss: 0.8728173971176147\nEpoch: 44 | train_loss: 0.2980826871547227 | validation_loss: 0.18604442477226257\nEpoch: 45 | train_loss: 0.29183549695881084 | validation_loss: 0.10287600755691528\nEpoch: 46 | train_loss: 0.2811006047219659 | validation_loss: 0.10516120493412018\nEpoch: 47 | train_loss: 0.27246687138297904 | validation_loss: 0.3490244448184967\nEpoch: 48 | train_loss: 0.2677709413401317 | validation_loss: 0.0410955473780632\nEpoch: 49 | train_loss: 0.25923893144742277 | validation_loss: 0.2072194367647171\n","output_type":"stream"}]},{"cell_type":"code","source":"# BEST EPOCH\nbest_epoch = np.argmin(validation_epoch_loss)\nprint('best epoch: ', best_epoch)\n\n# LOAD BEST MODEL\nstate_dict = torch.load('/kaggle/working/EEGPT_Models/checkpoint_epoch_%s.pth' % (best_epoch))\nprint(state_dict.keys())\neegpt.load_state_dict(state_dict)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jN5zN2vCXeVD","outputId":"5af53d39-727c-4d01-ecc5-c8e4bb86d42f","execution":{"iopub.status.busy":"2023-04-20T02:20:30.679465Z","iopub.execute_input":"2023-04-20T02:20:30.681578Z","iopub.status.idle":"2023-04-20T02:20:30.728194Z","shell.execute_reply.started":"2023-04-20T02:20:30.681533Z","shell.execute_reply":"2023-04-20T02:20:30.726973Z"},"trusted":true},"execution_count":298,"outputs":[{"name":"stdout","text":"best epoch:  48\nodict_keys(['Conv1_s.weight', 'Conv1_s.bias', 'Conv2_s.weight', 'Conv2_s.bias', 'Conv3_s.weight', 'Conv3_s.bias', 'Conv4_s.weight', 'Conv4_s.bias', 'PosEnc1_s.pe', 'Transf1_s.encoderLayer.self_attn.in_proj_weight', 'Transf1_s.encoderLayer.self_attn.in_proj_bias', 'Transf1_s.encoderLayer.self_attn.out_proj.weight', 'Transf1_s.encoderLayer.self_attn.out_proj.bias', 'Transf1_s.encoderLayer.linear1.weight', 'Transf1_s.encoderLayer.linear1.bias', 'Transf1_s.encoderLayer.linear2.weight', 'Transf1_s.encoderLayer.linear2.bias', 'Transf1_s.encoderLayer.norm1.weight', 'Transf1_s.encoderLayer.norm1.bias', 'Transf1_s.encoderLayer.norm2.weight', 'Transf1_s.encoderLayer.norm2.bias', 'Transf1_s.encoder.layers.0.self_attn.in_proj_weight', 'Transf1_s.encoder.layers.0.self_attn.in_proj_bias', 'Transf1_s.encoder.layers.0.self_attn.out_proj.weight', 'Transf1_s.encoder.layers.0.self_attn.out_proj.bias', 'Transf1_s.encoder.layers.0.linear1.weight', 'Transf1_s.encoder.layers.0.linear1.bias', 'Transf1_s.encoder.layers.0.linear2.weight', 'Transf1_s.encoder.layers.0.linear2.bias', 'Transf1_s.encoder.layers.0.norm1.weight', 'Transf1_s.encoder.layers.0.norm1.bias', 'Transf1_s.encoder.layers.0.norm2.weight', 'Transf1_s.encoder.layers.0.norm2.bias', 'Transf1_s.encoder.layers.1.self_attn.in_proj_weight', 'Transf1_s.encoder.layers.1.self_attn.in_proj_bias', 'Transf1_s.encoder.layers.1.self_attn.out_proj.weight', 'Transf1_s.encoder.layers.1.self_attn.out_proj.bias', 'Transf1_s.encoder.layers.1.linear1.weight', 'Transf1_s.encoder.layers.1.linear1.bias', 'Transf1_s.encoder.layers.1.linear2.weight', 'Transf1_s.encoder.layers.1.linear2.bias', 'Transf1_s.encoder.layers.1.norm1.weight', 'Transf1_s.encoder.layers.1.norm1.bias', 'Transf1_s.encoder.layers.1.norm2.weight', 'Transf1_s.encoder.layers.1.norm2.bias', 'Transf1_s.encoder.layers.2.self_attn.in_proj_weight', 'Transf1_s.encoder.layers.2.self_attn.in_proj_bias', 'Transf1_s.encoder.layers.2.self_attn.out_proj.weight', 'Transf1_s.encoder.layers.2.self_attn.out_proj.bias', 'Transf1_s.encoder.layers.2.linear1.weight', 'Transf1_s.encoder.layers.2.linear1.bias', 'Transf1_s.encoder.layers.2.linear2.weight', 'Transf1_s.encoder.layers.2.linear2.bias', 'Transf1_s.encoder.layers.2.norm1.weight', 'Transf1_s.encoder.layers.2.norm1.bias', 'Transf1_s.encoder.layers.2.norm2.weight', 'Transf1_s.encoder.layers.2.norm2.bias', 'Transf1_s.encoder.layers.3.self_attn.in_proj_weight', 'Transf1_s.encoder.layers.3.self_attn.in_proj_bias', 'Transf1_s.encoder.layers.3.self_attn.out_proj.weight', 'Transf1_s.encoder.layers.3.self_attn.out_proj.bias', 'Transf1_s.encoder.layers.3.linear1.weight', 'Transf1_s.encoder.layers.3.linear1.bias', 'Transf1_s.encoder.layers.3.linear2.weight', 'Transf1_s.encoder.layers.3.linear2.bias', 'Transf1_s.encoder.layers.3.norm1.weight', 'Transf1_s.encoder.layers.3.norm1.bias', 'Transf1_s.encoder.layers.3.norm2.weight', 'Transf1_s.encoder.layers.3.norm2.bias', 'Transf1_s.encoder.layers.4.self_attn.in_proj_weight', 'Transf1_s.encoder.layers.4.self_attn.in_proj_bias', 'Transf1_s.encoder.layers.4.self_attn.out_proj.weight', 'Transf1_s.encoder.layers.4.self_attn.out_proj.bias', 'Transf1_s.encoder.layers.4.linear1.weight', 'Transf1_s.encoder.layers.4.linear1.bias', 'Transf1_s.encoder.layers.4.linear2.weight', 'Transf1_s.encoder.layers.4.linear2.bias', 'Transf1_s.encoder.layers.4.norm1.weight', 'Transf1_s.encoder.layers.4.norm1.bias', 'Transf1_s.encoder.layers.4.norm2.weight', 'Transf1_s.encoder.layers.4.norm2.bias', 'Transf1_s.encoder.layers.5.self_attn.in_proj_weight', 'Transf1_s.encoder.layers.5.self_attn.in_proj_bias', 'Transf1_s.encoder.layers.5.self_attn.out_proj.weight', 'Transf1_s.encoder.layers.5.self_attn.out_proj.bias', 'Transf1_s.encoder.layers.5.linear1.weight', 'Transf1_s.encoder.layers.5.linear1.bias', 'Transf1_s.encoder.layers.5.linear2.weight', 'Transf1_s.encoder.layers.5.linear2.bias', 'Transf1_s.encoder.layers.5.norm1.weight', 'Transf1_s.encoder.layers.5.norm1.bias', 'Transf1_s.encoder.layers.5.norm2.weight', 'Transf1_s.encoder.layers.5.norm2.bias', 'Transf1_s.encoder.layers.6.self_attn.in_proj_weight', 'Transf1_s.encoder.layers.6.self_attn.in_proj_bias', 'Transf1_s.encoder.layers.6.self_attn.out_proj.weight', 'Transf1_s.encoder.layers.6.self_attn.out_proj.bias', 'Transf1_s.encoder.layers.6.linear1.weight', 'Transf1_s.encoder.layers.6.linear1.bias', 'Transf1_s.encoder.layers.6.linear2.weight', 'Transf1_s.encoder.layers.6.linear2.bias', 'Transf1_s.encoder.layers.6.norm1.weight', 'Transf1_s.encoder.layers.6.norm1.bias', 'Transf1_s.encoder.layers.6.norm2.weight', 'Transf1_s.encoder.layers.6.norm2.bias', 'Transf1_s.encoder.layers.7.self_attn.in_proj_weight', 'Transf1_s.encoder.layers.7.self_attn.in_proj_bias', 'Transf1_s.encoder.layers.7.self_attn.out_proj.weight', 'Transf1_s.encoder.layers.7.self_attn.out_proj.bias', 'Transf1_s.encoder.layers.7.linear1.weight', 'Transf1_s.encoder.layers.7.linear1.bias', 'Transf1_s.encoder.layers.7.linear2.weight', 'Transf1_s.encoder.layers.7.linear2.bias', 'Transf1_s.encoder.layers.7.norm1.weight', 'Transf1_s.encoder.layers.7.norm1.bias', 'Transf1_s.encoder.layers.7.norm2.weight', 'Transf1_s.encoder.layers.7.norm2.bias', 'Transf1_s.encoder.layers.8.self_attn.in_proj_weight', 'Transf1_s.encoder.layers.8.self_attn.in_proj_bias', 'Transf1_s.encoder.layers.8.self_attn.out_proj.weight', 'Transf1_s.encoder.layers.8.self_attn.out_proj.bias', 'Transf1_s.encoder.layers.8.linear1.weight', 'Transf1_s.encoder.layers.8.linear1.bias', 'Transf1_s.encoder.layers.8.linear2.weight', 'Transf1_s.encoder.layers.8.linear2.bias', 'Transf1_s.encoder.layers.8.norm1.weight', 'Transf1_s.encoder.layers.8.norm1.bias', 'Transf1_s.encoder.layers.8.norm2.weight', 'Transf1_s.encoder.layers.8.norm2.bias', 'Transf1_s.encoder.layers.9.self_attn.in_proj_weight', 'Transf1_s.encoder.layers.9.self_attn.in_proj_bias', 'Transf1_s.encoder.layers.9.self_attn.out_proj.weight', 'Transf1_s.encoder.layers.9.self_attn.out_proj.bias', 'Transf1_s.encoder.layers.9.linear1.weight', 'Transf1_s.encoder.layers.9.linear1.bias', 'Transf1_s.encoder.layers.9.linear2.weight', 'Transf1_s.encoder.layers.9.linear2.bias', 'Transf1_s.encoder.layers.9.norm1.weight', 'Transf1_s.encoder.layers.9.norm1.bias', 'Transf1_s.encoder.layers.9.norm2.weight', 'Transf1_s.encoder.layers.9.norm2.bias', 'Transf1_s.fc1.weight', 'Transf1_s.fc1.bias', 'dwconv1_t.weight', 'dwconv1_t.bias', 'conv2_t.weight', 'PosEnc1_t.pe', 'Transf1_t.encoderLayer.self_attn.in_proj_weight', 'Transf1_t.encoderLayer.self_attn.in_proj_bias', 'Transf1_t.encoderLayer.self_attn.out_proj.weight', 'Transf1_t.encoderLayer.self_attn.out_proj.bias', 'Transf1_t.encoderLayer.linear1.weight', 'Transf1_t.encoderLayer.linear1.bias', 'Transf1_t.encoderLayer.linear2.weight', 'Transf1_t.encoderLayer.linear2.bias', 'Transf1_t.encoderLayer.norm1.weight', 'Transf1_t.encoderLayer.norm1.bias', 'Transf1_t.encoderLayer.norm2.weight', 'Transf1_t.encoderLayer.norm2.bias', 'Transf1_t.encoder.layers.0.self_attn.in_proj_weight', 'Transf1_t.encoder.layers.0.self_attn.in_proj_bias', 'Transf1_t.encoder.layers.0.self_attn.out_proj.weight', 'Transf1_t.encoder.layers.0.self_attn.out_proj.bias', 'Transf1_t.encoder.layers.0.linear1.weight', 'Transf1_t.encoder.layers.0.linear1.bias', 'Transf1_t.encoder.layers.0.linear2.weight', 'Transf1_t.encoder.layers.0.linear2.bias', 'Transf1_t.encoder.layers.0.norm1.weight', 'Transf1_t.encoder.layers.0.norm1.bias', 'Transf1_t.encoder.layers.0.norm2.weight', 'Transf1_t.encoder.layers.0.norm2.bias', 'Transf1_t.encoder.layers.1.self_attn.in_proj_weight', 'Transf1_t.encoder.layers.1.self_attn.in_proj_bias', 'Transf1_t.encoder.layers.1.self_attn.out_proj.weight', 'Transf1_t.encoder.layers.1.self_attn.out_proj.bias', 'Transf1_t.encoder.layers.1.linear1.weight', 'Transf1_t.encoder.layers.1.linear1.bias', 'Transf1_t.encoder.layers.1.linear2.weight', 'Transf1_t.encoder.layers.1.linear2.bias', 'Transf1_t.encoder.layers.1.norm1.weight', 'Transf1_t.encoder.layers.1.norm1.bias', 'Transf1_t.encoder.layers.1.norm2.weight', 'Transf1_t.encoder.layers.1.norm2.bias', 'Transf1_t.encoder.layers.2.self_attn.in_proj_weight', 'Transf1_t.encoder.layers.2.self_attn.in_proj_bias', 'Transf1_t.encoder.layers.2.self_attn.out_proj.weight', 'Transf1_t.encoder.layers.2.self_attn.out_proj.bias', 'Transf1_t.encoder.layers.2.linear1.weight', 'Transf1_t.encoder.layers.2.linear1.bias', 'Transf1_t.encoder.layers.2.linear2.weight', 'Transf1_t.encoder.layers.2.linear2.bias', 'Transf1_t.encoder.layers.2.norm1.weight', 'Transf1_t.encoder.layers.2.norm1.bias', 'Transf1_t.encoder.layers.2.norm2.weight', 'Transf1_t.encoder.layers.2.norm2.bias', 'Transf1_t.encoder.layers.3.self_attn.in_proj_weight', 'Transf1_t.encoder.layers.3.self_attn.in_proj_bias', 'Transf1_t.encoder.layers.3.self_attn.out_proj.weight', 'Transf1_t.encoder.layers.3.self_attn.out_proj.bias', 'Transf1_t.encoder.layers.3.linear1.weight', 'Transf1_t.encoder.layers.3.linear1.bias', 'Transf1_t.encoder.layers.3.linear2.weight', 'Transf1_t.encoder.layers.3.linear2.bias', 'Transf1_t.encoder.layers.3.norm1.weight', 'Transf1_t.encoder.layers.3.norm1.bias', 'Transf1_t.encoder.layers.3.norm2.weight', 'Transf1_t.encoder.layers.3.norm2.bias', 'Transf1_t.encoder.layers.4.self_attn.in_proj_weight', 'Transf1_t.encoder.layers.4.self_attn.in_proj_bias', 'Transf1_t.encoder.layers.4.self_attn.out_proj.weight', 'Transf1_t.encoder.layers.4.self_attn.out_proj.bias', 'Transf1_t.encoder.layers.4.linear1.weight', 'Transf1_t.encoder.layers.4.linear1.bias', 'Transf1_t.encoder.layers.4.linear2.weight', 'Transf1_t.encoder.layers.4.linear2.bias', 'Transf1_t.encoder.layers.4.norm1.weight', 'Transf1_t.encoder.layers.4.norm1.bias', 'Transf1_t.encoder.layers.4.norm2.weight', 'Transf1_t.encoder.layers.4.norm2.bias', 'Transf1_t.fc1.weight', 'Transf1_t.fc1.bias', 'fc1.weight', 'fc1.bias'])\n","output_type":"stream"},{"execution_count":298,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"# REPORT ACCURACY\ntest_preds = []\nlabels = []\nfor i, sample in enumerate(testloader):\n    accuracy = list()\n    eegTensor = sample['eeg']\n    #print(np.shape(eegTensor))\n    label = sample['label']\n    labels.append(label.detach().cpu().numpy())\n    #print(np.shape(labels))\n    #print(np.shape(label))\n    #print('sample: ', sample)\n    \n    #print(test_label)\n    eegpt.eval()\n    if cuda:\n        #print(eegTensor.shape)\n        test_pred = eegpt(eegTensor.cuda())\n        #print(test_pred.shape)\n        test_preds.append(test_pred.detach().cpu().numpy())\n        # tpred = test_pred.detach().numpy()\n        # tlabels = test_label.detach().numpy()\n        # tpredictions = get_predicted_labels(tpred)\n        #print(tpred)x\n        #accuracy.append(acc)\n    else:\n        pass\n    #print(np.mean(accuracy))\n    #Acc = np.mean(accuracy)\n\n# print('EEGPT accuracy: ',accuracy_score(tlabels,tpredictions)) # BUILD ACCURACY SCORE FUN\n# CONFUSION MATRIX\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vry23LqWX4Xw","outputId":"92fe40cf-10d3-4dbe-db1d-f79cd298c264","execution":{"iopub.status.busy":"2023-04-20T02:20:30.729781Z","iopub.execute_input":"2023-04-20T02:20:30.730482Z","iopub.status.idle":"2023-04-20T02:20:32.598339Z","shell.execute_reply.started":"2023-04-20T02:20:30.730427Z","shell.execute_reply":"2023-04-20T02:20:32.596844Z"},"trusted":true},"execution_count":299,"outputs":[]},{"cell_type":"code","source":"print(np.shape(labels[0]))\n# print(np.shape(test_preds[1]))\nprint(np.shape(test_preds[0]))\n# st_shap = np.shape(test_preds)\nprint(np.exp(test_preds[1][0]))\n#print(labels[2][5])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K31JgGBcfMs-","outputId":"a2f5276b-f4df-46b6-b157-1e587a0f2281","execution":{"iopub.status.busy":"2023-04-20T02:20:32.605210Z","iopub.execute_input":"2023-04-20T02:20:32.609394Z","iopub.status.idle":"2023-04-20T02:20:32.623646Z","shell.execute_reply.started":"2023-04-20T02:20:32.609342Z","shell.execute_reply":"2023-04-20T02:20:32.622208Z"},"trusted":true},"execution_count":300,"outputs":[{"name":"stdout","text":"(1, 1)\n(1, 5, 1)\n[[9.9255359e-01]\n [7.2298651e-03]\n [4.6923928e-05]\n [8.4392705e-05]\n [8.5244617e-05]]\n","output_type":"stream"}]},{"cell_type":"code","source":"pred_labels = list()\nfor i in range(np.shape(test_preds)[0]):\n    for j in range(np.shape(test_preds[i])[0]):\n        # print(np.exp(test_preds[i][1]))\n        #print(j)\n        class_pred = np.argmax(test_preds[i][j])\n        #print(class_pred)\n        pred_labels.append(class_pred) \nprint(np.shape(pred_labels))","metadata":{"execution":{"iopub.status.busy":"2023-04-20T02:20:32.625502Z","iopub.execute_input":"2023-04-20T02:20:32.626494Z","iopub.status.idle":"2023-04-20T02:20:32.643096Z","shell.execute_reply.started":"2023-04-20T02:20:32.626444Z","shell.execute_reply":"2023-04-20T02:20:32.641727Z"},"trusted":true},"execution_count":301,"outputs":[{"name":"stdout","text":"(142,)\n","output_type":"stream"}]},{"cell_type":"code","source":"true_labels = list()\nfor i in range(np.shape(labels)[0]):\n    # print(i)\n    for j in range(np.shape(test_preds[i])[0]):\n        # print(np.exp(test_preds[i][1]))\n        #print(labels[j][0])\n        #print(class_pred)\n        true_labels.append(labels[i][j]) \nprint(np.shape(true_labels))","metadata":{"execution":{"iopub.status.busy":"2023-04-20T02:20:32.644944Z","iopub.execute_input":"2023-04-20T02:20:32.646213Z","iopub.status.idle":"2023-04-20T02:20:32.664526Z","shell.execute_reply.started":"2023-04-20T02:20:32.646167Z","shell.execute_reply":"2023-04-20T02:20:32.662048Z"},"trusted":true},"execution_count":302,"outputs":[{"name":"stdout","text":"(142, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"brk = len(true_labels)\nCM = confusion_matrix(true_labels[1:brk], pred_labels[1:brk])\naccuracy = accuracy_score(true_labels[1:brk], pred_labels[1:brk])\nplt.figure(figsize = (12,10))\nsns.heatmap(CM, annot = True, annot_kws = {\"size\": 10}, fmt='d')\nplt.ylabel('True labels');\nplt.xlabel('predicted labels');\nprint('accuracy: ',accuracy)","metadata":{"id":"-JcC_9tief8C","execution":{"iopub.status.busy":"2023-04-20T02:20:32.665746Z","iopub.execute_input":"2023-04-20T02:20:32.666098Z","iopub.status.idle":"2023-04-20T02:20:33.138965Z","shell.execute_reply.started":"2023-04-20T02:20:32.666054Z","shell.execute_reply":"2023-04-20T02:20:33.137835Z"},"trusted":true},"execution_count":303,"outputs":[{"name":"stdout","text":"accuracy:  0.7021276595744681\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x1000 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAA5cAAANBCAYAAAB08krXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABEYUlEQVR4nO3de5xVdb0//vcWZAQcUESYIRVRQVHAFA3wpICKih4TtbzmrbwlXohMQzOxrzJmJ6Hy6DEtxFMK/TQv56goJwNTxC8XL4SKlCBojHhD5OIgs9fvj77NaYKFe7MG92x8Pnusx8P9WWuv9Z79hz1evt/7s3NJkiQBAAAAGWxV6gIAAAAof8IlAAAAmQmXAAAAZCZcAgAAkJlwCQAAQGbCJQAAAJkJlwAAAGQmXAIAAJCZcAkAAEBmLUtdwOaw/NTBpS4BgCbQ8f7XSl0CAE1g3dq3Sl3CJvvk3ddLXcIGbd1xt1KXsB6dSwAAADITLgEAAMhsixyLBQAAaBL5+lJXUDZ0LgEAAMhMuAQAACAzY7EAAABpknypKygbOpcAAABkJlwCAACQmbFYAACANHljsYXSuQQAACAz4RIAAIDMjMUCAACkSOwWWzCdSwAAADITLgEAAMjMWCwAAEAau8UWTOcSAABgCzZ69OjI5XKNjqqqqobzZ5999nrn+/fvX/RzdC4BAAC2cPvss0/8z//8T8PrFi1aNDp/1FFHxfjx4xtet2rVquhnCJcAAABptpDdYlu2bNmoW/nPKioqNnq+EMZiAQAAtnALFiyILl26RLdu3eKUU06J119/vdH5qVOnRqdOnaJHjx5x3nnnxbJly4p+Ri5JkqSpCm4ulp86uNQlANAEOt7/WqlLAKAJrFv7VqlL2GRrl7xY6hI2KOm0V9TV1TVaq6ioiIqKivWufeyxx2L16tXRo0ePePvtt+P666+PV199NebNmxc77LBDTJo0Kbbddtvo2rVrLFy4MK655ppYt25dzJ49e4P3SyNcAtBsCZcAW4ayDpdvzCl1CRs0ZvzDcd111zVau/baa2P06NGf+t5Vq1bF7rvvHldccUWMHDlyvfNLly6Nrl27xsSJE+OEE04ouCbfuQQAACgzo0aNWi8YFtplbNu2bfTu3TsWLFiwwfPV1dXRtWvX1PNphEsAAIAykzYCW4i6urp45ZVX4uCDD97g+ffeey+WLFkS1dXVRd3Xhj4AAABpknzzPIpw+eWXx7Rp02LhwoXx3HPPxVe/+tVYsWJFnHXWWbFy5cq4/PLL49lnn41FixbF1KlT49hjj42OHTvG8ccfX9RzdC4BAAC2YG+++Waceuqp8e6778aOO+4Y/fv3jxkzZkTXrl1jzZo1MXfu3Lj77rtj+fLlUV1dHYMHD45JkyZFZWVlUc8RLgEAALZgEydOTD3XunXrePzxx5vkOcIlAABAmnxxI6ifZ75zCQAAQGbCJQAAAJkZiwUAAEiRFLkz6+eZziUAAACZCZcAAABkZiwWAAAgjd1iC6ZzCQAAQGbCJQAAAJkZiwUAAEhjt9iC6VwCAACQmXAJAABAZsZiAQAA0uTrS11B2dC5BAAAIDPhEgAAgMyMxQIAAKSxW2zBdC4BAADITLgEAAAgM2OxAAAAafLGYgulcwkAAEBmwiUAAACZGYsFAABIY7fYgulcAgAAkJlwCQAAQGbGYgEAANLYLbZgOpcAAABkJlwCAACQmbFYAACAFElSX+oSyobOJQAAAJkJlwAAAGRmLBYAACBNYrfYQulcAgAAkJlwCQAAQGbGYgEAANLkjcUWSucSAACAzIRLAAAAMjMWCwAAkMZusQXTuQQAACAz4RIAAIDMjMUCAACkydeXuoKyoXMJAABAZsIlAAAAmRmLBQAASGO32ILpXAIAAJCZcAkAAEBmxmIBAADS5I3FFkrnEgAAgMyESwAAADIzFgsAAJDGbrEF07kEAAAgM+ESAACAzIzFAgAApLFbbMF0LgEAAMhMuAQAACAzY7EAAABpjMUWTOcSAACAzIRLAAAAMjMWCwAAkCJJ6ktdQtnQuQQAACAz4RIAAIDMjMUCAACksVtswXQuAQAAyEy4BAAAIDNjsQAAAGkSY7GF0rkEAAAgM+ESAACAzIzFAgAApLFbbMF0LgEAAMhMuAQAACAzY7EAAABp7BZbMJ1LAAAAMhMuAQAAyMxYLAAAQBq7xRZM5xIAAIDMhEsAAAAyMxYLAACQxm6xBdO5BAAAIDPhEgAAgMyMxQIAAKSxW2zBdC4BAADITLgEAAAgM2OxAAAAaYzFFkznEgAAgMyESwAAADIzFgsAAJAmMRZbKJ1LAAAAMhMuAQAAyMxYLAAAQBq7xRZM5xIAAIDMhEsAAAAyMxYLAACQxm6xBdO5BAAAIDPhEgAAgMyESwAAgDT5fPM8ijB69OjI5XKNjqqqqobzSZLE6NGjo0uXLtG6desYNGhQzJs3r+iPSrgEAADYwu2zzz6xdOnShmPu3LkN52666aa4+eab45ZbbomZM2dGVVVVDBkyJD766KOiniFcAgAAbOFatmwZVVVVDceOO+4YEX/rWo4bNy6uvvrqOOGEE6JXr14xYcKEWL16ddxzzz1FPUO4BAAASJPkm+dRpAULFkSXLl2iW7duccopp8Trr78eERELFy6M2traOOKIIxquraioiIEDB8b06dOLeoafIgEAACgzdXV1UVdX12itoqIiKioq1ru2X79+cffdd0ePHj3i7bffjuuvvz4OOuigmDdvXtTW1kZEROfOnRu9p3PnzvHGG28UVZPOJQAAQJmpqamJ9u3bNzpqamo2eO3QoUPjxBNPjN69e8fhhx8ejzzySERETJgwoeGaXC7X6D1Jkqy39ml0LgEAANIUuTPrZ2XUqFExcuTIRmsb6lpuSNu2baN3796xYMGCGDZsWERE1NbWRnV1dcM1y5YtW6+b+Wl0LgEAAMpMRUVFtGvXrtFRaLisq6uLV155Jaqrq6Nbt25RVVUVU6ZMaTi/du3amDZtWhx00EFF1aRzCQAAsAW7/PLL49hjj41ddtklli1bFtdff32sWLEizjrrrMjlcjFixIgYM2ZMdO/ePbp37x5jxoyJNm3axGmnnVbUc4RLAACANM10LLYYb775Zpx66qnx7rvvxo477hj9+/ePGTNmRNeuXSMi4oorrog1a9bERRddFB988EH069cvnnjiiaisrCzqObkkSZLN8QeU0vJTB5e6BACaQMf7Xyt1CQA0gXVr3yp1CZtszW9/WOoSNqj1ST8odQnr8Z1LAAAAMjMWCwAAkGbLG/TcbHQuAQAAyEy4BAAAIDNjsQAAAGm2gN1iPys6lwAAAGQmXAIAAJCZsVgAAIA0xmILpnMJAABAZsIlAAAAmRmLBQAASJMYiy2UziUAAACZCZcAAABkZiwWAAAgjd1iC6ZzCQAAQGbCJQAAAJkZiwUAAEiTJKWuoGzoXAIAAJCZcAkAAEBmxmIBAADS2C22YDqXAAAAZCZcAgAAkJmxWAAAgDTGYgumcwkAAEBmwiUAAACZGYsFAABIkxiLLZTOJQAAAJkJlwAAAGRmLBYAACBFkk9KXULZ0LkEAAAgM+ESAACAzIzFAgAApMnbLbZQOpcAAABkJlwCAACQmbFYAACANImx2ELpXAIAAJCZcAkAAEBmxmIBAADS5JNSV1A2dC4BAADITLgEAAAgM2OxAAAAafJ2iy2UziUAAACZCZcAAABkZiwWAAAgjbHYgulcAgAAkJlwCQAAQGbGYgEAANIkSakrKBs6lwAAAGQmXAIAAJCZsVgAAIA0dostmM4lAAAAmQmXAAAAZGYsFgAAIE3ebrGF0rkEAAAgM+ESAACAzIRLKBMVx50W2937h2h95vCGtW1OPCsq/21CtB//aLS74+Foe9W/RYvde5awSgA25OAv94sHH7grFi+aHevWvhVf+cqRjc536tQxfnnn2Fi8aHasWP7neOS/fh177NGtRNUCjST55nk0Q8IllIEWu+0ZrQ7916h/4y+N1uuXvhlr7vppfHTlN2PldZdG/p3a2PaqmyJX2b5ElQKwIW3btomXXno5Lh3x/Q2e/919v4rduu0SJ5z4jTjgS0fGG4vfiscfmxht2rT+jCsF2HQ29IHmrmKbaHPx1bHmjn+LbY4/o9GpT6b/vtHrNb++NSoOPSZa7LJ7rJs357OsEoCNmPz4H2Ly43/Y4Lnu3XeL/v37Rp8vDo6XX34tIiIuvmRULH3rpTjl5GHxq/H3fpalAmwynUto5tp8Y0R88vyMWPenTwmLLVpGxaH/GsmqlVG/+M+fTXEAZFZR0SoiIj7+uK5hLZ/Px9q1a+Nf/uVLpSoL+Lt80jyPZqikncs333wzbrvttpg+fXrU1tZGLpeLzp07x0EHHRQXXnhh7LzzzqUsD0pu6wGDo8Wu3WP19y9Mvablfv2j7aU/iGhVEcny92LlmMsj+WjFZ1glAFm8+uqfY9GiJXHD9aPiWxddGatWrY5vjzg/qqs7R3VVp1KXB1CwknUun3766ejZs2c88MADse+++8aZZ54ZX//612PfffeNBx98MPbZZ5945plnPvU+dXV1sWLFikZHXX3z/IIrFCPXYcdofdbFserfx0R88knqdetefiE++t65sfLai+OTF2dGm8uujVy77T67QgHIZN26dXHSyedF9+67xbvLXo6PPvxzDDxkQDz22O+jvr6+1OUBFKxknctvf/vbce6558bYsWNTz48YMSJmzpy50fvU1NTEdddd12jtyn26xvd622GN8tZytx6xVfsOUTnm9oa1XIsW0WKvPtHqiOPjwzOO+NtOYXUfR/7tv0a8/ddY8+dXovLm/4xWg4+OuofuKWH1ABRjzvNz44ADj4h27SqjVaut491334/pT/9XzJr9UqlLg8+9JK9xVaiShcs//elP8etf/zr1/AUXXBD/8R//8an3GTVqVIwcObLR2ppzj81cH5TaJ3+aEyu+e06jtTYXXhn5vy6Ojx++N30L6lwuci23/gwqBKCprVjxUURE7LFHt+jbd9+4dvSPS1wRQOFKFi6rq6tj+vTpseeee27w/LPPPhvV1dWfep+KioqoqKhotJZvYZ8itgAfr4n8m4sar9V9HMnKFX9br9gmthn29fhk9jORX/5+bLVtu2g15LjYqsOOsfa5aaWoGIAUbdu2afS7ld123SX23XefeP/9D2LJkr/GiSf+a7z7znuxeMlb0avXXjH2Jz+Mhx6eHFP+56kSVg1QnJKFy8svvzwuvPDCmD17dgwZMiQ6d+4cuVwuamtrY8qUKXHnnXfGuHHjSlUeNH/5+tiqy87R9pDrIlfZPpKVK6L+L/P/9nuX/xxKASipA/ruG7//n/saXv/k30ZHRMSEu38b3zz321Fd1Sn+7aZro3PnjrF06bL49W/ui+tvGFeaYoHGmunOrM1RLkmSkn1akyZNirFjx8bs2bMbvrDeokWL6Nu3b4wcOTJOOumkTbrv8lMHN2WZAJRIx/tfK3UJADSBdWvfKnUJm2zVDWeWuoQNanv13aUuYT0l/SmSk08+OU4++eT45JNP4t13342IiI4dO8bWW/u+GAAAQDkpabj8u6233rqg71cCAAB8ptI2UWQ9dr4BAAAgM+ESAACAzJrFWCwAAECzZLfYgulcAgAAkJlwCQAAQGbGYgEAANLk7RZbKJ1LAAAAMhMuAQAAyMxYLAAAQBq7xRZM5xIAAIDMhEsAAAAyMxYLAACQJrFbbKF0LgEAAMhMuAQAACAzY7EAAABp7BZbMJ1LAAAAMhMuAQAAyMxYLAAAQIokb7fYQulcAgAAkJlwCQAAQGbGYgEAANLYLbZgOpcAAABkJlwCAACQmbFYAACANMZiC6ZzCQAAQGbCJQAAwOdITU1N5HK5GDFiRMPa2WefHblcrtHRv3//ou5rLBYAACBNki91BU1q5syZ8Ytf/CL69Omz3rmjjjoqxo8f3/C6VatWRd1b5xIAAOBzYOXKlXH66afHHXfcEdtvv/165ysqKqKqqqrh6NChQ1H3Fy4BAAA+B4YPHx7HHHNMHH744Rs8P3Xq1OjUqVP06NEjzjvvvFi2bFlR9zcWCwAAkKaZ7hZbV1cXdXV1jdYqKiqioqJig9dPnDgx5syZEzNnztzg+aFDh8bXvva16Nq1ayxcuDCuueaaOPTQQ2P27Nmp9/xnOpcAAABlpqamJtq3b9/oqKmp2eC1S5Ysicsuuyx+/etfxzbbbLPBa04++eQ45phjolevXnHsscfGY489Fq+99lo88sgjBdekcwkAAFBmRo0aFSNHjmy0ltZhnD17dixbtiz69u3bsFZfXx9PPfVU3HLLLVFXVxctWrRo9J7q6uro2rVrLFiwoOCahEsAAIAUSTMdi93YCOw/O+yww2Lu3LmN1s4555zYa6+94sorr1wvWEZEvPfee7FkyZKorq4uuCbhEgAAYAtWWVkZvXr1arTWtm3b2GGHHaJXr16xcuXKGD16dJx44olRXV0dixYtiquuuio6duwYxx9/fMHPES4BAAA+x1q0aBFz586Nu+++O5YvXx7V1dUxePDgmDRpUlRWVhZ8H+ESAAAgTTMdi81q6tSpDf/cunXrePzxxzPf026xAAAAZCZcAgAAkJmxWAAAgDT5fKkrKBs6lwAAAGQmXAIAAJCZsVgAAIA0W+husZuDziUAAACZCZcAAABkZiwWAAAgjbHYgulcAgAAkJlwCQAAQGbGYgEAAFIkibHYQulcAgAAkJlwCQAAQGbGYgEAANLYLbZgOpcAAABkJlwCAACQmbFYAACANMZiC6ZzCQAAQGbCJQAAAJkZiwUAAEiRGIstmM4lAAAAmQmXAAAAZGYsFgAAII2x2ILpXAIAAJCZcAkAAEBmxmIBAADS5EtdQPnQuQQAACAz4RIAAIDMjMUCAACkSOwWWzCdSwAAADITLgEAAMjMWCwAAEAaY7EF07kEAAAgM+ESAACAzIzFAgAApMmXuoDyoXMJAABAZsIlAAAAmRmLBQAASJHYLbZgOpcAAABkJlwCAACQmbFYAACANHaLLZjOJQAAAJkJlwAAAGRmLBYAACCF3WILp3MJAABAZsIlAAAAmRmLBQAASGO32ILpXAIAAJCZcAkAAEBmxmIBAABSJMZiC6ZzCQAAQGbCJQAAAJkZiwUAAEhjLLZgOpcAAABkJlwCAACQmbFYAACAFHaLLZzOJQAAAJkJlwAAAGRmLBYAACCNsdiC6VwCAACQmXAJAABAZsZiAQAAUtgttnA6lwAAAGQmXAIAAJCZcAkAAEBmvnMJAACQwncuC6dzCQAAQGbCJQAAAJkZiwUAAEhhLLZwOpcAAABkJlwCAACQmbFYAACANEmu1BWUDZ1LAAAAMhMuAQAAyMxYLAAAQAq7xRZO5xIAAIDMhEsAAAAyMxYLAACQIsnbLbZQOpcAAABkJlwCAACQmbFYAACAFHaLLZzOJQAAAJkJlwAAAGRmLBYAACBFktgttlA6lwAAAGQmXAIAAJCZsVgAAIAUdostnM4lAAAAmQmXAAAAZGYsFgAAIEWSt1tsoXQuAQAAyEy4BAAAIDPhEgAAIEWSNM8ji5qamsjlcjFixIh/+DuTGD16dHTp0iVat24dgwYNinnz5hV1X+ESAADgc2LmzJnxi1/8Ivr06dNo/aabboqbb745brnllpg5c2ZUVVXFkCFD4qOPPir43sIlAADA58DKlSvj9NNPjzvuuCO23377hvUkSWLcuHFx9dVXxwknnBC9evWKCRMmxOrVq+Oee+4p+P7CJQAAQIokn2uWx6YYPnx4HHPMMXH44Yc3Wl+4cGHU1tbGEUcc0bBWUVERAwcOjOnTpxd8fz9FAgAAUGbq6uqirq6u0VpFRUVUVFRs8PqJEyfGnDlzYubMmeudq62tjYiIzp07N1rv3LlzvPHGGwXXpHMJAABQZmpqaqJ9+/aNjpqamg1eu2TJkrjsssvi17/+dWyzzTap98zlGndEkyRZb21jdC4BAABSbOoI6uY2atSoGDlyZKO1tK7l7NmzY9myZdG3b9+Gtfr6+njqqafilltuifnz50fE3zqY1dXVDdcsW7ZsvW7mxgiXAAAAZWZjI7D/7LDDDou5c+c2WjvnnHNir732iiuvvDJ22223qKqqiilTpsR+++0XERFr166NadOmxY9+9KOCaxIuAQAAtmCVlZXRq1evRmtt27aNHXbYoWF9xIgRMWbMmOjevXt07949xowZE23atInTTjut4OcIlwAAACmSpNQVfDauuOKKWLNmTVx00UXxwQcfRL9+/eKJJ56IysrKgu+RS5It7+NafurgUpcAQBPoeP9rpS4BgCawbu1bpS5hky3cd0ipS9igbi9OKXUJ67FbLAAAAJkZiwUAAEjRXHeLbY50LgEAAMhMuAQAACAzY7EAAAApksRYbKF0LgEAAMhMuAQAACAzY7EAAAApknypKygfOpcAAABkljlc1tfXxwsvvBAffPBBU9QDAABAGSo6XI4YMSJ++ctfRsTfguXAgQNj//33j5133jmmTp3a1PUBAACUTD7JNcujOSo6XN53332x7777RkTEf/3Xf8XChQvj1VdfjREjRsTVV1/d5AUCAADQ/BUdLt99992oqqqKiIhHH300vva1r0WPHj3im9/8ZsydO7fJCwQAAKD5Kzpcdu7cOV5++eWor6+PyZMnx+GHHx4REatXr44WLVo0eYEAAAClkiS5Znk0R0X/FMk555wTJ510UlRXV0cul4shQ4ZERMRzzz0Xe+21V5MXCAAAQPNXdLgcPXp09OrVK5YsWRJf+9rXoqKiIiIiWrRoEd/73veavEAAAACav6LDZUTEV7/61fXWzjrrrMzFAAAANCdJvnmOoDZHBYXLn/3sZwXf8NJLL93kYgAAAChPBYXLsWPHFnSzXC4nXAIAAHwOFRQuFy5cuLnrAAAAaHaSpNQVlI+if4rk79auXRvz58+PdevWNWU9AAAAlKGiw+Xq1avjm9/8ZrRp0yb22WefWLx4cUT87buWN954Y5MXCAAAQPNXdLgcNWpUvPjiizF16tTYZpttGtYPP/zwmDRpUpMWBwAAUEpJPtcsj+ao6J8iefDBB2PSpEnRv3//yOX+94/ae++94y9/+UuTFgcAAEB5KLpz+c4770SnTp3WW1+1alWjsAkAAMDnR9Hh8sADD4xHHnmk4fXfA+Udd9wRAwYMaLrKAAAASiyf5Jrl0RwVPRZbU1MTRx11VLz88suxbt26+OlPfxrz5s2LZ599NqZNm7Y5agQAAKCZK7pzedBBB8UzzzwTq1evjt133z2eeOKJ6Ny5czz77LPRt2/fzVEjAAAAzVzRncuIiN69e8eECROauhYAAIBmJWmmI6jN0SaFy/r6+njggQfilVdeiVwuFz179ozjjjsuWrbcpNsBAABQ5opOg3/605/iuOOOi9ra2thzzz0jIuK1116LHXfcMR5++OHo3bt3kxcJAABA81b0dy7PPffc2GeffeLNN9+MOXPmxJw5c2LJkiXRp0+fOP/88zdHjQAAACWRJM3zaI6K7ly++OKLMWvWrNh+++0b1rbffvu44YYb4sADD2zS4gAAACgPRXcu99xzz3j77bfXW1+2bFnsscceTVIUAAAA5aWgzuWKFSsa/nnMmDFx6aWXxujRo6N///4RETFjxoz44Q9/GD/60Y82T5UAAAAlkLdbbMEKCpfbbbdd5HL/+6EmSRInnXRSw1ry/4Z+jz322Kivr98MZQIAANCcFRQu//CHP2zuOgAAAChjBYXLgQMHbu46AAAAmp3EWGzBit4t9u9Wr14dixcvjrVr1zZa79OnT+aiAAAAKC9Fh8t33nknzjnnnHjsscc2eN53LgEAAD5/iv4pkhEjRsQHH3wQM2bMiNatW8fkyZNjwoQJ0b1793j44Yc3R40AAAAlkSTN82iOiu5cPvnkk/HQQw/FgQceGFtttVV07do1hgwZEu3atYuampo45phjNkedAAAANGNFdy5XrVoVnTp1ioiIDh06xDvvvBMREb179445c+Y0bXUAAACUhaI7l3vuuWfMnz8/dt111/jiF78Yt99+e+y6667xH//xH1FdXb05agQAACiJvN1iC1Z0uBwxYkQsXbo0IiKuvfbaOPLII+M3v/lNtGrVKu66666mrg8AAIAyUHS4PP300xv+eb/99otFixbFq6++Grvsskt07NixSYsDAACgPGzy71z+XZs2bWL//fdvilqazIDfryp1CQA0gTV//WOpSwDgcy4xFluwgsLlyJEjC77hzTffvMnFAAAAUJ4KCpfPP/98QTfL5aR6AACAz6OCwuUf/vCHzV0HAABAs2O32MIV/TuXAAAA8M+ESwAAADLLvFssAADAliopdQFlROcSAACAzIRLAAAAMtukcPmf//mf8S//8i/RpUuXeOONNyIiYty4cfHQQw81aXEAAACllE9yzfJojooOl7fddluMHDkyjj766Fi+fHnU19dHRMR2220X48aNa+r6AAAAKANFh8uf//zncccdd8TVV18dLVq0aFg/4IADYu7cuU1aHAAAAOWh6N1iFy5cGPvtt9966xUVFbFq1aomKQoAAKA5SJrpCGpzVHTnslu3bvHCCy+st/7YY4/F3nvv3RQ1AQAAUGaK7lx+97vfjeHDh8fHH38cSZLE//2//zfuvffeqKmpiTvvvHNz1AgAAEAzV3S4POecc2LdunVxxRVXxOrVq+O0006LL3zhC/HTn/40TjnllM1RIwAAQEnkS11AGSk6XEZEnHfeeXHeeefFu+++G/l8Pjp16tTUdQEAAFBGNilc/l3Hjh2bqg4AAADKWNHhslu3bpHLpe+Y9Prrr2cqCAAAoLlIwm6xhSo6XI4YMaLR608++SSef/75mDx5cnz3u99tqroAAAAoI0WHy8suu2yD6//+7/8es2bNylwQAAAA5afo37lMM3To0Lj//vub6nYAAAAll0+a59EcNVm4vO+++6JDhw5NdTsAAADKSNFjsfvtt1+jDX2SJIna2tp455134tZbb23S4gAAACgPRYfLYcOGNXq91VZbxY477hiDBg2Kvfbaq6nqAgAAKLm83WILVlS4XLduXey6665x5JFHRlVV1eaqCQAAgDJT1HcuW7ZsGd/61reirq5uc9UDAABAGSp6Q59+/frF888/vzlqAQAAaFaSyDXLozkq+juXF110UXznO9+JN998M/r27Rtt27ZtdL5Pnz5NVhwAAADloeBw+Y1vfCPGjRsXJ598ckREXHrppQ3ncrlcJEkSuVwu6uvrm75KAAAAmrWCw+WECRPixhtvjIULF27OegAAAJqNfKkLKCMFh8skSSIiomvXrputGAAAAMpTURv65HLN84ujAAAAlFZRG/r06NHjUwPm+++/n6kgAACA5qK57szaHBUVLq+77rpo37795qoFAACAMlVUuDzllFOiU6dOm6sWAAAAylTB4dL3LQEAgM8bu8UWruANff6+WywAAAD8s4I7l/m8zA4AAMCGFfWdSwAAgM8TLbbCFfU7lwAAALAhwiUAAACZGYsFAABIkYRfzSiUziUAAACZCZcAAABkZiwWAAAgRd5UbMF0LgEAAMhMuAQAACAz4RIAACBFPnLN8ijGbbfdFn369Il27dpFu3btYsCAAfHYY481nD/77LMjl8s1Ovr371/0Z+U7lwAAAFuwnXbaKW688cbYY489IiJiwoQJcdxxx8Xzzz8f++yzT0REHHXUUTF+/PiG97Rq1aro5wiXAAAAW7Bjjz220esbbrghbrvttpgxY0ZDuKyoqIiqqqpMzzEWCwAAkCJppkddXV2sWLGi0VFXV/epf099fX1MnDgxVq1aFQMGDGhYnzp1anTq1Cl69OgR5513Xixbtqzoz0q4BAAAKDM1NTXRvn37RkdNTU3q9XPnzo1tt902Kioq4sILL4wHHngg9t5774iIGDp0aPzmN7+JJ598Mn7yk5/EzJkz49BDDy0orP6jXJIkSaa/qhnq2elLpS4BgCbw0ssTS10CAE1g6467lbqETfZg1WmlLmGDhr4xfr3wV1FRERUVFRu8fu3atbF48eJYvnx53H///XHnnXfGtGnTGgLmP1q6dGl07do1Jk6cGCeccELBNfnOJQAAQIp8qQtIsbEguSGtWrVq2NDngAMOiJkzZ8ZPf/rTuP3229e7trq6Orp27RoLFiwoqiZjsQAAAJ8zSZKkjr2+9957sWTJkqiuri7qnjqXAAAAW7Crrroqhg4dGjvvvHN89NFHMXHixJg6dWpMnjw5Vq5cGaNHj44TTzwxqqurY9GiRXHVVVdFx44d4/jjjy/qOcIlAABAinwuV+oSMnv77bfjjDPOiKVLl0b79u2jT58+MXny5BgyZEisWbMm5s6dG3fffXcsX748qqurY/DgwTFp0qSorKws6jnCJQAAwBbsl7/8Zeq51q1bx+OPP94kz/GdSwAAADLTuQQAAEixxf1u42akcwkAAEBmwiUAAACZGYsFAABIkS91AWVE5xIAAIDMhEsAAAAyMxYLAACQIp8rdQXlQ+cSAACAzIRLAAAAMjMWCwAAkCIf5mILpXMJAABAZsIlAAAAmRmLBQAASJGUuoAyonMJAABAZsIlAAAAmRmLBQAASJG3WWzBdC4BAADITLgEAAAgM2OxAAAAKfKlLqCM6FwCAACQmXAJAABAZsZiAQAAUiSlLqCM6FwCAACQmXAJAABAZsZiAQAAUuRzpa6gfOhcAgAAkJlwCQAAQGbGYgEAAFLkS11AGdG5BAAAIDPhEgAAgMyMxQIAAKQwFls4nUsAAAAyEy4BAADIzFgsAABAiiRX6grKh84lAAAAmQmXAAAAZGYsFgAAIIXdYguncwkAAEBmwiUAAACZGYsFAABIYSy2cDqXAAAAZCZcAgAAkJmxWAAAgBRJqQsoIzqXAAAAZCZcAgAAkJmxWAAAgBT5XKkrKB86lwAAAGQmXAIAAJCZsVgAAIAU+VIXUEZ0LgEAAMhMuAQAACAzY7EAAAApjMUWTucSAACAzIRLAAAAMjMWCwAAkCIpdQFlROcSAACAzIRLAAAAMjMWCwAAkCKfK3UF5UPnEgAAgMyESwAAADIzFgsAAJAiX+oCyojOJQAAAJkJlwAAAGRmLBYAACBFUuoCyojOJQAAAJkJlwAAAGRmLBYAACBF3mBswXQuAQAAyEy4BAAAIDNjsQAAACnypS6gjOhcAgAAkJlwCQAAQGbGYgEAAFLYK7ZwOpcAAABkJlwCAACQmbFYAACAFHaLLZzOJQAAAJkJlwAAAGRmLBYAACBFPlfqCsqHziUAAACZCZcAAABkZiwWAAAgRT6SUpdQNnQuAQAAyEy4BAAAIDNjsQAAACkMxRZO5xIAAIDMhEsAAAAyMxYLAACQIl/qAsqIziUAAACZCZcAAABkZiwWAAAgRd5+sQXTuQQAACAz4RIAAGALdtttt0WfPn2iXbt20a5duxgwYEA89thjDeeTJInRo0dHly5donXr1jFo0KCYN29e0c8RLgEAAFIkzfQoxk477RQ33nhjzJo1K2bNmhWHHnpoHHfccQ0B8qabboqbb745brnllpg5c2ZUVVXFkCFD4qOPPirqOcIlAADAFuzYY4+No48+Onr06BE9evSIG264IbbddtuYMWNGJEkS48aNi6uvvjpOOOGE6NWrV0yYMCFWr14d99xzT1HPES4BAADKTF1dXaxYsaLRUVdX96nvq6+vj4kTJ8aqVatiwIABsXDhwqitrY0jjjii4ZqKiooYOHBgTJ8+vaiahEsAAIAU+WZ61NTURPv27RsdNTU1qX/H3LlzY9ttt42Kioq48MIL44EHHoi99947amtrIyKic+fOja7v3Llzw7lC+SkSAACAMjNq1KgYOXJko7WKiorU6/fcc8944YUXYvny5XH//ffHWWedFdOmTWs4n8vlGl2fJMl6a59GuAQAACgzFRUVGw2T/6xVq1axxx57RETEAQccEDNnzoyf/vSnceWVV0ZERG1tbVRXVzdcv2zZsvW6mZ/GWCwAAECKfCTN8sgqSZKoq6uLbt26RVVVVUyZMqXh3Nq1a2PatGlx0EEHFXVPnUsAAIAt2FVXXRVDhw6NnXfeOT766KOYOHFiTJ06NSZPnhy5XC5GjBgRY8aMie7du0f37t1jzJgx0aZNmzjttNOKeo5wCQAAsAV7++2344wzzoilS5dG+/bto0+fPjF58uQYMmRIRERcccUVsWbNmrjooovigw8+iH79+sUTTzwRlZWVRT0nlyRJ9p5qM9Oz05dKXQIATeCllyeWugQAmsDWHXcrdQmb7Nu7nlLqEjZo7KLm9/+RvnMJAABAZsIlAAAAmfnOJQAAQIp8qQsoIzqXAAAAZCZcAgAAkJmxWAAAgBRJbHE/rrHZ6FwCAACQmXAJAABAZsZiAQAAUtgttnA6lwAAAGQmXAIAAJCZsVgAAIAUebvFFkznEgAAgMyESwAAADIzFgsAAJDCUGzhdC4BAADITLgEAAAgM2OxAAAAKewWWzidSwAAADITLgEAAMjMWCwAAECKfKkLKCM6lwAAAGQmXAIAAJCZsVgAAIAUid1iCyZcQjN13qVnxZBjBsdu3bvGx2vq4vlZc+MnP/x5LPrL4oZrhn/3vDh62JCo6tI5Pvnkk3j5pVdj3Jjb4qU580pYOQD/6N9/+eu47Ve/abS2Q4ftY9p/3dPw+i+LFsfYW38Vs16YG/l8Ent02yV+8n+uiuqqTp91uQCbTLiEZurAg/aPe371/8WfXnglWrRsESNGfSt++dufx78efHKsWf1xREQs+sviuH7Uj2PJG2/FNttsE2ddcGrc+dufx5H9TogP3lte2j8AgAZ7dOsad/50TMPrrbb6328mLX7zr3Hmty6PE/71yBh+7tdj27Zt4/U3lkSrilalKBVgkwmX0Eydf8pljV5fddkPY/orT8Q+fXrGrBnPR0TEI797vNE1N/5gXHz168fFnnt3jxl/nPmZ1QrAxrVo0SI67tBhg+d+9osJcfCAA+M7w7/ZsLbzF6o/q9KAT2G32MIJl1AmKtttGxERHy7/cIPnt966ZZx05rBY8eFH8eq81z7L0gD4FIvffCsGf+X0aNVq6+i9955x2QVnx85fqI58Ph9PTZ8Z3zj9q3H+t6+OV1/7S3yhS1Wce8ZJcdghB5W6bICiNOvdYpcsWRLf+MY3NnpNXV1drFixotGRT/z3BbY8V143ImbNeCEWvPp6o/VBQ74csxZOjReWPB1nXXBqfPNrF8fy9zccQAH47PXZe88Y8/3L4/ax18foKy+Ld9//IL5+4Xdi+Ycr4v0PlsfqNWvil7/+bXy53wHxi7E3xGGHHBQjrro+Zj7/UqlLByhKsw6X77//fkyYMGGj19TU1ET79u0bHe+tXvoZVQifjWtu/G7sufcecfkF31/v3HPPzIoTDv16nHbMufH0kzNi7B010aHj9iWoEoANOXjAgTFk8Jejx+7dYsCB+8WtP/5hREQ89Nj/RD7/t10oBx88IM485fjYq8fuce4ZJ8XAg74Uv33w0VKWDfw/STP9X3NU0rHYhx9+eKPnX3/99Y2ej4gYNWpUjBw5stHagbsfmqkuaE6uHnN5DD7ykDjjuAvi7aXL1ju/ZvXHsXjhm7F44Zvx4uw/xeQZ98WJp30l7vjZxv/DDACl0ab1NtF9t13jjSVvxfbbtYuWLVrE7rvu0uia3XbdOea89HKJKgTYNCUNl8OGDYtcLhdJkp68c7ncRu9RUVERFRUVjda2yjXrhiwU7Ps1l8fhRw+Ks4Z9K95a/NfC3pTL2WEQoBlbu3ZtLHxjcfTdd5/YeuutY5+ePWLh4jcbXbNoyVvRxc+QAGWmpCmsuro67r///sjn8xs85syZU8ryoKR+8KMr4tivDo3vXnhNrFq1Ojp22iE6dtohKrb5239Mad1mmxhx1bdi3769ostOVbF37z3j/9x8dVRVd4rHH/59iasH4O9+fMsdMfP5l+LNv9bGS/NejW9//4ZYuWp1HHf04RERcc5pJ8bk3z8V9z38WCx+869xz30Px7RnnotTjj+mxJUDEX/bLbY5Hs1RSTuXffv2jTlz5sSwYcM2eP7TupqwJTv1nK9GRMTdD93eaH3UJdfFg5Meifr6fOzWfdcYdvIxsX2H7WL5Bx/G3Odfjq9/5fz48/xPHykH4LPx9rJ344prfxQffLgiOmzXPvrss1fc84ux0aWqc0REHD7wX+IH37047vzP30bN2P+IXXfZKcbe8P3Yf99eJa4coDi5pITp7Y9//GOsWrUqjjrqqA2eX7VqVcyaNSsGDhxY1H17dvpSU5QHQIm99PLEUpcAQBPYuuNupS5hk52164mlLmGDJiy6v9QlrKekncuDDz54o+fbtm1bdLAEAABoKnmTlAWz8w0AAACZCZcAAABkVtKxWAAAgObMUGzhdC4BAADITLgEAAAgM2OxAAAAKfIGYwumcwkAAEBmwiUAAACZGYsFAABIkRiLLZjOJQAAAJkJlwAAAGRmLBYAACBFvtQFlBGdSwAAADITLgEAAMjMWCwAAECKvN1iC6ZzCQAAQGbCJQAAAJkZiwUAAEiRGIstmM4lAAAAmQmXAAAAZGYsFgAAIEW+1AWUEZ1LAAAAMhMuAQAAyMxYLAAAQIoksVtsoXQuAQAAyEy4BAAAIDNjsQAAACnyYSy2UDqXAAAAZCZcAgAAkJmxWAAAgBT5UhdQRnQuAQAAyEy4BAAAIDNjsQAAACkSu8UWTOcSAACAzIRLAAAAMjMWCwAAkCJvLLZgOpcAAABkJlwCAACQmbFYAACAFEliLLZQOpcAAABkJlwCAACQmbFYAACAFPlSF1BGdC4BAADITLgEAAAgM2OxAAAAKZKwW2yhdC4BAADITLgEAAAgM2OxAAAAKfLGYgumcwkAAEBmwiUAAACZGYsFAABIkSTGYgulcwkAAEBmwiUAAACZGYsFAABIYbfYwulcAgAAkJlwCQAAQGbGYgEAAFIkxmILpnMJAACwBaupqYkDDzwwKisro1OnTjFs2LCYP39+o2vOPvvsyOVyjY7+/fsX9RzhEgAAYAs2bdq0GD58eMyYMSOmTJkS69atiyOOOCJWrVrV6Lqjjjoqli5d2nA8+uijRT3HWCwAAECKfFL+Y7GTJ09u9Hr8+PHRqVOnmD17dhxyyCEN6xUVFVFVVbXJz9G5BAAAKDN1dXWxYsWKRkddXV1B7/3www8jIqJDhw6N1qdOnRqdOnWKHj16xHnnnRfLli0rqibhEgAAoMzU1NRE+/btGx01NTWf+r4kSWLkyJHx5S9/OXr16tWwPnTo0PjNb34TTz75ZPzkJz+JmTNnxqGHHlpwYI2IyCXJFtDn/Sc9O32p1CUA0AReenliqUsAoAls3XG3UpewyQ7+wmGlLmGD/uf1R9cLfhUVFVFRUbHR9w0fPjweeeSRePrpp2OnnXZKvW7p0qXRtWvXmDhxYpxwwgkF1eQ7lwAAAGWmkCD5zy655JJ4+OGH46mnntposIyIqK6ujq5du8aCBQsKvr9wCQAAsAVLkiQuueSSeOCBB2Lq1KnRrVu3T33Pe++9F0uWLInq6uqCnyNcAgAApMhH+X+LcPjw4XHPPffEQw89FJWVlVFbWxsREe3bt4/WrVvHypUrY/To0XHiiSdGdXV1LFq0KK666qro2LFjHH/88QU/R7gEAADYgt12220RETFo0KBG6+PHj4+zzz47WrRoEXPnzo277747li9fHtXV1TF48OCYNGlSVFZWFvwc4RIAAGAL9ml7uLZu3Toef/zxzM8RLgEAAFJsCWOxnxW/cwkAAEBmwiUAAACZGYsFAABI8WnfV+R/6VwCAACQmXAJAABAZsZiAQAAUtgttnA6lwAAAGQmXAIAAJCZsVgAAIAUibHYgulcAgAAkJlwCQAAQGbGYgEAAFIkibHYQulcAgAAkJlwCQAAQGbGYgEAAFLk7RZbMJ1LAAAAMhMuAQAAyMxYLAAAQAq7xRZO5xIAAIDMhEsAAAAyMxYLAACQwm6xhdO5BAAAIDPhEgAAgMyMxQIAAKRIjMUWTOcSAACAzIRLAAAAMjMWCwAAkCKfGIstlM4lAAAAmQmXAAAAZGYsFgAAIIXdYguncwkAAEBmwiUAAACZCZcAAABk5juXAAAAKfwUSeF0LgEAAMhMuAQAACAzY7EAAAAp/BRJ4XQuAQAAyEy4BAAAIDNjsQAAACnsFls4nUsAAAAyEy4BAADIzFgsAABACrvFFk7nEgAAgMyESwAAADIzFgsAAJDCbrGF07kEAAAgM+ESAACAzIzFAgAApLBbbOF0LgEAAMhMuAQAACAzY7EAAAApkiRf6hLKhs4lAAAAmQmXAAAAZGYsFgAAIEXebrEF07kEAAAgM+ESAACAzIzFAgAApEgSY7GF0rkEAAAgM+ESAACAzIzFAgAApLBbbOF0LgEAAMhMuAQAACAzY7EAAAAp7BZbOJ1LAAAAMhMuAQAAyMxYLAAAQIq8sdiC6VwCAACQmXAJAABAZsZiAQAAUiRhLLZQOpcAAABkJlwCAACQmbFYAACAFIndYgumcwkAAEBmwiUAAACZGYsFAABIkbdbbMF0LgEAAMhMuAQAACAzY7EAAAAp7BZbOJ1LAAAAMhMuAQAAyMxYLAAAQIq8sdiC6VwCAACQmXAJAABAZsZiAQAAUtgttnA6lwAAAGQmXAIAAJCZsVgAAIAU+TAWWyidSwAAADITLgEAAMjMWCwAAEAKu8UWTucSAACAzIRLAACALVhNTU0ceOCBUVlZGZ06dYphw4bF/PnzG12TJEmMHj06unTpEq1bt45BgwbFvHnzinqOcAkAAJAinyTN8ijGtGnTYvjw4TFjxoyYMmVKrFu3Lo444ohYtWpVwzU33XRT3HzzzXHLLbfEzJkzo6qqKoYMGRIfffRRwc/JJVvgEHHPTl8qdQkANIGXXp5Y6hIAaAJbd9yt1CVssm3bdCt1CRu0cvXCTX7vO++8E506dYpp06bFIYccEkmSRJcuXWLEiBFx5ZVXRkREXV1ddO7cOX70ox/FBRdcUNB9dS4BAADKTF1dXaxYsaLRUVdXV9B7P/zww4iI6NChQ0RELFy4MGpra+OII45ouKaioiIGDhwY06dPL7gm4RIAACBF0kz/V1NTE+3bt2901NTUfPrfkyQxcuTI+PKXvxy9evWKiIja2tqIiOjcuXOjazt37txwrhB+igQAAKDMjBo1KkaOHNloraKi4lPfd/HFF8dLL70UTz/99Hrncrlco9dJkqy3tjHCJQAAQJmpqKgoKEz+o0suuSQefvjheOqpp2KnnXZqWK+qqoqIv3Uwq6urG9aXLVu2XjdzY4zFAgAApCj1rrBNsVtskiRx8cUXx+9+97t48skno1u3xpsUdevWLaqqqmLKlCkNa2vXro1p06bFQQcdVPBzdC4BAAC2YMOHD4977rknHnrooaisrGz4HmX79u2jdevWkcvlYsSIETFmzJjo3r17dO/ePcaMGRNt2rSJ0047reDnCJcAAABbsNtuuy0iIgYNGtRoffz48XH22WdHRMQVV1wRa9asiYsuuig++OCD6NevXzzxxBNRWVlZ8HP8ziUAzZbfuQTYMpTz71xus80upS5hgz7+eHGpS1iP71wCAACQmXAJAABAZr5zCQAAkCKJLe5bhJuNziUAAACZCZcAAABkZiwWAAAgxRb44xqbjc4lAAAAmQmXAAAAZGYsFgAAIIWx2MLpXAIAAJCZcAkAAEBmxmIBAABSGIotnM4lAAAAmQmXAAAAZJZLbH8EZaeuri5qampi1KhRUVFRUepyANhE/n0ObEmESyhDK1asiPbt28eHH34Y7dq1K3U5AGwi/z4HtiTGYgEAAMhMuAQAACAz4RIAAIDMhEsoQxUVFXHttdfa/AGgzPn3ObAlsaEPAAAAmelcAgAAkJlwCQAAQGbCJQAAAJkJlwAAAGQmXEIZuvXWW6Nbt26xzTbbRN++feOPf/xjqUsCoAhPPfVUHHvssdGlS5fI5XLx4IMPlrokgMyESygzkyZNihEjRsTVV18dzz//fBx88MExdOjQWLx4calLA6BAq1atin333TduueWWUpcC0GT8FAmUmX79+sX+++8ft912W8Naz549Y9iwYVFTU1PCygDYFLlcLh544IEYNmxYqUsByETnEsrI2rVrY/bs2XHEEUc0Wj/iiCNi+vTpJaoKAACESygr7777btTX10fnzp0brXfu3Dlqa2tLVBUAAAiXUJZyuVyj10mSrLcGAACfJeESykjHjh2jRYsW63Uply1btl43EwAAPkvCJZSRVq1aRd++fWPKlCmN1qdMmRIHHXRQiaoCAICIlqUuACjOyJEj44wzzogDDjggBgwYEL/4xS9i8eLFceGFF5a6NAAKtHLlyvjzn//c8HrhwoXxwgsvRIcOHWKXXXYpYWUAm85PkUAZuvXWW+Omm26KpUuXRq9evWLs2LFxyCGHlLosAAo0derUGDx48HrrZ511Vtx1112ffUEATUC4BAAAIDPfuQQAACAz4RIAAIDMhEsAAAAyEy4BAADITLgEAAAgM+ESAACAzIRLAAAAMhMuASjarrvuGuPGjWt4ncvl4sEHH/zM6xg9enR88YtfTD0/derUyOVysXz58oLvOWjQoBgxYkSmuu66667YbrvtMt0DAMqNcAlAZkuXLo2hQ4cWdO2nBUIAoDy1LHUBAJTG2rVro1WrVk1yr6qqqia5DwBQvnQuAbYAgwYNiosvvjguvvji2G677WKHHXaI73//+5EkScM1u+66a1x//fVx9tlnR/v27eO8886LiIjp06fHIYccEq1bt46dd945Lr300li1alXD+5YtWxbHHntstG7dOrp16xa/+c1v1nv+P4/Fvvnmm3HKKadEhw4dom3btnHAAQfEc889F3fddVdcd9118eKLL0Yul4tcLhd33XVXRER8+OGHcf7550enTp2iXbt2ceihh8aLL77Y6Dk33nhjdO7cOSorK+Ob3/xmfPzxx0V9Tu+9916ceuqpsdNOO0WbNm2id+/ece+996533bp16zb6Wa5duzauuOKK+MIXvhBt27aNfv36xdSpU1Of++KLL8bgwYOjsrIy2rVrF3379o1Zs2YVVTsANHfCJcAWYsKECdGyZct47rnn4mc/+1mMHTs27rzzzkbX/PjHP45evXrF7Nmz45prrom5c+fGkUceGSeccEK89NJLMWnSpHj66afj4osvbnjP2WefHYsWLYonn3wy7rvvvrj11ltj2bJlqXWsXLkyBg4cGH/961/j4YcfjhdffDGuuOKKyOfzcfLJJ8d3vvOd2GeffWLp0qWxdOnSOPnkkyNJkjjmmGOitrY2Hn300Zg9e3bsv//+cdhhh8X7778fERG//e1v49prr40bbrghZs2aFdXV1XHrrbcW9Rl9/PHH0bdv3/jv//7v+NOf/hTnn39+nHHGGfHcc88V9Vmec8458cwzz8TEiRPjpZdeiq997Wtx1FFHxYIFCzb43NNPPz122mmnmDlzZsyePTu+973vxdZbb11U7QDQ7CUAlL2BAwcmPXv2TPL5fMPalVdemfTs2bPhddeuXZNhw4Y1et8ZZ5yRnH/++Y3W/vjHPyZbbbVVsmbNmmT+/PlJRCQzZsxoOP/KK68kEZGMHTu2YS0ikgceeCBJkiS5/fbbk8rKyuS9997bYK3XXnttsu+++zZa+/3vf5+0a9cu+fjjjxut77777sntt9+eJEmSDBgwILnwwgsbne/Xr9969/pHf/jDH5KISD744IPUa44++ujkO9/5TsPrT/ss//znPye5XC556623Gt3nsMMOS0aNGpUkSZKMHz8+ad++fcO5ysrK5K677kqtAQC2BDqXAFuI/v37Ry6Xa3g9YMCAWLBgQdTX1zesHXDAAY3eM3v27Ljrrrti2223bTiOPPLIyOfzsXDhwnjllVeiZcuWjd631157bXQn1BdeeCH222+/6NChQ8G1z549O1auXBk77LBDo1oWLlwYf/nLXyIi4pVXXokBAwY0et8/v/409fX1ccMNN0SfPn0anvXEE0/E4sWLG123sc9yzpw5kSRJ9OjRo1Gt06ZNa6j1n40cOTLOPffcOPzww+PGG29MvQ4AypkNfQA+R9q2bdvodT6fjwsuuCAuvfTS9a7dZZddYv78+RERjYLWp2ndunXRdeXz+aiurt7g9xab8ic9fvKTn8TYsWNj3Lhx0bt372jbtm2MGDEi1q5dW1StLVq0iNmzZ0eLFi0andt22203+J7Ro0fHaaedFo888kg89thjce2118bEiRPj+OOPz/T3AEBzIlwCbCFmzJix3uvu3buvF4D+0f777x/z5s2LPfbYY4Pne/bsGevWrYtZs2bFl770pYiImD9//kZ/N7JPnz5x5513xvvvv7/B7mWrVq0adVP/XkdtbW20bNkydt1119RaZsyYEWeeeWajv7EYf/zjH+O4446Lr3/96xHxt6C4YMGC6NmzZ6PrNvZZ7rffflFfXx/Lli2Lgw8+uOBn9+jRI3r06BHf/va349RTT43x48cLlwBsUYzFAmwhlixZEiNHjoz58+fHvffeGz//+c/jsssu2+h7rrzyynj22Wdj+PDh8cILL8SCBQvi4YcfjksuuSQiIvbcc8846qij4rzzzovnnnsuZs+eHeeee+5Gu5OnnnpqVFVVxbBhw+KZZ56J119/Pe6///549tlnI+Jvu9YuXLgwXnjhhXj33Xejrq4uDj/88BgwYEAMGzYsHn/88Vi0aFFMnz49vv/97zfsqnrZZZfFr371q/jVr34Vr732Wlx77bUxb968oj6jPfbYI6ZMmRLTp0+PV155JS644IKora0t6rPs0aNHnH766XHmmWfG7373u1i4cGHMnDkzfvSjH8Wjjz663r3WrFkTF198cUydOjXeeOONeOaZZ2LmzJnrBVoAKHfCJcAW4swzz4w1a9bEl770pRg+fHhccsklcf7552/0PX369Ilp06bFggUL4uCDD4799tsvrrnmmqiurm64Zvz48bHzzjvHwIED44QTTmj4uZA0rVq1iieeeCI6deoURx99dPTu3TtuvPHGhg7qiSeeGEcddVQMHjw4dtxxx7j33nsjl8vFo48+Goccckh84xvfiB49esQpp5wSixYtis6dO0dExMknnxw/+MEP4sorr4y+ffvGG2+8Ed/61reK+oyuueaa2H///ePII4+MQYMGNYTgYj/L8ePHx5lnnhnf+c53Ys8994yvfOUr8dxzz8XOO++83r1atGgR7733Xpx55pnRo0ePOOmkk2Lo0KFx3XXXFVU7ADR3uST5hx/uAqAsDRo0KL74xS/GuHHjSl0KAPA5pXMJAABAZsIlAAAAmRmLBQAAIDOdSwAAADITLgEAAMhMuAQAACAz4RIAAIDMhEsAAAAyEy4BAADITLgEAAAgM+ESAACAzIRLAAAAMvv/ATqSk3pmq4JoAAAAAElFTkSuQmCC\n"},"metadata":{}}]},{"cell_type":"code","source":"#@title TABS REFERENCE\n\nclass up_conv_3D(nn.Module):\n    def __init__(self, ch_in, ch_out):\n        super(up_conv_3D, self).__init__()\n        self.up = nn.Sequential(\n            nn.Upsample(scale_factor = 2),\n            nn.Conv3d(ch_in, ch_out, kernel_size = 3, stride = 1, padding = 1, bias = True),\n            nn.GroupNorm(8, ch_out),\n            # nn.BatchNorm3d(ch_out),\n            nn.ReLU(inplace = True)\n        )\n\n    def forward(self,x):\n        x = self.up(x)\n        return x\n\n\nclass conv_block_3D(nn.Module):\n    def __init__(self, ch_in, ch_out):\n        super(conv_block_3D, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv3d(ch_in, ch_out, kernel_size = 3, stride = 1, padding = 1, bias = True),\n            nn.GroupNorm(8, ch_out),\n            nn.ReLU(inplace = True),\n            nn.Conv3d(ch_out, ch_out, kernel_size = 3, stride = 1, padding = 1, bias = True),\n            nn.GroupNorm(8, ch_out),\n            nn.ReLU(inplace = True)\n        )\n\n    def forward(self,x):\n        x = self.conv(x)\n        return x\n\nclass resconv_block_3D(nn.Module):\n    def __init__(self, ch_in, ch_out):\n        super(resconv_block_3D, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv3d(ch_in, ch_out, kernel_size = 3, stride = 1, padding = 1, bias = True),\n            nn.GroupNorm(8, ch_out),\n            nn.ReLU(inplace = True),\n            nn.Conv3d(ch_out, ch_out, kernel_size = 3, stride = 1, padding = 1, bias = True),\n            nn.GroupNorm(8, ch_out),\n            nn.ReLU(inplace = True)\n        )\n        self.Conv_1x1 = nn.Conv3d(ch_in, ch_out, kernel_size = 1, stride = 1, padding = 0)\n\n    def forward(self,x):\n\n        residual = self.Conv_1x1(x)\n        x = self.conv(x)\n        return residual + x\n\n# Can add squeeze excitation layers if you want to try that as well.\nclass ChannelSELayer3D(nn.Module):\n    \"\"\"\n    3D extension of Squeeze-and-Excitation (SE) block described in:\n        *Hu et al., Squeeze-and-Excitation Networks, arXiv:1709.01507*\n        *Zhu et al., AnatomyNet, arXiv:arXiv:1808.05238*\n    \"\"\"\n\n    def __init__(self, num_channels, reduction_ratio=8):\n        \"\"\"\n        :param num_channels: No of input channels\n        :param reduction_ratio: By how much should the num_channels should be reduced\n        \"\"\"\n        super(ChannelSELayer3D, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n        num_channels_reduced = num_channels // reduction_ratio\n        self.reduction_ratio = reduction_ratio\n        self.fc1 = nn.Linear(num_channels, num_channels_reduced, bias=True)\n        self.fc2 = nn.Linear(num_channels_reduced, num_channels, bias=True)\n        self.relu = nn.ReLU()\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, input_tensor):\n        \"\"\"\n        :param input_tensor: X, shape = (batch_size, num_channels, D, H, W)\n        :return: output tensor\n        \"\"\"\n        batch_size, num_channels, D, H, W = input_tensor.size()\n        # Average along each channel\n        squeeze_tensor = self.avg_pool(input_tensor)\n\n        # channel excitation\n        fc_out_1 = self.relu(self.fc1(squeeze_tensor.view(batch_size, num_channels)))\n        fc_out_2 = self.sigmoid(self.fc2(fc_out_1))\n\n        output_tensor = torch.mul(input_tensor, fc_out_2.view(batch_size, num_channels, 1, 1, 1))\n\n        return output_tensor\n\nclass TABS(nn.Module):\n    def __init__(\n        self,\n        img_dim = 192,\n        patch_dim = 8,\n        img_ch = 1,\n        output_ch = 3,\n        embedding_dim = 512,\n        num_heads = 8,\n        num_layers = 4,\n        hidden_dim = 1728,\n        dropout_rate = 0.1,\n        attn_dropout_rate = 0.1,\n        ):\n        super(TABS,self).__init__()\n\n        self.Maxpool = nn.MaxPool3d(kernel_size=2,stride=2)\n\n        self.Conv1 = resconv_block_3D(ch_in=img_ch,ch_out=8)\n\n        self.Conv2 = resconv_block_3D(ch_in=8,ch_out=16)\n\n        self.Conv3 = resconv_block_3D(ch_in=16,ch_out=32)\n\n        self.Conv4 = resconv_block_3D(ch_in=32,ch_out=64)\n\n        self.Conv5 = resconv_block_3D(ch_in=64,ch_out=128)\n\n        self.Up5 = up_conv_3D(ch_in=128,ch_out=64)\n        self.Up_conv5 = resconv_block_3D(ch_in=128, ch_out=64)\n\n        self.Up4 = up_conv_3D(ch_in=64,ch_out=32)\n        self.Up_conv4 = resconv_block_3D(ch_in=64, ch_out=32)\n\n        self.Up3 = up_conv_3D(ch_in=32,ch_out=16)\n        self.Up_conv3 = resconv_block_3D(ch_in=32, ch_out=16)\n\n        self.Up2 = up_conv_3D(ch_in=16,ch_out=8)\n        self.Up_conv2 = resconv_block_3D(ch_in=16, ch_out=8)\n\n        self.Conv_1x1 = nn.Conv3d(8,output_ch,kernel_size=1,stride=1,padding=0)\n        self.gn = nn.GroupNorm(8, 128)\n        self.relu = nn.ReLU(inplace=True)\n\n        self.num_patches = int((img_dim // patch_dim) ** 3)\n        self.seq_length = self.num_patches\n        self.flatten_dim = 128 * img_ch\n\n        self.position_encoding = LearnedPositionalEncoding(\n            self.seq_length, embedding_dim, self.seq_length\n        )\n\n        self.act = nn.Softmax(dim=1)\n\n        self.reshaped_conv = conv_block_3D(512, 128)\n\n        self.transformer = TransformerModel(\n            embedding_dim,\n            num_layers,\n            num_heads,\n            hidden_dim,\n\n            dropout_rate,\n            attn_dropout_rate,\n        )\n\n        self.conv_x = nn.Conv3d(\n            128,\n            embedding_dim,\n            kernel_size=3,\n            stride=1,\n            padding=1\n            )\n\n        self.pre_head_ln = nn.LayerNorm(embedding_dim)\n\n        self.img_dim = 192\n        self.patch_dim = 8\n        self.img_ch = 1\n        self.output_ch = 3\n        self.embedding_dim = 512\n\n    def forward(self,x):\n        # encoding path\n        x1 = self.Conv1(x)\n\n        x2 = self.Maxpool(x1)\n        x2 = self.Conv2(x2)\n\n        x3 = self.Maxpool(x2)\n        x3 = self.Conv3(x3)\n\n        x4 = self.Maxpool(x3)\n        x4 = self.Conv4(x4)\n\n        x5 = self.Maxpool(x4)\n        x = self.Conv5(x5)\n\n        x = self.gn(x)\n        x = self.relu(x)\n        x = self.conv_x(x)\n\n        x = x.permute(0, 2, 3, 4, 1).contiguous()\n        x = x.view(x.size(0), -1, self.embedding_dim)\n\n        x = self.position_encoding(x)\n\n        x, intmd_x = self.transformer(x)\n        x = self.pre_head_ln(x)\n\n        encoder_outputs = {}\n        all_keys = []\n        for i in [1, 2, 3, 4]:\n            val = str(2 * i - 1)\n            _key = 'Z' + str(i)\n            all_keys.append(_key)\n            encoder_outputs[_key] = intmd_x[val]\n        all_keys.reverse()\n\n        x = encoder_outputs[all_keys[0]]\n        x = self._reshape_output(x)\n        x = self.reshaped_conv(x)\n\n        d5 = self.Up5(x)\n        d5 = torch.cat((x4,d5),dim=1)\n        d5 = self.Up_conv5(d5)\n\n        d4 = self.Up4(d5)\n        d4 = torch.cat((x3,d4),dim=1)\n        d4 = self.Up_conv4(d4)\n\n        d3 = self.Up3(d4)\n        d3 = torch.cat((x2,d3),dim=1)\n        d3 = self.Up_conv3(d3)\n\n        d2 = self.Up2(d3)\n        d2 = torch.cat((x1,d2),dim=1)\n        d2 = self.Up_conv2(d2)\n\n        d1 = self.Conv_1x1(d2)\n\n        d1 = self.act(d1)\n\n        return d1\n\n    def _reshape_output(self, x):\n        x = x.view(\n            x.size(0),\n            int(self.img_dim//2 / self.patch_dim),\n            int(self.img_dim//2 / self.patch_dim),\n            int(self.img_dim//2 / self.patch_dim),\n            self.embedding_dim,\n        )\n        x = x.permute(0, 4, 1, 2, 3).contiguous()\n\n        return x\n","metadata":{"id":"MLfq9obROrbO","cellView":"form","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-04-20T02:20:33.144543Z","iopub.execute_input":"2023-04-20T02:20:33.145202Z","iopub.status.idle":"2023-04-20T02:20:33.206823Z","shell.execute_reply.started":"2023-04-20T02:20:33.145163Z","shell.execute_reply":"2023-04-20T02:20:33.205595Z"},"trusted":true},"execution_count":304,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}