{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"gpuClass":"standard"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount(\"/content/drive\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zY3z4fGrPY0j","outputId":"b4b1b71e-3e35-462b-c095-f81f786878b1","execution":{"iopub.status.busy":"2023-04-22T01:17:17.787410Z","iopub.execute_input":"2023-04-22T01:17:17.787799Z","iopub.status.idle":"2023-04-22T01:17:17.794170Z","shell.execute_reply.started":"2023-04-22T01:17:17.787759Z","shell.execute_reply":"2023-04-22T01:17:17.792885Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport random\nimport scipy\nimport scipy.io as scio\nfrom scipy.signal import butter, sosfilt\nfrom scipy.stats import bernoulli\nfrom torch.utils.data import ConcatDataset, Dataset, DataLoader, random_split, RandomSampler\nimport numpy as np\n#from torchmetrics.classification import ConfusionMatrix\nfrom sklearn.metrics import confusion_matrix, accuracy_score \nfrom sklearn.preprocessing import normalize\nimport os\nfrom os import *\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#from Models.Transformer import TransformerModel\n#from Models.PositionalEncoding import LearnedPositionalEncoding\nimport torch.optim.lr_scheduler as lr_scheduler\n\n","metadata":{"id":"yhOLV8UPTrKb","execution":{"iopub.status.busy":"2023-04-22T01:17:17.796093Z","iopub.execute_input":"2023-04-22T01:17:17.796456Z","iopub.status.idle":"2023-04-22T01:17:19.225108Z","shell.execute_reply.started":"2023-04-22T01:17:17.796420Z","shell.execute_reply":"2023-04-22T01:17:19.223789Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# pip install oct2py\n#!apt-get install octave -y","metadata":{"execution":{"iopub.status.busy":"2023-04-22T01:17:19.227151Z","iopub.execute_input":"2023-04-22T01:17:19.227885Z","iopub.status.idle":"2023-04-22T01:17:19.233119Z","shell.execute_reply.started":"2023-04-22T01:17:19.227811Z","shell.execute_reply":"2023-04-22T01:17:19.231725Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"if (not(os.path.isdir('./EEGPT_Models'))):\n    os.makedirs('./EEGPT_Models')\n# if (not(os.path.isdir('./Top_Models'))):\n#     os.makedirs('./Top_Models')","metadata":{"execution":{"iopub.status.busy":"2023-04-22T01:17:19.237489Z","iopub.execute_input":"2023-04-22T01:17:19.238397Z","iopub.status.idle":"2023-04-22T01:17:19.244362Z","shell.execute_reply.started":"2023-04-22T01:17:19.238349Z","shell.execute_reply":"2023-04-22T01:17:19.243019Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#os.removedirs('./Top_Models')","metadata":{"execution":{"iopub.status.busy":"2023-04-22T01:17:19.246129Z","iopub.execute_input":"2023-04-22T01:17:19.247004Z","iopub.status.idle":"2023-04-22T01:17:19.254787Z","shell.execute_reply.started":"2023-04-22T01:17:19.246950Z","shell.execute_reply":"2023-04-22T01:17:19.253382Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# CHECK GPU RESOURCES\ncuda = torch.cuda.is_available()\nprint(\"GPU available:\", cuda)\n\ntorch.manual_seed(4460)# you don't have to set random seed beyond this block\nnp.random.seed(4460)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ue7yaBP0kCW-","outputId":"81ec6b0e-0bfd-4e96-d60c-a3475b504e12","execution":{"iopub.status.busy":"2023-04-22T01:17:19.258283Z","iopub.execute_input":"2023-04-22T01:17:19.258723Z","iopub.status.idle":"2023-04-22T01:17:19.334551Z","shell.execute_reply.started":"2023-04-22T01:17:19.258692Z","shell.execute_reply":"2023-04-22T01:17:19.333426Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"GPU available: True\n","output_type":"stream"}]},{"cell_type":"code","source":"os.listdir()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T01:17:19.338630Z","iopub.execute_input":"2023-04-22T01:17:19.339028Z","iopub.status.idle":"2023-04-22T01:17:19.349613Z","shell.execute_reply.started":"2023-04-22T01:17:19.338945Z","shell.execute_reply":"2023-04-22T01:17:19.348561Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['EEGPT_Models', '.virtual_documents', '__notebook_source__.ipynb']"},"metadata":{}}]},{"cell_type":"code","source":"datatype = 'eeg-merge'","metadata":{"execution":{"iopub.status.busy":"2023-04-22T01:17:19.351589Z","iopub.execute_input":"2023-04-22T01:17:19.352615Z","iopub.status.idle":"2023-04-22T01:17:19.357209Z","shell.execute_reply.started":"2023-04-22T01:17:19.352570Z","shell.execute_reply":"2023-04-22T01:17:19.356081Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"if datatype == 'eeg':\n    sub01 = scio.loadmat('/kaggle/input/eeg-tensors/Signal_Processing_FC/Subject_1.mat')\n    sub02 = scio.loadmat('/kaggle/input/eeg-tensors/Signal_Processing_FC/Subject_2.mat')\n    sub03 = scio.loadmat('/kaggle/input/eeg-tensors/Signal_Processing_FC/Subject_3.mat')\n    sub04 = scio.loadmat('/kaggle/input/eeg-tensors/Signal_Processing_FC/Subject_4.mat')\n    sub05 = scio.loadmat('/kaggle/input/eeg-tensors/Signal_Processing_FC/Subject_5.mat')\n    # sub06 = scio.loadmat('/content/drive/MyDrive/Columbia Spring 2023/Signal Modeling/Project-EEG-Classifier/Signal_Processing_FC/Signal_Processing_FC/Subject_6.mat')\n    sub07 = scio.loadmat('/kaggle/input/eeg-tensors/Signal_Processing_FC/Subject_7.mat')\n    sub08 = scio.loadmat('/kaggle/input/eeg-tensors/Signal_Processing_FC/Subject_8.mat')\n    data = {'sub01':sub01,'sub02':sub02,'sub03':sub03,'sub04':sub04,'sub05':sub05,'sub06':sub06,'sub07':sub07,'sub08':sub08}\n#     data = {'sub01':sub01,'sub02':sub02,'sub03':sub03,'sub04':sub04,'sub05':sub05,'sub07':sub07,'sub08':sub08}\nelif datatype == 'modeeg':\n    sub01 = scio.loadmat('/kaggle/input/mod-eeg-tensors-imputed/Modified_EEG_Tensors/sub01.mat')\n    sub02 = scio.loadmat('/kaggle/input/mod-eeg-tensors-imputed/Modified_EEG_Tensors/sub02.mat')\n    sub03 = scio.loadmat('/kaggle/input/mod-eeg-tensors-imputed/Modified_EEG_Tensors/sub03.mat')\n    sub04 = scio.loadmat('/kaggle/input/mod-eeg-tensors-imputed/Modified_EEG_Tensors/sub04.mat')\n    sub05 = scio.loadmat('/kaggle/input/mod-eeg-tensors-imputed/Modified_EEG_Tensors/sub05.mat')\n    sub06 = scio.loadmat('/kaggle/input/mod-eeg-tensors-imputed/Modified_EEG_Tensors/sub06.mat')\n    sub07 = scio.loadmat('/kaggle/input/mod-eeg-tensors-imputed/Modified_EEG_Tensors/sub07.mat')\n    sub08 = scio.loadmat('/kaggle/input/mod-eeg-tensors-imputed/Modified_EEG_Tensors/sub08.mat')\n    data = {'sub01':sub01,'sub02':sub02,'sub03':sub03,'sub04':sub04,'sub05':sub05,'sub06':sub06,'sub07':sub07,'sub08':sub08}\nelif datatype == 'eeg-merge':\n    sub01 = scio.loadmat('/kaggle/input/eeg-tensors-mergeimputed/EEG_Tensors/Subject_1.mat')\n    sub02 = scio.loadmat('/kaggle/input/eeg-tensors-mergeimputed/EEG_Tensors/Subject_2.mat')\n    sub03 = scio.loadmat('/kaggle/input/eeg-tensors-mergeimputed/EEG_Tensors/Subject_3.mat')\n    sub04 = scio.loadmat('/kaggle/input/eeg-tensors-mergeimputed/EEG_Tensors/Subject_4.mat')\n    sub05 = scio.loadmat('/kaggle/input/eeg-tensors-mergeimputed/EEG_Tensors/Subject_5.mat')\n    sub06 = scio.loadmat('/kaggle/input/eeg-tensors-mergeimputed/EEG_Tensors/Subject_6.mat')\n    sub07 = scio.loadmat('/kaggle/input/eeg-tensors-mergeimputed/EEG_Tensors/Subject_7.mat')\n    sub08 = scio.loadmat('/kaggle/input/eeg-tensors-mergeimputed/EEG_Tensors/Subject_8.mat')\n    data = {'sub01':sub01,'sub02':sub02,'sub03':sub03,'sub04':sub04,'sub05':sub05,'sub06':sub06,'sub07':sub07,'sub08':sub08}\n#     data = {'sub01':sub01,'sub02':sub02,'sub03':sub03,'sub04':sub04,'sub05':sub05,'sub07':sub07,'sub08':sub08}","metadata":{"id":"lUT0FtKqgNPP","execution":{"iopub.status.busy":"2023-04-22T01:17:19.359461Z","iopub.execute_input":"2023-04-22T01:17:19.360373Z","iopub.status.idle":"2023-04-22T01:17:21.954891Z","shell.execute_reply.started":"2023-04-22T01:17:19.360330Z","shell.execute_reply":"2023-04-22T01:17:21.953890Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EEGData():\n  def __init__(self, samples, labels):\n    self.X = samples\n    self.Y = labels\n    self.indices = list(range(np.size(self.Y,0)))\n  def __getitem__(self, index):\n    eegTensor = self.X[index]\n    label = self.Y[index]    \n    sample = {'eeg' : eegTensor,\n              'label' : label}\n    return sample\n    #return self.x[self.indices[index]], self.y[self.indices[index]]\n  def shuffle(self):\n    random.shuffle(self.indices)\n  def __len__(self):\n    return (np.size(self.Y,0))","metadata":{"id":"CvUVk_oEw4CR","execution":{"iopub.status.busy":"2023-04-22T01:17:21.956565Z","iopub.execute_input":"2023-04-22T01:17:21.957071Z","iopub.status.idle":"2023-04-22T01:17:21.964629Z","shell.execute_reply.started":"2023-04-22T01:17:21.957030Z","shell.execute_reply":"2023-04-22T01:17:21.963450Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class testEEGPT(nn.Module):\n  def __init__(\n      self,\n      eeg_channels = 60,\n      time_len = 182\n               ):\n    super(testEEGPT,self).__init__()\n    # BUILD SPATIAL PATH\n    ## CNN MODULE\n    self.Conv1_s = nn.Conv1d(in_channels=eeg_channels, out_channels=eeg_channels, kernel_size=17, stride=1, padding=\"same\")\n    self.AvgPool1_s = nn.AvgPool1d(kernel_size=2,stride=2)\n    self.Conv2_s = nn.Conv1d(in_channels=eeg_channels,out_channels=eeg_channels,kernel_size=14,stride=1,padding=6) # output should be \n    self.grp_norm_s = nn.GroupNorm(eeg_channels//6,eeg_channels)\n    ## TRANSFORMER MODULE\n    self.PosEnc1_s = PositionalEncoder(embedding_dim=(90),max_length=1000)\n    self.Transf1_s = EncoderTransformer(inSize=(90),outSize=4,numLayers=10,hiddenSize=1,numHeads=10,dropout=0.01)\n\n    # BUILD TEMPORAL PATH\n    # CNN MODULE\n    self.dwconv1_t = nn.Conv1d(in_channels=eeg_channels,out_channels=eeg_channels, kernel_size=eeg_channels, stride=1, groups = eeg_channels, padding=\"same\")\n    self.AvgPool1_t = nn.AvgPool2d(kernel_size=(2,1))    \n#     self.grp_norm_t = nn.GroupNorm(eeg_channels//6, eeg_channels)\n    # TRANSFORMER MODULE\n#     self.PosEnc1_t = PositionalEncoder(embedding_dim=eeg_channels//2,max_length=1500)\n    self.PosEnc1_t = PositionalEncoder(embedding_dim=eeg_channels,max_length=1500)\n    self.Transf1_t = EncoderTransformer(inSize=eeg_channels,outSize=4,numLayers=10,hiddenSize=1,numHeads=6,dropout=0.01)\n#     self.Transf1_t = EncoderTransformer(inSize=eeg_channels//2,outSize=4,numLayers=10,hiddenSize=1,numHeads=6,dropout=0.01)\n    # Build Fully Connected Path\n    self.fc1 = nn.Linear(60+182,1)\n\n  def forward(self, x):\n    # Spatial Pass\n    x_s = self.Conv1_s(x)\n#     print('x_s conv1: ',x_s.shape)\n    x_s = self.AvgPool1_s(x_s)\n#     print('x_s avg1: ',x_s.shape)\n    x_s = self.Conv2_s(x_s)\n#     print('x_s conv2: ',x_s.shape)\n#     x_s = self.grp_norm_s(x_s)\n    x_s = self.PosEnc1_s(x_s)\n    x_s = self.Transf1_s(x_s)\n#     print('x_s tf1: ',x_s.shape)\n    \n    # Temporal Pass\n#     x_t = self.dwconv1_t(x)\n#     print('x_t conv1: ',x_t.shape)\n#     x_t = self.AvgPool1_t(x_t)\n#     x_t = self.grp_norm_t(x_t)\n#     print('x_t avg1: ',x_t.shape)\n    x = x.permute(0,2,1) # transpose to present time wise vectors to transformer encoder    \n    x_t = self.PosEnc1_t(x)\n    x_t = self.Transf1_t(x_t)\n#     print('x_t tf1: ',x_t.shape)\n    # Concatenation\n    x_s = x_s.permute(0,2,1)\n    x_t = x_t.permute(0,2,1)\n    x_cat = torch.cat((x_s, x_t),dim=2)\n#     print('x_cat: ',x_cat.shape)\n    # Output Pass: Fully Connected into Softmax\n    x = self.fc1(x_cat)\n    x = torch.log_softmax(x,dim=1)\n    return x\n\nclass testEEGPTFull(nn.Module):\n  def __init__(\n      self,\n      eeg_channels = 60,\n      time_len = 1200\n               ):\n    super(testEEGPTFull,self).__init__()\n    # BUILD SPATIAL PATH\n    ## CNN MODULE\n    self.Conv1_s = nn.Conv1d(in_channels=eeg_channels, out_channels=eeg_channels, kernel_size=17, stride=1, padding=\"same\")\n    self.AvgPool1_s = nn.AvgPool1d(kernel_size=10,stride=10)\n    self.Conv2_s = nn.Conv1d(in_channels=eeg_channels,out_channels=eeg_channels,kernel_size=14,stride=1,padding=6) # output should be \n    self.grp_norm_s = nn.GroupNorm(eeg_channels//6,eeg_channels)\n    ## TRANSFORMER MODULE\n    self.PosEnc1_s = PositionalEncoder(embedding_dim=(120),max_length=1000)\n    self.Transf1_s = EncoderTransformer(inSize=(120),outSize=4,numLayers=10,hiddenSize=1,numHeads=10,dropout=0.01)\n\n    # BUILD TEMPORAL PATH\n    # CNN MODULE\n    self.dwconv1_t = nn.Conv1d(in_channels=eeg_channels,out_channels=eeg_channels, kernel_size=eeg_channels, stride=1, groups = eeg_channels, padding=\"same\")\n    self.AvgPool1_t = nn.AvgPool2d(kernel_size=(2,1))    \n#     self.grp_norm_t = nn.GroupNorm(eeg_channels//6, eeg_channels)\n    # TRANSFORMER MODULE\n#     self.PosEnc1_t = PositionalEncoder(embedding_dim=eeg_channels//2,max_length=1500)\n    self.PosEnc1_t = PositionalEncoder(embedding_dim=eeg_channels,max_length=1500)\n    self.Transf1_t = EncoderTransformer(inSize=eeg_channels,outSize=4,numLayers=10,hiddenSize=1,numHeads=6,dropout=0.01)\n#     self.Transf1_t = EncoderTransformer(inSize=eeg_channels//2,outSize=4,numLayers=10,hiddenSize=1,numHeads=6,dropout=0.01)\n    # Build Fully Connected Path\n    self.fc1 = nn.Linear(60+182,1)\n\n  def forward(self, x):\n    # Spatial Pass\n    x_s = self.Conv1_s(x)\n#     print('x_s conv1: ',x_s.shape)\n    x_s = self.AvgPool1_s(x_s)\n#     print('x_s avg1: ',x_s.shape)\n    x_s = self.Conv2_s(x_s)\n#     print('x_s conv2: ',x_s.shape)\n#     x_s = self.grp_norm_s(x_s)\n    x_s = self.PosEnc1_s(x_s)\n    x_s = self.Transf1_s(x_s)\n#     print('x_s tf1: ',x_s.shape)\n    \n    # Temporal Pass\n#     x_t = self.dwconv1_t(x)\n#     print('x_t conv1: ',x_t.shape)\n#     x_t = self.AvgPool1_t(x_t)\n#     x_t = self.grp_norm_t(x_t)\n#     print('x_t avg1: ',x_t.shape)\n    x = x.permute(0,2,1) # transpose to present time wise vectors to transformer encoder    \n    x_t = self.PosEnc1_t(x)\n    x_t = self.Transf1_t(x_t)\n#     print('x_t tf1: ',x_t.shape)\n    # Concatenation\n    x_s = x_s.permute(0,2,1)\n    x_t = x_t.permute(0,2,1)\n    x_cat = torch.cat((x_s, x_t),dim=2)\n#     print('x_cat: ',x_cat.shape)\n    # Output Pass: Fully Connected into Softmax\n    x = self.fc1(x_cat)\n    x = torch.log_softmax(x,dim=1)\n    return x\n\nclass EEGPT_A(nn.Module):\n  def __init__(\n      self,\n      eeg_channels = 60,\n      time_len = 1200\n               ):\n    super(EEGPT_A,self).__init__()\n    # BUILD SPATIAL PATH\n    ## CNN MODULE\n    self.Conv1_s = nn.Conv1d(in_channels=eeg_channels, out_channels=eeg_channels, kernel_size=17, stride=1, padding=\"same\")\n    self.AvgPool1_s = nn.AvgPool1d(kernel_size=10,stride=10)\n    self.Conv2_s = nn.Conv1d(in_channels=eeg_channels,out_channels=eeg_channels,kernel_size=15,stride=1,padding=\"same\") # output should be \n    self.grp_norm_s = nn.GroupNorm(eeg_channels//6,eeg_channels)\n    ## TRANSFORMER MODULE\n    self.PosEnc1_s = PositionalEncoder(embedding_dim=time_len//10,max_length=1000)\n    self.Transf1_s = EncoderTransformer(inSize=time_len//10,outSize=4,numLayers=10,hiddenSize=1,numHeads=6,dropout=0.01)\n\n    # BUILD TEMPORAL PATH\n    # CNN MODULE\n    self.dwconv1_t = nn.Conv1d(in_channels=eeg_channels,out_channels=eeg_channels, kernel_size=eeg_channels, stride=1, groups = eeg_channels, bias=False, padding=\"same\")\n    self.AvgPool1_t = nn.AvgPool2d(kernel_size=(2,1))    \n    # TRANSFORMER MODULE\n    self.PosEnc1_t = PositionalEncoder(embedding_dim=eeg_channels//2,max_length=1500)\n#     self.Transf1_t = EncoderTransformer(inSize=time_len,outSize=4,numLayers=3,hiddenSize=1,numHeads=6,dropout=0.01)\n    self.Transf1_t = EncoderTransformer(inSize=eeg_channels//2,outSize=4,numLayers=10,hiddenSize=1,numHeads=6,dropout=0.01)\n    # Build Fully Connected Path\n    self.fc1 = nn.Linear(1260,1)\n\n  def forward(self, x):\n    # Spatial Pass\n    x_s = self.Conv1_s(x)\n#     print('x_s conv1: ',x_s.shape)\n    x_s = self.AvgPool1_s(x_s)\n#     print('x_s avg1: ',x_s.shape)\n    x_s = self.Conv2_s(x_s)\n#     print('x_s conv21: ',x_s.shape)\n    x_s = self.grp_norm_s(x_s)\n    x_s = self.PosEnc1_s(x_s)\n    x_s = self.Transf1_s(x_s)\n#     print('x_s tf1: ',x_s.shape)\n    \n    # Temporal Pass\n    x_t = self.dwconv1_t(x)\n#     print('x_t conv1: ',x_t.shape)\n    x_t = self.AvgPool1_t(x_t)\n#     print('x_t avg1: ',x_t.shape)\n    x_t = x_t.permute(0,2,1) # transpose to present time wise vectors to transformer encoder    \n    x_t = self.PosEnc1_t(x_t)\n    x_t = self.Transf1_t(x_t)\n#     print('x_t tf1: ',x_t.shape)\n    # Concatenation\n    x_s = x_s.permute(0,2,1)\n    x_t = x_t.permute(0,2,1)\n    x_cat = torch.cat((x_s, x_t),dim=2)\n#     print('x_cat: ',x_cat.shape)\n    # Output Pass: Fully Connected into Softmax\n    x = self.fc1(x_cat)\n    x = torch.log_softmax(x,dim=1)\n    return x\n\n\n# class EEGPT(nn.Module):\n#   def __init__(\n#       self,\n#       eeg_channels = 60,\n#       time_len = 1200\n#                ):\n#     super(EEGPT,self).__init__()\n#     # BUILD SPATIAL PATH\n#     ## CNN MODULE\n#     self.Conv1_s = nn.Conv1d(in_channels=eeg_channels, out_channels=eeg_channels, kernel_size=16, stride=1, padding=\"same\")\n#     self.AvgPool1_s = nn.AvgPool1d(kernel_size=4,stride=4)\n#     self.Conv2_s = nn.Conv1d(in_channels=eeg_channels,out_channels=eeg_channels,kernel_size=10,stride=1,padding=\"same\")\n#     self.AvgPool2_s = nn.AvgPool1d(kernel_size=3,stride=3)\n#     self.Conv3_s = nn.Conv1d(in_channels=eeg_channels,out_channels=eeg_channels,kernel_size=9,stride=1,padding=\"same\")\n#     self.AvgPool3_s = nn.AvgPool1d(kernel_size=3,stride=3)\n#     self.Conv4_s = nn.Conv1d(in_channels=eeg_channels,out_channels=eeg_channels,kernel_size=9,stride=1,padding=\"valid\")\n#     ## TRANSFORMER MODULE\n#     self.PosEnc1_s = PositionalEncoder(embedding_dim=100,max_length=1000)\n#     self.Transf1_s = EncoderTransformer(inSize=100,outSize=5,numLayers=10,hiddenSize=10,numHeads=10,dropout=0.001)\n\n#     # BUILD TEMPORAL PATH\n#     # CNN MODULE\n#     self.dwconv1_t = nn.Conv1d(in_channels=eeg_channels,out_channels=eeg_channels, kernel_size=eeg_channels, stride=1, groups = eeg_channels, bias=True, padding=\"same\")\n#     self.AvgPool1_t = nn.AvgPool2d(kernel_size=(2,1)) \n#     self.conv2_t = nn.Conv1d(in_channels=eeg_channels//2,out_channels=eeg_channels//2, kernel_size=3, stride=1, bias = False, padding='same')\n#     self.AvgPool2_t = nn.AvgPool2d(kernel_size=(2,1)) \n#     # TRANSFORMER MODULE\n#     self.PosEnc1_t = PositionalEncoder(embedding_dim=60,max_length=1500)\n#     self.Transf1_t = EncoderTransformer(inSize=60,outSize=5,numLayers=5,hiddenSize=5,numHeads=10,dropout=0.001)\n#     # Build Fully Connected Path\n#     if datatype == 'eeg':\n#         self.fc1 = nn.Linear(1260,1)\n#     elif datatype == 'ica':\n#         self.fc1 = nn.Linear(1220,1)\n        \n\n#   def forward(self, x):\n#     # Spatial Pass\n    \n#     x = x.to(torch.float32)\n# #     print('x: ',x.shape)\n#     x_s = self.Conv1_s(x)\n# #     print('x conv1: ',x_s.shape)\n#     x_s = self.AvgPool1_s(x_s)\n# #     print('x avg1: ',x_s.shape)\n#     x_s = self.Conv2_s(x_s)\n# #     print('x conv2: ',x_s.shape)\n# #     x_s = self.AvgPool2_s(x_s)\n# #     print('x avg2: ',x_s.shape)\n# #     x_s = self.Conv3_s(x_s)\n# #     print('x conv3: ',x_s.shape)\n# #     x_s = self.AvgPool3_s(x_s)\n# #     x_s = self.Conv4_s(x_s)\n#     x_s = self.PosEnc1_s(x_s)\n#     x_s = self.Transf1_s(x_s)\n# #     print('x_s_transf: ', x_s.shape)\n    \n#     # Temporal Pass\n#     #x_t = self.dwconv1_t(x)\n#     #print('x_t conv1: ',x_t.shape)\n#     #x_t = self.AvgPool1_t(x_t)\n# #     print('x_t avg1: ',x_t.shape)\n#     #x_t = self.conv2_t(x_t)\n# #     print('x_t conv2: ',x_t.shape)\n#     #x_t = self.AvgPool2_t(x_t)\n# #     print('x_t avg2: ',x_t.shape)\n#     x_t = x.permute(0,2,1) # transpose to present time wise vectors to transformer encoder\n# #     print('x_t avg1_permute: ',x_t.shape)    \n#     x_t = self.PosEnc1_t(x_t)\n#     x_t = self.Transf1_t(x_t)\n# #     print('x_t_transf: ', x_t.shape)\n    \n#     # Concatenation\n#     x_s = x_s.permute(0,2,1)\n#     x_t = x_t.permute(0,2,1)\n# #     print('x_t transf1_perm: ',x_t.shape)\n# #     print('x_s transf1_perm: ',x_s.shape)\n#     x_cat = torch.cat((x_s, x_t),dim=2)\n#     # Output Pass: Fully Connected into Softmax\n# #     print('x cat: ',x_cat.shape)\n#     x = self.fc1(x_cat)\n# #     print('x fc1: ',x.shape)\n#     x = torch.log_softmax(x,dim=1)\n# #     print('x softmax: ',x.shape)\n#     return x\n\nclass EncoderTransformer(nn.Module):\n  def __init__(self, inSize, outSize, numLayers=3, hiddenSize=1, numHeads=8, dropout=0.01):\n    super(EncoderTransformer,self).__init__()\n    self.encoderLayer = nn.TransformerEncoderLayer(d_model=inSize, nhead=numHeads, dim_feedforward=hiddenSize, dropout=dropout)\n    self.encoder = nn.TransformerEncoder(self.encoderLayer,num_layers=numLayers)\n    self.fc1 = nn.Linear(inSize, outSize)\n  def forward(self, x):\n    x = self.encoder(x)\n    x = self.fc1(x)\n    return x\n\n## CHECK HERE !\nclass PositionalEncoder(nn.Module):\n  def __init__(self, embedding_dim, max_length=1000):\n    super(PositionalEncoder,self).__init__()\n    pe = torch.zeros(max_length, embedding_dim)\n    position = torch.arange(0, max_length,dtype=float).unsqueeze(1)\n    div_term = torch.exp(\n        torch.arange(0, embedding_dim, 2).float()\n        * (-torch.log(torch.tensor(10000.0))/embedding_dim)\n    )\n    pe[:,0::2] = torch.sin(position * div_term)\n    pe[:,1::2] = torch.cos(position * div_term)\n    pe.unsqueeze(0).transpose(0,1)\n    self.register_buffer('pe',pe)\n\n  def forward(self, x):\n    #print(self.pe[:x.size(1)].shape)\n    return x + self.pe[:x.size(1),:]\n\n","metadata":{"id":"IjLUvymIhn45","execution":{"iopub.status.busy":"2023-04-22T01:17:21.966527Z","iopub.execute_input":"2023-04-22T01:17:21.967232Z","iopub.status.idle":"2023-04-22T01:17:22.007678Z","shell.execute_reply.started":"2023-04-22T01:17:21.967195Z","shell.execute_reply":"2023-04-22T01:17:22.006642Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# PREPROCESSING FUNCTIONS\n#tensor = subx\n#print(np.shape(subx))\nclass AddGaussNoise(object):\n    def __init__(self, std, mean, p):\n        self.std = std\n        self.mean = mean\n        self.prob = p # tune probability controlling fraction of dataset this augmentation will be applied to\n    def __call__(self, tensor):\n        #return img + torch.randn_like(img)*std + mean\n        bern_rv = bernoulli.rvs(self.prob)\n        if bern_rv == 1:\n            ret_tensor = tensor + np.random.randn(np.shape(tensor)[0],np.shape(tensor)[1])*self.std + self.mean\n        else:\n            ret_tensor = tensor                \n        return ret_tensor \n\ndef mas2565_normalize(tensor):\n    # normalizes a 60 x 1200 tensor, time wise\n    normal_tensor = normalize(tensor,axis=1,norm='l2')\n    return normal_tensor\ndef mas2565_filter(tensor):\n    Fs = 1000\n    lowcut = 0.5\n    highcut = 40\n    order = 4\n    nyq = 0.5*Fs\n    low = lowcut/nyq\n    high = highcut/nyq\n    sos = butter(order, [low, high], btype='band',output='sos')\n    filtered_tensor = sosfilt(sos, tensor, axis=1)\n    return filtered_tensor\n#print(np.shape(mas2565_normalize(tensor)))\n\ndef mas2565_ICA(tensor):\n    pass\n    #return ICA_tensor","metadata":{"execution":{"iopub.status.busy":"2023-04-22T01:17:22.010715Z","iopub.execute_input":"2023-04-22T01:17:22.011050Z","iopub.status.idle":"2023-04-22T01:17:22.024411Z","shell.execute_reply.started":"2023-04-22T01:17:22.011020Z","shell.execute_reply":"2023-04-22T01:17:22.023340Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#print(data['sub01']['X_EEG_TRAIN'])","metadata":{"execution":{"iopub.status.busy":"2023-04-22T01:17:22.029965Z","iopub.execute_input":"2023-04-22T01:17:22.030561Z","iopub.status.idle":"2023-04-22T01:17:22.037322Z","shell.execute_reply.started":"2023-04-22T01:17:22.030531Z","shell.execute_reply":"2023-04-22T01:17:22.036046Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# COMPOSE MEGA DATASET FROM ALL SUBJECT TENSORS\nnumSets = 8\nX = []\nY = []\nID = []\nfor i in range(numSets):\n    if i != 5:\n        subSetX = data[('sub0'+str(i+1))]['X_EEG_TRAIN']\n        subSetY = data[('sub0'+str(i+1))]['Y_EEG_TRAIN']\n  #print(np.size(subSetY,0))\n    for j in range(np.size(subSetY,0)):   \n        #print(np.shape(subSetX)[])\n        subx = subSetX[:,:,j]\n\n        #subx = mas2565_ICA(subx)\n        subx = mas2565_filter(subx)\n        subx = mas2565_normalize(subx)\n        \n\n        #noise = AddGaussNoise(50,0,0.7) # noise augmentation\n        #subx = noise(subx)\n        subx = torch.Tensor(subx)\n        #subx = mas2565_filter(subx)\n        #print(np.shape(subx))\n        suby = subSetY[j,:]\n        # miniSet = EEGData(subx,suby)\n        # print(np.shape(miniSet.y))\n        X.append(subx)\n        Y.append(suby)\n\n\n        # DEBUGGING PRINTS\n        #print(np.size(subSetY,0))\n        #print(np.shape(subSetX))\n        #print(np.shape(subSetY))\n        #print(miniSet.__len__())\n\n#MegaSet = ConcatDataset(megaSet)\n#print(np.shape((MegaSet).x))\n#MegaSet = RandomSampler(MegaSet)\n#print(np.shape(X))\n#print(np.shape(Y[1]))\n\nmyEEG = EEGData(X,Y)\n\n# Load Dataset using EEGData and Dataloader\ntrainset, validset, testset = random_split(myEEG,[0.70, 0.15, 0.15])\ntrainloader = DataLoader(trainset,batch_size=10,shuffle=True)\nvalidloader = DataLoader(validset,batch_size=10,shuffle=True)\ntestloader = DataLoader(testset, batch_size =1, shuffle=True)","metadata":{"id":"2tat7z1h7fPw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"48b710ee-f7b9-417c-b27a-0eb1a60b8946","execution":{"iopub.status.busy":"2023-04-22T01:17:22.039113Z","iopub.execute_input":"2023-04-22T01:17:22.039557Z","iopub.status.idle":"2023-04-22T01:17:23.821426Z","shell.execute_reply.started":"2023-04-22T01:17:22.039519Z","shell.execute_reply":"2023-04-22T01:17:23.820133Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Build/Instantiate Model\neegpt = EEGPT_A(eeg_channels=60, time_len=1200)\nif cuda:\n  eegpt.cuda()\n\n# Call Optimizer\nadam = Adam(eegpt.parameters(),lr=0.00005)","metadata":{"id":"u8WNB1li-GX0","execution":{"iopub.status.busy":"2023-04-22T01:17:23.823461Z","iopub.execute_input":"2023-04-22T01:17:23.823873Z","iopub.status.idle":"2023-04-22T01:17:25.415470Z","shell.execute_reply.started":"2023-04-22T01:17:23.823816Z","shell.execute_reply":"2023-04-22T01:17:25.414409Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# COUNT MODEL PARAMETERS\nparam_count = 0;\nfor param in eegpt.parameters():\n    param_count += param.numel()\n\nprint('number of model params: ', param_count)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V_dPdRf_hV-m","outputId":"0c4744ed-0b2f-41d4-d3b0-6a09563a2318","execution":{"iopub.status.busy":"2023-04-22T01:17:25.416929Z","iopub.execute_input":"2023-04-22T01:17:25.417932Z","iopub.status.idle":"2023-04-22T01:17:25.427238Z","shell.execute_reply.started":"2023-04-22T01:17:25.417893Z","shell.execute_reply":"2023-04-22T01:17:25.425898Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"number of model params:  812281\n","output_type":"stream"}]},{"cell_type":"code","source":"# MODEL TRAINING\nscheduler = lr_scheduler.CosineAnnealingLR(adam, T_max=100, eta_min=0.000001)\nEPOCHS = 100\ntrain_epoch_loss = list()\nvalidation_epoch_loss = list()\nfor epoch in range(EPOCHS):\n  train_loss = list()\n  valid_loss = list()\n  eegpt.train() # put model in train mode  \n  for i, sample in enumerate(trainloader):\n    eegTensor = sample['eeg']\n    #print(np.shape(eegTensor))\n    label = sample['label']\n    #print('label shape: ',np.shape(label))\n    #print('sample: ', sample)\n    if cuda:\n      train_pred = eegpt(eegTensor.cuda())\n      # print('pred shape: ', train_pred.shape)\n      # calculate loss\n      loss_fun = nn.CrossEntropyLoss()\n      loss = loss_fun(train_pred, label.cuda().long())\n      train_loss.append(loss.cpu().data.item())\n      \n      # reset gradient\n      adam.zero_grad()\n      # back propagation\n      loss.backward()\n      # Update parameters\n      adam.step()\n      scheduler.step()\n      #print('epoch: ', epoch, ' loss: ', loss.item())\n      \n      #print(f'EPOCH {epoch + 1}/{EPOCHS} - Training Batch {i+1}/{len(trainloader)} - Loss: {loss.item()}', end='\\r')\n  eegpt.eval()\n  for i, samples in enumerate(validloader):\n    eegTensor = sample['eeg']\n    #print(np.shape(eegTensor))\n    label = sample['label']\n    #print(np.shape(label))\n    #print('sample: ', sample)\n    if cuda:\n      valid_pred = eegpt(eegTensor.cuda())\n      # calculate loss\n      loss_fun = nn.CrossEntropyLoss()\n      loss = loss_fun(train_pred, label.cuda().long())\n      valid_loss.append(loss.cpu().data.item())\n      \n  train_epoch_loss.append(np.mean(train_loss))\n  validation_epoch_loss.append(np.mean(valid_loss))\n  print(\"Epoch: {} | train_loss: {} | validation_loss: {}\".format(epoch, train_epoch_loss[-1], validation_epoch_loss[-1]))\n  # print(\"Epoch: {} | train_loss: {}\".format(epoch, train_epoch_loss[-1]))\n  torch.save(eegpt.state_dict(), '/kaggle/working/EEGPT_Models/checkpoint_epoch_%s.pth' % (epoch))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":305},"id":"79_uGinHjAXm","outputId":"631006fb-42d7-4895-b1f7-350db5497e1a","execution":{"iopub.status.busy":"2023-04-22T01:17:25.429031Z","iopub.execute_input":"2023-04-22T01:17:25.429801Z","iopub.status.idle":"2023-04-22T01:25:20.289227Z","shell.execute_reply.started":"2023-04-22T01:17:25.429762Z","shell.execute_reply":"2023-04-22T01:25:20.287126Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:310: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/Convolution.cpp:895.)\n  self.padding, self.dilation, self.groups)\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 0 | train_loss: 1.2928046971559524 | validation_loss: 0.9919990234904819\nEpoch: 1 | train_loss: 0.939210706949234 | validation_loss: 0.8359488248825073\nEpoch: 2 | train_loss: 0.8372474178671837 | validation_loss: 0.8308035135269165\nEpoch: 3 | train_loss: 0.7895573660731315 | validation_loss: 0.7278250455856323\nEpoch: 4 | train_loss: 0.7267705753445626 | validation_loss: 0.6942209071583219\nEpoch: 5 | train_loss: 0.7141534939408303 | validation_loss: 0.7885907159911262\nEpoch: 6 | train_loss: 0.7066271096467972 | validation_loss: 0.705397261513604\nEpoch: 7 | train_loss: 0.6988340795040131 | validation_loss: 0.7235288818677267\nEpoch: 8 | train_loss: 0.7030360013246536 | validation_loss: 0.6957742704285516\nEpoch: 9 | train_loss: 0.7042150393128395 | validation_loss: 0.7052695353825887\nEpoch: 10 | train_loss: 0.7030792891979217 | validation_loss: 0.7422261370552911\nEpoch: 11 | train_loss: 0.6993955492973327 | validation_loss: 0.6732427411609225\nEpoch: 12 | train_loss: 0.6959040656685829 | validation_loss: 0.7094660401344299\nEpoch: 13 | train_loss: 0.6965026304125785 | validation_loss: 0.6959884431627061\nEpoch: 14 | train_loss: 0.6989961639046669 | validation_loss: 0.7134134901894463\nEpoch: 15 | train_loss: 0.703104168176651 | validation_loss: 0.6909273333019681\nEpoch: 16 | train_loss: 0.6997069895267487 | validation_loss: 0.6669307682249281\nEpoch: 17 | train_loss: 0.6945853218436241 | validation_loss: 0.7240807745191786\nEpoch: 18 | train_loss: 0.6940531685948372 | validation_loss: 0.6935692429542542\nEpoch: 19 | train_loss: 0.7048464968800545 | validation_loss: 0.7520888447761536\nEpoch: 20 | train_loss: 0.7027433231472969 | validation_loss: 0.708966851234436\nEpoch: 21 | train_loss: 0.6985279530286789 | validation_loss: 0.6992026170094808\nEpoch: 22 | train_loss: 0.6952445179224014 | validation_loss: 0.710416575272878\nEpoch: 23 | train_loss: 0.6977251753211021 | validation_loss: 0.7267512083053589\nEpoch: 24 | train_loss: 0.6964812844991684 | validation_loss: 0.6864742636680603\nEpoch: 25 | train_loss: 0.6955636098980904 | validation_loss: 0.6957113279236687\nEpoch: 26 | train_loss: 0.6945781096816063 | validation_loss: 0.6909865140914917\nEpoch: 27 | train_loss: 0.6942722335457802 | validation_loss: 0.681138383017646\nEpoch: 28 | train_loss: 0.6944501042366028 | validation_loss: 0.7011672059694926\nEpoch: 29 | train_loss: 0.7045402556657792 | validation_loss: 0.724877675374349\nEpoch: 30 | train_loss: 0.7015747264027595 | validation_loss: 0.7469912833637662\nEpoch: 31 | train_loss: 0.6959860906004905 | validation_loss: 0.6909033060073853\nEpoch: 32 | train_loss: 0.6949280425906181 | validation_loss: 0.6931093401379056\nEpoch: 33 | train_loss: 0.6957023307681084 | validation_loss: 0.7451320687929789\nEpoch: 34 | train_loss: 0.6973993211984635 | validation_loss: 0.7088850140571594\nEpoch: 35 | train_loss: 0.7026668697595596 | validation_loss: 0.6933433810869852\nEpoch: 36 | train_loss: 0.6962539538741112 | validation_loss: 0.698919415473938\nEpoch: 37 | train_loss: 0.691029217839241 | validation_loss: 0.6950163642565409\nEpoch: 38 | train_loss: 0.68923120200634 | validation_loss: 0.7086813449859619\nEpoch: 39 | train_loss: 0.6948031187057495 | validation_loss: 0.6936079263687134\nEpoch: 40 | train_loss: 0.6762099668383599 | validation_loss: 0.6423023343086243\nEpoch: 41 | train_loss: 0.6965938776731491 | validation_loss: 0.6960479021072388\nEpoch: 42 | train_loss: 0.6871745735406876 | validation_loss: 0.6865147749582926\nEpoch: 43 | train_loss: 0.6854537785053253 | validation_loss: 0.7188740173975626\nEpoch: 44 | train_loss: 0.6961801365017891 | validation_loss: 0.7045267290539212\nEpoch: 45 | train_loss: 0.6800164930522442 | validation_loss: 0.7807153463363647\nEpoch: 46 | train_loss: 0.6955991521477699 | validation_loss: 0.7057494454913669\nEpoch: 47 | train_loss: 0.6914672836661339 | validation_loss: 0.6692459583282471\nEpoch: 48 | train_loss: 0.6906157024204731 | validation_loss: 0.6977025270462036\nEpoch: 49 | train_loss: 0.6861292570829391 | validation_loss: 0.6680514216423035\nEpoch: 50 | train_loss: 0.6868061155080796 | validation_loss: 0.6296201944351196\nEpoch: 51 | train_loss: 0.6880335129797459 | validation_loss: 0.7047034899393717\nEpoch: 52 | train_loss: 0.6917338594794273 | validation_loss: 0.6047643621762594\nEpoch: 53 | train_loss: 0.6960206314921379 | validation_loss: 0.7111902899212308\nEpoch: 54 | train_loss: 0.6856205508112907 | validation_loss: 0.6906293630599976\nEpoch: 55 | train_loss: 0.6875463798642159 | validation_loss: 0.6663580735524496\nEpoch: 56 | train_loss: 0.683211725950241 | validation_loss: 0.7076983981662326\nEpoch: 57 | train_loss: 0.6824455559253693 | validation_loss: 0.643350448873308\nEpoch: 58 | train_loss: 0.6751459941267968 | validation_loss: 0.6761588719156053\nEpoch: 59 | train_loss: 0.6938770815730095 | validation_loss: 0.6937517523765564\nEpoch: 60 | train_loss: 0.6806902259588241 | validation_loss: 0.6963747673564487\nEpoch: 61 | train_loss: 0.6976558685302734 | validation_loss: 0.6699022452036539\nEpoch: 62 | train_loss: 0.6829460576176644 | validation_loss: 0.6967164344257779\nEpoch: 63 | train_loss: 0.6827472075819969 | validation_loss: 0.7248334619734023\nEpoch: 64 | train_loss: 0.6855351060628891 | validation_loss: 0.6302338242530823\nEpoch: 65 | train_loss: 0.6756548501551152 | validation_loss: 0.7050756414731344\nEpoch: 66 | train_loss: 0.6815166011452675 | validation_loss: 0.6373977992269728\nEpoch: 67 | train_loss: 0.6739478796720505 | validation_loss: 0.6493237879541185\nEpoch: 68 | train_loss: 0.6809220865368844 | validation_loss: 0.6901549100875854\nEpoch: 69 | train_loss: 0.6822047740221023 | validation_loss: 0.6836703419685364\nEpoch: 70 | train_loss: 0.6857118055224418 | validation_loss: 0.5363366074032254\nEpoch: 71 | train_loss: 0.6791841819882393 | validation_loss: 0.6818571951654222\nEpoch: 72 | train_loss: 0.6799899563193321 | validation_loss: 0.6965233352449205\nEpoch: 73 | train_loss: 0.6769420757889748 | validation_loss: 0.6926057802306281\nEpoch: 74 | train_loss: 0.6945034593343735 | validation_loss: 0.6693619423442416\nEpoch: 75 | train_loss: 0.6810001656413078 | validation_loss: 0.6911672353744507\nEpoch: 76 | train_loss: 0.6789647802710533 | validation_loss: 0.6720126867294312\nEpoch: 77 | train_loss: 0.6786135643720627 | validation_loss: 0.6758660078048706\nEpoch: 78 | train_loss: 0.6915976613759994 | validation_loss: 0.7150378161006503\nEpoch: 79 | train_loss: 0.6838171780109406 | validation_loss: 0.6522570848464966\nEpoch: 80 | train_loss: 0.6949223592877388 | validation_loss: 0.6311053037643433\nEpoch: 81 | train_loss: 0.6751917473971843 | validation_loss: 0.6862839460372925\nEpoch: 82 | train_loss: 0.6741231456398964 | validation_loss: 0.6556204424964057\nEpoch: 83 | train_loss: 0.6829065442085266 | validation_loss: 0.7169809341430664\nEpoch: 84 | train_loss: 0.6860072135925293 | validation_loss: 0.7087538838386536\nEpoch: 85 | train_loss: 0.6772084593772888 | validation_loss: 0.7392680181397332\nEpoch: 86 | train_loss: 0.6821193769574165 | validation_loss: 0.6380469666586982\nEpoch: 87 | train_loss: 0.6852597892284393 | validation_loss: 0.6988712416754829\nEpoch: 88 | train_loss: 0.6718545258045197 | validation_loss: 0.6927491426467896\nEpoch: 89 | train_loss: 0.6814723327755928 | validation_loss: 0.6700151496463351\nEpoch: 90 | train_loss: 0.6817577093839645 | validation_loss: 0.666770875453949\nEpoch: 91 | train_loss: 0.674760927259922 | validation_loss: 0.7641363739967346\nEpoch: 92 | train_loss: 0.6801226630806922 | validation_loss: 0.7101368308067322\nEpoch: 93 | train_loss: 0.6885589748620987 | validation_loss: 0.6202670401997037\nEpoch: 94 | train_loss: 0.6736060559749604 | validation_loss: 0.6980570554733276\nEpoch: 95 | train_loss: 0.6774500250816345 | validation_loss: 0.6827214956283569\nEpoch: 96 | train_loss: 0.6801859878003598 | validation_loss: 0.7092116475105286\nEpoch: 97 | train_loss: 0.6652407482266426 | validation_loss: 0.6139382190174527\nEpoch: 98 | train_loss: 0.6759432122111321 | validation_loss: 0.6727224588394165\nEpoch: 99 | train_loss: 0.6753094539046287 | validation_loss: 0.6594465970993042\n","output_type":"stream"}]},{"cell_type":"code","source":"# BEST EPOCH\nbest_epoch = np.argmin(validation_epoch_loss)\nprint('best epoch: ', best_epoch)\n\n# LOAD BEST MODEL\n# state_dict = torch.load('/kaggle/working/EEGPT_Models/checkpoint_epoch_%s.pth' % (best_epoch))\nstate_dict = torch.load('/kaggle/working/EEGPT_Models/checkpoint_epoch_21.pth')\n# print(state_dict.keys())\neegpt.load_state_dict(state_dict)\n\n# REPORT ACCURACY\ntest_preds = []\nlabels = []\nfor i, sample in enumerate(testloader):\n    accuracy = list()\n    eegTensor = sample['eeg']\n    #print(np.shape(eegTensor))\n    label = sample['label']\n    labels.append(label.detach().cpu().numpy())\n    #print(np.shape(labels))\n    #print(np.shape(label))\n    #print('sample: ', sample)\n    \n    #print(test_label)\n    eegpt.eval()\n    if cuda:\n        #print(eegTensor.shape)\n        test_pred = eegpt(eegTensor.cuda())\n        #print(test_pred.shape)\n        test_preds.append(test_pred.detach().cpu().numpy())\n        # tpred = test_pred.detach().numpy()\n        # tlabels = test_label.detach().numpy()\n        # tpredictions = get_predicted_labels(tpred)\n        #print(tpred)x\n        #accuracy.append(acc)\n    else:\n        pass\n    #print(np.mean(accuracy))\n    #Acc = np.mean(accuracy)\n\n# print('EEGPT accuracy: ',accuracy_score(tlabels,tpredictions)) # BUILD ACCURACY SCORE FUN\n# CONFUSION MATRIX\npred_labels = list()\nfor i in range(np.shape(test_preds)[0]):\n    for j in range(np.shape(test_preds[i])[0]):\n        # print(np.exp(test_preds[i][1]))\n        #print(j)\n        class_pred = np.argmax(test_preds[i][j])\n        #print(class_pred)\n        pred_labels.append(class_pred) \nprint(np.shape(pred_labels))\n\ntrue_labels = list()\nfor i in range(np.shape(labels)[0]):\n    # print(i)\n    for j in range(np.shape(test_preds[i])[0]):\n        # print(np.exp(test_preds[i][1]))\n        #print(labels[j][0])\n        #print(class_pred)\n        true_labels.append(labels[i][j]) \nprint(np.shape(true_labels))\n\nbrk = len(true_labels)\nCM = confusion_matrix(true_labels[1:brk], pred_labels[1:brk])\naccuracy = accuracy_score(true_labels[1:brk], pred_labels[1:brk])\nplt.figure(figsize = (12,10))\nsns.heatmap(CM, annot = True, annot_kws = {\"size\": 10}, fmt='d')\nplt.ylabel('True labels');\nplt.xlabel('predicted labels');\nprint('accuracy: ',accuracy)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jN5zN2vCXeVD","outputId":"5af53d39-727c-4d01-ecc5-c8e4bb86d42f","execution":{"iopub.status.busy":"2023-04-22T01:37:05.749455Z","iopub.execute_input":"2023-04-22T01:37:05.749854Z","iopub.status.idle":"2023-04-22T01:37:07.616979Z","shell.execute_reply.started":"2023-04-22T01:37:05.749801Z","shell.execute_reply":"2023-04-22T01:37:07.615812Z"},"trusted":true},"execution_count":291,"outputs":[{"name":"stdout","text":"best epoch:  70\n(85,)\n(85, 1)\naccuracy:  0.5357142857142857\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x1000 with 2 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":"# REPORT ACCURACY\ntest_preds = []\nlabels = []\nfor i, sample in enumerate(testloader):\n    accuracy = list()\n    eegTensor = sample['eeg']\n    #print(np.shape(eegTensor))\n    label = sample['label']\n    labels.append(label.detach().cpu().numpy())\n    #print(np.shape(labels))\n    #print(np.shape(label))\n    #print('sample: ', sample)\n    \n    #print(test_label)\n    eegpt.eval()\n    if cuda:\n        #print(eegTensor.shape)\n        test_pred = eegpt(eegTensor.cuda())\n        #print(test_pred.shape)\n        test_preds.append(test_pred.detach().cpu().numpy())\n        # tpred = test_pred.detach().numpy()\n        # tlabels = test_label.detach().numpy()\n        # tpredictions = get_predicted_labels(tpred)\n        #print(tpred)x\n        #accuracy.append(acc)\n    else:\n        pass\n    #print(np.mean(accuracy))\n    #Acc = np.mean(accuracy)\n\n# print('EEGPT accuracy: ',accuracy_score(tlabels,tpredictions)) # BUILD ACCURACY SCORE FUN\n# CONFUSION MATRIX\npred_labels = list()\nfor i in range(np.shape(test_preds)[0]):\n    for j in range(np.shape(test_preds[i])[0]):\n        # print(np.exp(test_preds[i][1]))\n        #print(j)\n        class_pred = np.argmax(test_preds[i][j])\n        #print(class_pred)\n        pred_labels.append(class_pred) \nprint(np.shape(pred_labels))\n\ntrue_labels = list()\nfor i in range(np.shape(labels)[0]):\n    # print(i)\n    for j in range(np.shape(test_preds[i])[0]):\n        # print(np.exp(test_preds[i][1]))\n        #print(labels[j][0])\n        #print(class_pred)\n        true_labels.append(labels[i][j]) \nprint(np.shape(true_labels))\n\nbrk = len(true_labels)\nCM = confusion_matrix(true_labels[1:brk], pred_labels[1:brk])\naccuracy = accuracy_score(true_labels[1:brk], pred_labels[1:brk])\nplt.figure(figsize = (12,10))\nsns.heatmap(CM, annot = True, annot_kws = {\"size\": 10}, fmt='d')\nplt.ylabel('True labels');\nplt.xlabel('predicted labels');\nprint('accuracy: ',accuracy)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vry23LqWX4Xw","outputId":"92fe40cf-10d3-4dbe-db1d-f79cd298c264","execution":{"iopub.status.busy":"2023-04-22T01:32:04.273380Z","iopub.execute_input":"2023-04-22T01:32:04.273751Z","iopub.status.idle":"2023-04-22T01:32:06.043126Z","shell.execute_reply.started":"2023-04-22T01:32:04.273717Z","shell.execute_reply":"2023-04-22T01:32:06.041847Z"}}},{"cell_type":"markdown","source":"print(np.shape(labels[0]))\n# print(np.shape(test_preds[1]))\nprint(np.shape(test_preds[0]))\n# st_shap = np.shape(test_preds)\nprint(np.exp(test_preds[1][0]))\n#print(labels[2][5])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K31JgGBcfMs-","outputId":"a2f5276b-f4df-46b6-b157-1e587a0f2281","execution":{"iopub.status.busy":"2023-04-22T01:31:21.894894Z","iopub.execute_input":"2023-04-22T01:31:21.895341Z","iopub.status.idle":"2023-04-22T01:31:21.903267Z","shell.execute_reply.started":"2023-04-22T01:31:21.895295Z","shell.execute_reply":"2023-04-22T01:31:21.901713Z"}}},{"cell_type":"code","source":"pred_labels = list()\nfor i in range(np.shape(test_preds)[0]):\n    for j in range(np.shape(test_preds[i])[0]):\n        # print(np.exp(test_preds[i][1]))\n        #print(j)\n        class_pred = np.argmax(test_preds[i][j])\n        #print(class_pred)\n        pred_labels.append(class_pred) \nprint(np.shape(pred_labels))","metadata":{"execution":{"iopub.status.busy":"2023-04-22T01:31:21.905531Z","iopub.execute_input":"2023-04-22T01:31:21.906222Z","iopub.status.idle":"2023-04-22T01:31:21.917011Z","shell.execute_reply.started":"2023-04-22T01:31:21.906179Z","shell.execute_reply":"2023-04-22T01:31:21.915507Z"},"trusted":true},"execution_count":242,"outputs":[{"name":"stdout","text":"(85,)\n","output_type":"stream"}]},{"cell_type":"code","source":"true_labels = list()\nfor i in range(np.shape(labels)[0]):\n    # print(i)\n    for j in range(np.shape(test_preds[i])[0]):\n        # print(np.exp(test_preds[i][1]))\n        #print(labels[j][0])\n        #print(class_pred)\n        true_labels.append(labels[i][j]) \nprint(np.shape(true_labels))","metadata":{"execution":{"iopub.status.busy":"2023-04-22T01:31:21.920888Z","iopub.execute_input":"2023-04-22T01:31:21.921299Z","iopub.status.idle":"2023-04-22T01:31:21.931911Z","shell.execute_reply.started":"2023-04-22T01:31:21.921248Z","shell.execute_reply":"2023-04-22T01:31:21.930479Z"},"trusted":true},"execution_count":243,"outputs":[{"name":"stdout","text":"(85, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"brk = len(true_labels)\nCM = confusion_matrix(true_labels[1:brk], pred_labels[1:brk])\naccuracy = accuracy_score(true_labels[1:brk], pred_labels[1:brk])\nplt.figure(figsize = (12,10))\nsns.heatmap(CM, annot = True, annot_kws = {\"size\": 10}, fmt='d')\nplt.ylabel('True labels');\nplt.xlabel('predicted labels');\nprint('accuracy: ',accuracy)","metadata":{"id":"-JcC_9tief8C","execution":{"iopub.status.busy":"2023-04-22T01:31:21.933913Z","iopub.execute_input":"2023-04-22T01:31:21.934355Z","iopub.status.idle":"2023-04-22T01:31:22.337548Z","shell.execute_reply.started":"2023-04-22T01:31:21.934320Z","shell.execute_reply":"2023-04-22T01:31:22.336485Z"},"trusted":true},"execution_count":244,"outputs":[{"name":"stdout","text":"accuracy:  0.7619047619047619\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x1000 with 2 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"#@title TABS REFERENCE\n\nclass up_conv_3D(nn.Module):\n    def __init__(self, ch_in, ch_out):\n        super(up_conv_3D, self).__init__()\n        self.up = nn.Sequential(\n            nn.Upsample(scale_factor = 2),\n            nn.Conv3d(ch_in, ch_out, kernel_size = 3, stride = 1, padding = 1, bias = True),\n            nn.GroupNorm(8, ch_out),\n            # nn.BatchNorm3d(ch_out),\n            nn.ReLU(inplace = True)\n        )\n\n    def forward(self,x):\n        x = self.up(x)\n        return x\n\n\nclass conv_block_3D(nn.Module):\n    def __init__(self, ch_in, ch_out):\n        super(conv_block_3D, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv3d(ch_in, ch_out, kernel_size = 3, stride = 1, padding = 1, bias = True),\n            nn.GroupNorm(8, ch_out),\n            nn.ReLU(inplace = True),\n            nn.Conv3d(ch_out, ch_out, kernel_size = 3, stride = 1, padding = 1, bias = True),\n            nn.GroupNorm(8, ch_out),\n            nn.ReLU(inplace = True)\n        )\n\n    def forward(self,x):\n        x = self.conv(x)\n        return x\n\nclass resconv_block_3D(nn.Module):\n    def __init__(self, ch_in, ch_out):\n        super(resconv_block_3D, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv3d(ch_in, ch_out, kernel_size = 3, stride = 1, padding = 1, bias = True),\n            nn.GroupNorm(8, ch_out),\n            nn.ReLU(inplace = True),\n            nn.Conv3d(ch_out, ch_out, kernel_size = 3, stride = 1, padding = 1, bias = True),\n            nn.GroupNorm(8, ch_out),\n            nn.ReLU(inplace = True)\n        )\n        self.Conv_1x1 = nn.Conv3d(ch_in, ch_out, kernel_size = 1, stride = 1, padding = 0)\n\n    def forward(self,x):\n\n        residual = self.Conv_1x1(x)\n        x = self.conv(x)\n        return residual + x\n\n# Can add squeeze excitation layers if you want to try that as well.\nclass ChannelSELayer3D(nn.Module):\n    \"\"\"\n    3D extension of Squeeze-and-Excitation (SE) block described in:\n        *Hu et al., Squeeze-and-Excitation Networks, arXiv:1709.01507*\n        *Zhu et al., AnatomyNet, arXiv:arXiv:1808.05238*\n    \"\"\"\n\n    def __init__(self, num_channels, reduction_ratio=8):\n        \"\"\"\n        :param num_channels: No of input channels\n        :param reduction_ratio: By how much should the num_channels should be reduced\n        \"\"\"\n        super(ChannelSELayer3D, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n        num_channels_reduced = num_channels // reduction_ratio\n        self.reduction_ratio = reduction_ratio\n        self.fc1 = nn.Linear(num_channels, num_channels_reduced, bias=True)\n        self.fc2 = nn.Linear(num_channels_reduced, num_channels, bias=True)\n        self.relu = nn.ReLU()\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, input_tensor):\n        \"\"\"\n        :param input_tensor: X, shape = (batch_size, num_channels, D, H, W)\n        :return: output tensor\n        \"\"\"\n        batch_size, num_channels, D, H, W = input_tensor.size()\n        # Average along each channel\n        squeeze_tensor = self.avg_pool(input_tensor)\n\n        # channel excitation\n        fc_out_1 = self.relu(self.fc1(squeeze_tensor.view(batch_size, num_channels)))\n        fc_out_2 = self.sigmoid(self.fc2(fc_out_1))\n\n        output_tensor = torch.mul(input_tensor, fc_out_2.view(batch_size, num_channels, 1, 1, 1))\n\n        return output_tensor\n\nclass TABS(nn.Module):\n    def __init__(\n        self,\n        img_dim = 192,\n        patch_dim = 8,\n        img_ch = 1,\n        output_ch = 3,\n        embedding_dim = 512,\n        num_heads = 8,\n        num_layers = 4,\n        hidden_dim = 1728,\n        dropout_rate = 0.1,\n        attn_dropout_rate = 0.1,\n        ):\n        super(TABS,self).__init__()\n\n        self.Maxpool = nn.MaxPool3d(kernel_size=2,stride=2)\n\n        self.Conv1 = resconv_block_3D(ch_in=img_ch,ch_out=8)\n\n        self.Conv2 = resconv_block_3D(ch_in=8,ch_out=16)\n\n        self.Conv3 = resconv_block_3D(ch_in=16,ch_out=32)\n\n        self.Conv4 = resconv_block_3D(ch_in=32,ch_out=64)\n\n        self.Conv5 = resconv_block_3D(ch_in=64,ch_out=128)\n\n        self.Up5 = up_conv_3D(ch_in=128,ch_out=64)\n        self.Up_conv5 = resconv_block_3D(ch_in=128, ch_out=64)\n\n        self.Up4 = up_conv_3D(ch_in=64,ch_out=32)\n        self.Up_conv4 = resconv_block_3D(ch_in=64, ch_out=32)\n\n        self.Up3 = up_conv_3D(ch_in=32,ch_out=16)\n        self.Up_conv3 = resconv_block_3D(ch_in=32, ch_out=16)\n\n        self.Up2 = up_conv_3D(ch_in=16,ch_out=8)\n        self.Up_conv2 = resconv_block_3D(ch_in=16, ch_out=8)\n\n        self.Conv_1x1 = nn.Conv3d(8,output_ch,kernel_size=1,stride=1,padding=0)\n        self.gn = nn.GroupNorm(8, 128)\n        self.relu = nn.ReLU(inplace=True)\n\n        self.num_patches = int((img_dim // patch_dim) ** 3)\n        self.seq_length = self.num_patches\n        self.flatten_dim = 128 * img_ch\n\n        self.position_encoding = LearnedPositionalEncoding(\n            self.seq_length, embedding_dim, self.seq_length\n        )\n\n        self.act = nn.Softmax(dim=1)\n\n        self.reshaped_conv = conv_block_3D(512, 128)\n\n        self.transformer = TransformerModel(\n            embedding_dim,\n            num_layers,\n            num_heads,\n            hidden_dim,\n\n            dropout_rate,\n            attn_dropout_rate,\n        )\n\n        self.conv_x = nn.Conv3d(\n            128,\n            embedding_dim,\n            kernel_size=3,\n            stride=1,\n            padding=1\n            )\n\n        self.pre_head_ln = nn.LayerNorm(embedding_dim)\n\n        self.img_dim = 192\n        self.patch_dim = 8\n        self.img_ch = 1\n        self.output_ch = 3\n        self.embedding_dim = 512\n\n    def forward(self,x):\n        # encoding path\n        x1 = self.Conv1(x)\n\n        x2 = self.Maxpool(x1)\n        x2 = self.Conv2(x2)\n\n        x3 = self.Maxpool(x2)\n        x3 = self.Conv3(x3)\n\n        x4 = self.Maxpool(x3)\n        x4 = self.Conv4(x4)\n\n        x5 = self.Maxpool(x4)\n        x = self.Conv5(x5)\n\n        x = self.gn(x)\n        x = self.relu(x)\n        x = self.conv_x(x)\n\n        x = x.permute(0, 2, 3, 4, 1).contiguous()\n        x = x.view(x.size(0), -1, self.embedding_dim)\n\n        x = self.position_encoding(x)\n\n        x, intmd_x = self.transformer(x)\n        x = self.pre_head_ln(x)\n\n        encoder_outputs = {}\n        all_keys = []\n        for i in [1, 2, 3, 4]:\n            val = str(2 * i - 1)\n            _key = 'Z' + str(i)\n            all_keys.append(_key)\n            encoder_outputs[_key] = intmd_x[val]\n        all_keys.reverse()\n\n        x = encoder_outputs[all_keys[0]]\n        x = self._reshape_output(x)\n        x = self.reshaped_conv(x)\n\n        d5 = self.Up5(x)\n        d5 = torch.cat((x4,d5),dim=1)\n        d5 = self.Up_conv5(d5)\n\n        d4 = self.Up4(d5)\n        d4 = torch.cat((x3,d4),dim=1)\n        d4 = self.Up_conv4(d4)\n\n        d3 = self.Up3(d4)\n        d3 = torch.cat((x2,d3),dim=1)\n        d3 = self.Up_conv3(d3)\n\n        d2 = self.Up2(d3)\n        d2 = torch.cat((x1,d2),dim=1)\n        d2 = self.Up_conv2(d2)\n\n        d1 = self.Conv_1x1(d2)\n\n        d1 = self.act(d1)\n\n        return d1\n\n    def _reshape_output(self, x):\n        x = x.view(\n            x.size(0),\n            int(self.img_dim//2 / self.patch_dim),\n            int(self.img_dim//2 / self.patch_dim),\n            int(self.img_dim//2 / self.patch_dim),\n            self.embedding_dim,\n        )\n        x = x.permute(0, 4, 1, 2, 3).contiguous()\n\n        return x\n","metadata":{"id":"MLfq9obROrbO","cellView":"form","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-04-22T01:30:32.392216Z","iopub.execute_input":"2023-04-22T01:30:32.393033Z","iopub.status.idle":"2023-04-22T01:30:32.427690Z","shell.execute_reply.started":"2023-04-22T01:30:32.392992Z","shell.execute_reply":"2023-04-22T01:30:32.426593Z"},"trusted":true},"execution_count":196,"outputs":[]},{"cell_type":"markdown","source":"def loadEEGData(data, subj):\n    X = []\n    Y = []\n    ID = []\n    print(subj)\n    subjXTEST = data[subj]['X_EEG_TEST']\n    for j in range(np.size(subjXTEST,2)):\n        #print(j)\n        subjXtest = subjXTEST[:,:,j]\n        subjXtest = mas2565_filter(subjXtest)\n        subjXtest = mas2565_normalize(subjXtest)  \n#         print(np.shape(subjXtest))\n        X.append(subjXtest)\n        Y.append(j+1)\n    print('eeg_tensor: ', np.shape(X))\n    print('trial_num: ',Y)\n    myfinalEEG = EEGData(X,Y)\n    print('data loaded for: ',subj)\n    return myfinalEEG\n\ndef mas2565_bagPreds(all_test_preds):\n#     for i in range(np.shape(all_test_preds)[1]):\n    pass\n        ","metadata":{"execution":{"iopub.status.busy":"2023-04-22T01:25:22.481392Z","iopub.execute_input":"2023-04-22T01:25:22.481976Z","iopub.status.idle":"2023-04-22T01:25:22.494078Z","shell.execute_reply.started":"2023-04-22T01:25:22.481932Z","shell.execute_reply":"2023-04-22T01:25:22.492910Z"}}},{"cell_type":"markdown","source":"# BAGGING AND FINAL TESTING\n\n# LOAD MODEL PATHS INTO A LIST\n#os.listdir('/kaggle/input/top-models/Top_models/*.pth')\ntop_model_dir = '/kaggle/input/top-models-full/Top_models_Full/'\npth_files = [f for f in os.listdir(top_model_dir) if f.endswith('.pth')]\ntop_models = []\nfor pth in pth_files:\n    pthDir = (top_model_dir + pth)\n#     print(pthDir)\n    top_models.append(pthDir)\nprint('TOP MODELS: \\n')\nprint(top_models)\n\nall_test_preds = []\nfor model in top_models:\n    mod_preds = []\n    state_dict = torch.load(model)\n#     print(state_dict.keys())\n    eegpt.load_state_dict(state_dict)\n    eegpt.eval()\n    for subject in data:\n        subjEEGData = loadEEGData(data,subject)        \n#         finalTestLoader = DataLoader(subjEEGData, batch_size =1, shuffle=False)\n        testLoader = DataLoader(subjEEGData, batch_size =1, shuffle=False)\n        subjTrialPreds = []\n        for i, sample in enumerate(finalTestLoader):\n            eeg_tensor = sample['eeg']\n            trial_num = sample['label']\n            finalPred = eegpt(eeg_tensor.cuda())\n            subjTrialPreds.append(finalPred)        \n#             print(np.shape(eeg_tensor))\n#             print(trial_num)\n        mod_preds.append(subjTrialPreds)\n    all_test_preds.append(mod_preds)\n            \n            ","metadata":{"execution":{"iopub.status.busy":"2023-04-22T01:25:22.495736Z","iopub.execute_input":"2023-04-22T01:25:22.496762Z","iopub.status.idle":"2023-04-22T01:25:22.766690Z","shell.execute_reply.started":"2023-04-22T01:25:22.496721Z","shell.execute_reply":"2023-04-22T01:25:22.764910Z"}}},{"cell_type":"code","source":"for subject in data:\n        subjEEGData = loadEEGData(data,subject)","metadata":{"execution":{"iopub.status.busy":"2023-04-22T01:25:22.768152Z","iopub.status.idle":"2023-04-22T01:25:22.768972Z","shell.execute_reply.started":"2023-04-22T01:25:22.768660Z","shell.execute_reply":"2023-04-22T01:25:22.768689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}